{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0490500e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "# default_exp core.block_types\n",
    "import os\n",
    "from nbdev.showdoc import *\n",
    "if not os.path.exists('settings.ini'):\n",
    "    os.chdir('..')\n",
    "    \n",
    "from block_types.core.block_types import __all__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d01038",
   "metadata": {},
   "source": [
    "# Block types\n",
    "\n",
    "> Types of blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e370aa98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from functools import partialmethod\n",
    "from typing import Optional\n",
    "import copy\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin, TransformerMixin\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow as pa\n",
    "import joblib\n",
    "from IPython.display import display\n",
    "\n",
    "try:\n",
    "    from graphviz import *\n",
    "    imported_graphviz = True\n",
    "except:\n",
    "    imported_graphviz = False\n",
    "\n",
    "# block_types\n",
    "from block_types.core.data_conversion import DataConverter, NoConverter, PandasConverter\n",
    "from block_types.core.utils import save_csv, save_parquet, save_multi_index_parquet, save_keras_model, save_csv_gz, read_csv, read_csv_gz\n",
    "from block_types.core.utils import DataIO, SklearnIO, PandasIO, NoSaverIO, ModelPlotter\n",
    "from block_types.core.utils import camel_to_snake\n",
    "from block_types.config import defaults as dflt\n",
    "from block_types.utils.utils import set_logger"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c79275f",
   "metadata": {},
   "source": [
    "## Component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2de14c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 3 g\n",
      "2 3\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "class A():\n",
    "    def f(self, x=1, y=2, func=None):\n",
    "        print (x, y, func)\n",
    "        getattr(self,func)(x, y)\n",
    "    def h (self, x=1, y=2):\n",
    "        print (x*2+y)\n",
    "    def g (self, x=1, y=2):\n",
    "        print (x, y)\n",
    "        print (x*3+y)\n",
    "    z = partialmethod (f, func='g', x=2)\n",
    "\n",
    "a = A()\n",
    "a.z (y=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "73e67a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "class Component (ClassifierMixin, TransformerMixin, BaseEstimator):\n",
    "    \"\"\"Base component class used in our Pipeline.\"\"\"\n",
    "    def __init__ (self,\n",
    "                  estimator=None,\n",
    "                  name: Optional[str] = None,\n",
    "                  data_converter: Optional[DataConverter] = None,\n",
    "                  data_io: Optional[DataIO] = None,\n",
    "                  model_plotter: Optional[ModelPlotter] = None,\n",
    "                  logger=None,\n",
    "                  verbose: int = 0,\n",
    "                  **kwargs):\n",
    "        \n",
    "        \"\"\"\n",
    "        Initialize attributes and fields.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        estimator : estimator (classifier or transformer) or None, optional\n",
    "            Estimator being wrapped.\n",
    "        name : Pipeline or None, optional\n",
    "            Name of component. If not provided, it is inferred from the name of the \n",
    "            estimator's class, or the name of the custom class defining the componet.\n",
    "        data_converter : DataConverter or None, optional\n",
    "            Converts incoming data to format expected by component, and convert \n",
    "            outgoing result to format expected by caller.\n",
    "        data_io : DataIO or None, optional\n",
    "            Manages data serialization and deserialization.\n",
    "        model_plotter : ModelPlotter or None, optional\n",
    "            Helper object that allows to retrieve information to be shown about this \n",
    "            component, as part of a Pipeline diagram.\n",
    "        logger : logging.logger or None, optional\n",
    "            Logger used to write messages\n",
    "        verbose : int, optional\n",
    "            Verbosity, 0: warning or critical, 1: info, 2: debug.\n",
    "        \"\"\"\n",
    "\n",
    "        # logger used to display messages\n",
    "        if logger is None:\n",
    "            self.logger = set_logger ('block_types', verbose=verbose)\n",
    "        else:\n",
    "            self.logger = logger\n",
    "\n",
    "        # name of current component, for logging and plotting purposes\n",
    "        self._determine_component_name (name, estimator)\n",
    "\n",
    "        # object that manages loading / saving\n",
    "        if data_io is None:\n",
    "            self.data_io = DataIO (component=self, **kwargs)\n",
    "        else:\n",
    "            self.data_io = copy.copy(data_io)\n",
    "            self.data_io.setup (self)\n",
    "\n",
    "        # estimator (ML model)\n",
    "        self.estimator = estimator\n",
    "\n",
    "        # data converter\n",
    "        if data_converter is None:\n",
    "            self.data_converter = NoConverter ()\n",
    "        else:\n",
    "            self.data_converter = data_converter\n",
    "\n",
    "        # plotting model component\n",
    "        if model_plotter is None:\n",
    "            self.model_plotter = ModelPlotter (component=self, **kwargs)\n",
    "        else:\n",
    "            self.model_plotter = model_plotter\n",
    "            self.model_plotter.set_component (self)\n",
    "\n",
    "    def _determine_component_name (self, name: Optional[str], estimator) -> None:\n",
    "        \"\"\"\n",
    "        Determines an appropriate name for the component if not provided by input.\n",
    "        \n",
    "        If not provided, it is inferred from the name of the estimator's class, or \n",
    "        the name of the custom class defining the componet.\n",
    "        \"\"\"\n",
    "        self.class_name = self.__class__.__name__\n",
    "        if (self.class_name in __all__) and (estimator is not None):\n",
    "            self.class_name = estimator.__class__.__name__\n",
    "\n",
    "        if name is not None:\n",
    "            self.name = name\n",
    "        else:\n",
    "            self.name = camel_to_snake (self.class_name)\n",
    "            \n",
    "    def fit_like (self, X, y=None, load=True, save=True, func='_fit', **kwargs):\n",
    "        \"\"\"\n",
    "        Estimates the parameters of the component based on given data X and labels y.\n",
    "        \n",
    "        Uses the previously fitted parameters if they're found in disk and overwrite \n",
    "        is False.\n",
    "        \"\"\"\n",
    "        self.logger.info (f'fitting {self.name}')\n",
    "        \n",
    "        previous_estimator = None\n",
    "        if load and not self.data_io.overwrite:\n",
    "            previous_estimator = self.data_io.load_estimator()\n",
    "            \n",
    "        if previous_estimator is None:\n",
    "            X, y = self.data_converter.convert_before_fitting (X, y)\n",
    "            if func=='_fit':\n",
    "                if len(kwargs) > 0:\n",
    "                    raise AttributeError (f'kwargs: {kwargs} not valid')\n",
    "                self._fit (X, y)\n",
    "            elif func=='__fit_apply':\n",
    "                result = self.__fit_apply (X, y, **kwargs)\n",
    "            else:\n",
    "                raise ValueError (f'function {func} not valid')\n",
    "            self.data_converter.convert_after_fitting (X)\n",
    "            if save:\n",
    "                self.data_io.save_estimator ()\n",
    "        else:\n",
    "            self.estimator = previous_estimator\n",
    "            self.logger.info (f'loaded pre-trained {self.name}')\n",
    "        if func=='_fit':\n",
    "            return self\n",
    "        else:\n",
    "            return result\n",
    "    \n",
    "    def __fit_apply (self, X, y, **kwargs):\n",
    "        if callable(getattr(self, '_fit_apply', None)):\n",
    "            return self._fit_apply (X, y, **kwargs)\n",
    "        else:\n",
    "            return self.fit (X, y).apply (X, **kwargs)\n",
    "     \n",
    "    fit = partialmethod (fit_like, func='_fit')\n",
    "    fit_apply = partialmethod (fit_like, func='__fit_apply')\n",
    "    \n",
    "    # aliases\n",
    "    fit_transform = fit_apply\n",
    "    fit_predict = fit_apply\n",
    "\n",
    "    def apply (self, *X, load=True, save=True, **kwargs):\n",
    "        \"\"\"\n",
    "        Transforms the data X and returns the transformed data.\n",
    "        \n",
    "        Uses the previously transformed data if it's found in disk and overwrite \n",
    "        is False.\n",
    "        \"\"\"\n",
    "        self.logger.info (f'applying {self.name} transform')\n",
    "        result_func = self._determine_result_func ()\n",
    "        result = self._compute_result (X, result_func, load=load, save=save, **kwargs)\n",
    "        return result\n",
    "\n",
    "    def _determine_result_func (self):\n",
    "        implemented = []\n",
    "        if callable(getattr(self, '_apply', None)):\n",
    "            result_func = self._apply\n",
    "            implemented += [result_func]\n",
    "        if callable(getattr(self, '_transform', None)):\n",
    "            result_func = self._transform\n",
    "            implemented += [result_func]\n",
    "        if callable(getattr(self, '_predict', None)):\n",
    "            result_func = self._predict\n",
    "            implemented += [result_func]\n",
    "        if self.estimator is not None and callable(getattr(self.estimator, 'transform', None)):\n",
    "            result_func = self.estimator.transform\n",
    "            implemented += [result_func]\n",
    "        if self.estimator is not None and callable(getattr(self.estimator, 'predict', None)):\n",
    "            result_func = self.estimator.predict\n",
    "            implemented += [result_func]\n",
    "        if len (implemented) == 0:\n",
    "            raise AttributeError (f'{self.class_name} must have one of _transform, _apply, or _predict methods implemented\\n'\n",
    "                                  f'Otherwise, self.estimator must have either predict or transform methods')\n",
    "        if len(implemented) > 1:\n",
    "            raise AttributeError (f'{self.class_name} must have only one of _transform, _apply, '\n",
    "                                  f'or _predict methods implemented => found: {implemented}')\n",
    "        return result_func\n",
    "    \n",
    "    # aliases for transform method\n",
    "    __call__ = apply\n",
    "    transform = apply\n",
    "    predict = partialmethod (apply, new_columns=['prediction'])\n",
    "\n",
    "    def _compute_result (self, X, result_func, load=True, save=True, **kwargs):\n",
    "        if len(X) == 1:\n",
    "            X = X[0]\n",
    "        previous_result = None\n",
    "        if load and not self.data_io.overwrite:\n",
    "            previous_result = self.data_io.load_result()\n",
    "        if previous_result is None:\n",
    "            X = self.data_converter.convert_before_transforming (X, **kwargs)\n",
    "            if type(X) is tuple:\n",
    "                result = result_func (*X)\n",
    "            else:\n",
    "                result = result_func (X)\n",
    "            result = self.data_converter.convert_after_transforming (result, **kwargs)\n",
    "            if save:\n",
    "                self.data_io.save_result (result)\n",
    "        else:\n",
    "            result = previous_result\n",
    "            self.logger.info (f'loaded pre-computed result')\n",
    "        return result\n",
    "\n",
    "\n",
    "    def _fit (self, X, y=None):\n",
    "        if self.estimator is not None:\n",
    "            self.estimator.fit (X, y)\n",
    "            \n",
    "    def show_result_statistics (self, result=None, training_data_flag=False) -> None:\n",
    "        \"\"\"\n",
    "        Show statistics of transformed data.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        result: DataFrame or other data structure or None, optional\n",
    "            Transformed data whose statistics we show. If not provided, it is loaded \n",
    "            from disk.\n",
    "        training_data_flag: bool, optional\n",
    "            If True, transformed training data is loaded, otherwise transformed test \n",
    "            data is loaded.\n",
    "        \"\"\"\n",
    "        if result is None:\n",
    "            self.set_training_data_flag (training_data_flag)\n",
    "            df = self.data_io.load_result()\n",
    "        else:\n",
    "            df = result\n",
    "        \n",
    "        if df is not None:\n",
    "            display (self.name)\n",
    "            if callable(getattr(df, 'describe', None)):\n",
    "                display (df.describe())\n",
    "\n",
    "    def assert_equal (self, path_reference_results: str, assert_equal_func=pd.testing.assert_frame_equal, **kwargs):\n",
    "        \"\"\"\n",
    "        Check whether the transformed data is the same as the reference data stored in given path.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        path_reference_results: str\n",
    "            Path where reference results are stored. The path does not include the \n",
    "            file name, since this is stored as a field of data_io.\n",
    "        assert_equal_func: function, optional\n",
    "            Function used to check whether the values are the same. By defaut, \n",
    "            `pd.testing.assert_frame_equal` is used, which assumes the data type is \n",
    "            DataFrame.\n",
    "        \n",
    "        \"\"\"\n",
    "        type_result = 'training' if self.data_io.training_data_flag else 'test'\n",
    "        self.logger.info (f'comparing {type_result} results for {self.class_name}')\n",
    "        \n",
    "        self.logger.info (f'loading...')\n",
    "        current_results = self.data_io.load_result ()\n",
    "        if self.data_io.training_data_flag:\n",
    "            path_to_reference_file = Path(path_reference_results) / self.data_io.result_file_name_training\n",
    "        else:\n",
    "            path_to_reference_file = Path(path_reference_results) / self.data_io.result_file_name_test\n",
    "        reference_results = self.data_io._load (path_to_reference_file, self.data_io.result_load_func)\n",
    "        self.logger.info (f'comparing...')\n",
    "        assert_equal_func (current_results, reference_results, **kwargs)\n",
    "        self.logger.info (f'equal results\\n')\n",
    "\n",
    "    # ********************************\n",
    "    # exposing some data_io and data_converters methods\n",
    "    # ********************************\n",
    "    def load_estimator (self):\n",
    "        estimator = self.data_io.load_estimator ()\n",
    "        if estimator is not None:\n",
    "            self.estimator = estimator\n",
    "        \n",
    "    # ********************************\n",
    "    # setters\n",
    "    # ********************************\n",
    "    def set_training_data_flag (self, training_data_flag):\n",
    "        self.data_io.set_training_data_flag (training_data_flag)\n",
    "\n",
    "    def set_save_result_flag_test (self, save_result_flag_test):\n",
    "        self.data_io.set_save_result_flag_test (save_result_flag_test)\n",
    "\n",
    "    def set_save_result_flag_training (self, save_result_flag_training):\n",
    "        self.data_io.set_save_result_flag_training (save_result_flag_training)\n",
    "\n",
    "    def set_save_result_flag (self, save_result_flag):\n",
    "        self.data_io.set_save_result_flag (save_result_flag)\n",
    "\n",
    "    def set_overwrite (self, overwrite):\n",
    "        self.data_io.set_overwrite (overwrite)\n",
    "\n",
    "    def set_save_fitting (self, save_fitting):\n",
    "        self.data_io.set_save_fitting (save_fitting)\n",
    "\n",
    "# ******************************************\n",
    "# Subclasses of Component.\n",
    "# Most of these are basically the same as GenericComponent, the only difference being that some parameters\n",
    "# are over-riden when constructing the object, to force a specific behavior\n",
    "# ******************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9125a115",
   "metadata": {},
   "source": [
    "#### Transform method called with different aliases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ae9bbf4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "applying my_transform transform\n",
      "applying my_transform transform\n",
      "applying my_transform transform\n",
      "applying my_transform transform\n",
      "applying my_transform2 transform\n",
      "applying my_transform2 transform\n",
      "applying my_transform2 transform\n",
      "applying my_transform2 transform\n",
      "applying my_transform3 transform\n",
      "applying my_transform3 transform\n",
      "applying my_transform3 transform\n",
      "applying my_transform3 transform\n",
      "applying my_transform4 transform\n",
      "applying my_transform5 transform\n"
     ]
    }
   ],
   "source": [
    "import pytest\n",
    "\n",
    "# test that we can implement _transform and use all the aliases \n",
    "# (transform, predict, apply,  __call__)\n",
    "class MyTransform (Component):\n",
    "    def _apply (self, x):\n",
    "        return x*2\n",
    "\n",
    "my_transform = MyTransform()\n",
    "assert my_transform.transform (3) == 6\n",
    "assert my_transform.predict (3) == 6\n",
    "assert my_transform.apply (3) == 6\n",
    "assert my_transform (3) == 6\n",
    "\n",
    "# test that we can implement _apply and use all the aliases \n",
    "# (transform, predict, apply and __call__)\n",
    "class MyTransform2 (Component):\n",
    "    def _apply (self, x):\n",
    "        return x*2\n",
    "\n",
    "my_transform2 = MyTransform2()\n",
    "assert my_transform2.transform (3) == 6\n",
    "assert my_transform2.predict (3) == 6\n",
    "assert my_transform2.apply (3) == 6\n",
    "assert my_transform2 (3) == 6\n",
    "\n",
    "# test that we can implement _predict and use all the aliases \n",
    "# (transform, predict, apply and __call__)\n",
    "class MyTransform3 (Component):\n",
    "    def _predict (self, x):\n",
    "        return x*2\n",
    "\n",
    "my_transform3 = MyTransform3()\n",
    "assert my_transform3.transform (3) == 6\n",
    "assert my_transform3.predict (3) == 6\n",
    "assert my_transform3.apply (3) == 6\n",
    "assert my_transform3 (3) == 6\n",
    "\n",
    "# test that an exception is raised if neither _tranform nor _apply are defined\n",
    "class MyTransform4 (Component):\n",
    "    def _wrong_method (self, x):\n",
    "        return x*2\n",
    " \n",
    "my_transform4 = MyTransform4 ()\n",
    "\n",
    "import pytest\n",
    "with pytest.raises(Exception):\n",
    "    my_transform4.transform(3)\n",
    "    \n",
    "\n",
    "# test that an exception is raised if more than one alias is implemented\n",
    "class MyTransform5 (Component):\n",
    "    def _predict (self, x):\n",
    "        return x*2\n",
    "    def _apply (self, x):\n",
    "        return x*2\n",
    " \n",
    "my_transform5 = MyTransform5 ()\n",
    "\n",
    "import pytest\n",
    "with pytest.raises(Exception):\n",
    "    my_transform5.transform(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f20147",
   "metadata": {},
   "source": [
    "#### Calling `predict` is handy when the result is a single array of predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9fe1eea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: remove this cell\n",
    "if False:\n",
    "    class MyTransform (Component):\n",
    "        def __init__ (self, **kwargs):\n",
    "            super().__init__ (\n",
    "                data_converter=PandasConverter(**kwargs),\n",
    "                **kwargs)\n",
    "\n",
    "        def _predict (self, x):\n",
    "            return x['a']+x['b']\n",
    "\n",
    "    my_transform = MyTransform()\n",
    "\n",
    "    df = pd.DataFrame ({'a': [10,20,30],'b':[4,5,6]})\n",
    "\n",
    "    pd.testing.assert_frame_equal(my_transform.transform (df).to_frame(), \n",
    "                                  pd.DataFrame ({0: [14,25,36]})\n",
    "                                 )\n",
    "\n",
    "    if False:\n",
    "        pd.testing.assert_frame_equal(my_transform.predict (df), \n",
    "                                      pd.DataFrame ({0: [14,25,36]})\n",
    "                                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0a8d8d",
   "metadata": {},
   "source": [
    "#### The `transform` method and its aliases can be called with multiple inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1088972d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "applying my_transform transform\n",
      "applying my_transform2 transform\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "# test that we can apply tranform to multiple data items\n",
    "class MyTransform (Component):\n",
    "    def _apply (self, x, y):\n",
    "        return x+y\n",
    "\n",
    "my_transform = MyTransform ()\n",
    "result = my_transform.transform (3, 4)\n",
    "print (result)\n",
    "assert result==7\n",
    "\n",
    "# test that we can apply tranform to single data items\n",
    "class MyTransform2 (Component):\n",
    "    def _apply (self, x):\n",
    "        return x*2\n",
    "\n",
    "my_transform2 = MyTransform2 ()\n",
    "result = my_transform2.transform (3)\n",
    "print (result)\n",
    "assert result==6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b273a5c8",
   "metadata": {},
   "source": [
    "#### `fit_apply()` and its aliases `fit_transform(), fit_predict()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b3b34a",
   "metadata": {},
   "source": [
    "`_fit_apply()` is called when implemented, otherwise `fit().apply()` is called"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a6905639",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fitting transform1\n",
      "fitting transform1\n",
      "fitting transform2\n",
      "fitting transform2\n",
      "applying transform2 transform\n",
      "fitting transform2\n",
      "fitting transform2\n",
      "applying transform2 transform\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "\n",
    "# example with _fit_apply implemented\n",
    "class Transform1 (Component):\n",
    "    def __init__ (self, **kwargs):\n",
    "        super().__init__ (**kwargs)\n",
    "    def _fit (self, X, y=None):\n",
    "        self.sum = X.sum(axis=0)\n",
    "    def _apply (self, X):\n",
    "        return X + self.sum\n",
    "    def _fit_apply (self, X, y=None):\n",
    "        self.sum = X.sum(axis=0)*10\n",
    "        return X + self.sum\n",
    "\n",
    "tr1 = Transform1 ()\n",
    "X = np.array ([100, 90, 10])\n",
    "result = tr1.fit_apply (X)\n",
    "assert (result==(X+2000)).all()\n",
    "\n",
    "# same result obtained by aliases\n",
    "result = tr1.fit_transform (X)\n",
    "assert (result==(X+2000)).all()\n",
    "    \n",
    "# example without _fit_apply implemented\n",
    "class Transform2 (Component):\n",
    "    def __init__ (self, **kwargs):\n",
    "        super().__init__ (**kwargs)\n",
    "    def _fit (self, X, y=None):\n",
    "        self.sum = X.sum(axis=0)\n",
    "    def _apply (self, X):\n",
    "        return X + self.sum\n",
    "\n",
    "tr2 = Transform2 ()\n",
    "result = tr2.fit_apply (X)\n",
    "assert (result==(X+200)).all()\n",
    "\n",
    "# same result obtained by aliases\n",
    "result = tr2.fit_transform (X)\n",
    "assert (result==(X+200)).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cfc6d434",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h3 id=\"Component\" class=\"doc_header\"><code>class</code> <code>Component</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h3>\n",
       "\n",
       "> <code>Component</code>(**`estimator`**=*`None`*, **`name`**:`Optional`\\[`str`\\]=*`None`*, **`data_converter`**:`Optional`\\[[`DataConverter`](/core.data_conversion.html#DataConverter)\\]=*`None`*, **`data_io`**:`Optional`\\[[`DataIO`](/core.utils.html#DataIO)\\]=*`None`*, **`model_plotter`**:`Optional`\\[[`ModelPlotter`](/core.utils.html#ModelPlotter)\\]=*`None`*, **`logger`**=*`None`*, **`verbose`**:`int`=*`0`*, **\\*\\*`kwargs`**) :: `ClassifierMixin`\n",
       "\n",
       "```\n",
       "Base component class used in our Pipeline.\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"__init__\" class=\"doc_header\"><code>__init__</code><a href=\"__main__.py#L5\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>__init__</code>(**`estimator`**=*`None`*, **`name`**:`Optional`\\[`str`\\]=*`None`*, **`data_converter`**:`Optional`\\[[`DataConverter`](/core.data_conversion.html#DataConverter)\\]=*`None`*, **`data_io`**:`Optional`\\[[`DataIO`](/core.utils.html#DataIO)\\]=*`None`*, **`model_plotter`**:`Optional`\\[[`ModelPlotter`](/core.utils.html#ModelPlotter)\\]=*`None`*, **`logger`**=*`None`*, **`verbose`**:`int`=*`0`*, **\\*\\*`kwargs`**)\n",
       "\n",
       "```\n",
       "Initialize attributes and fields.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "estimator : estimator (classifier or transformer) or None, optional\n",
       "    Estimator being wrapped.\n",
       "name : Pipeline or None, optional\n",
       "    Name of component. If not provided, it is inferred from the name of the \n",
       "    estimator's class, or the name of the custom class defining the componet.\n",
       "data_converter : DataConverter or None, optional\n",
       "    Converts incoming data to format expected by component, and convert \n",
       "    outgoing result to format expected by caller.\n",
       "data_io : DataIO or None, optional\n",
       "    Manages data serialization and deserialization.\n",
       "model_plotter : ModelPlotter or None, optional\n",
       "    Helper object that allows to retrieve information to be shown about this \n",
       "    component, as part of a Pipeline diagram.\n",
       "logger : logging.logger or None, optional\n",
       "    Logger used to write messages\n",
       "verbose : int, optional\n",
       "    Verbosity, 0: warning or critical, 1: info, 2: debug.\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"fit\" class=\"doc_header\"><code>fit</code><a href=\"functools.py#L371\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>fit</code>(**`X`**, **`y`**=*`None`*, **`load`**=*`True`*, **`save`**=*`True`*, **`func`**=*`'_fit'`*, **\\*\\*`kwargs`**)\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"transform\" class=\"doc_header\"><code>transform</code><a href=\"__main__.py#L134\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>transform</code>(**\\*`X`**, **`load`**=*`True`*, **`save`**=*`True`*, **\\*\\*`kwargs`**)\n",
       "\n",
       "```\n",
       "Transforms the data X and returns the transformed data.\n",
       "\n",
       "Uses the previously transformed data if it's found in disk and overwrite \n",
       "is False.\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"predict\" class=\"doc_header\"><code>predict</code><a href=\"functools.py#L371\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>predict</code>(**\\*`X`**, **`load`**=*`True`*, **`save`**=*`True`*, **\\*\\*`kwargs`**)\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"show_result_statistics\" class=\"doc_header\"><code>show_result_statistics</code><a href=\"__main__.py#L201\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>show_result_statistics</code>(**`result`**=*`None`*, **`training_data_flag`**=*`False`*)\n",
       "\n",
       "```\n",
       "Show statistics of transformed data.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "result: DataFrame or other data structure or None, optional\n",
       "    Transformed data whose statistics we show. If not provided, it is loaded \n",
       "    from disk.\n",
       "training_data_flag: bool, optional\n",
       "    If True, transformed training data is loaded, otherwise transformed test \n",
       "    data is loaded.\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc (Component, name='Component', title_level=3)\n",
    "show_doc (Component.__init__, name='__init__', title_level=4)\n",
    "show_doc (Component.fit, name='fit', title_level=4)\n",
    "show_doc (Component.transform, name='transform', title_level=4)\n",
    "show_doc (Component.predict, name='predict', title_level=4)\n",
    "show_doc (Component.show_result_statistics, name='show_result_statistics', title_level=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0592bd32",
   "metadata": {},
   "source": [
    "## Sub-classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "060c19d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class SamplingComponent (Component):\n",
    "    \"\"\"\n",
    "    Component that makes use of labels in transform method.\n",
    "    \n",
    "    When calling the transform method, one of the columns of the received data \n",
    "    is assumed to contain the ground-truth labels. This allows the transform \n",
    "    method to modify the number of observations, changing the number of rows in \n",
    "    the data and in the labels. See `PandasConverter` class in \n",
    "    `block_types.core.data_conversion`.\n",
    "    \"\"\"\n",
    "    def __init__ (self,\n",
    "                  estimator=None,\n",
    "                  transform_uses_labels=True,\n",
    "                  **kwargs):\n",
    "\n",
    "        # the SamplingComponent over-rides the following parameters:\n",
    "        super().__init__ (estimator=estimator,\n",
    "                          transform_uses_labels=transform_uses_labels,\n",
    "                          **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "48f37cbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h3 id=\"SamplingComponent\" class=\"doc_header\"><code>class</code> <code>SamplingComponent</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h3>\n",
       "\n",
       "> <code>SamplingComponent</code>(**`estimator`**=*`None`*, **`transform_uses_labels`**=*`True`*, **\\*\\*`kwargs`**) :: [`Component`](/core.block_types.html#Component)\n",
       "\n",
       "```\n",
       "Component that makes use of labels in transform method.\n",
       "\n",
       "When calling the transform method, one of the columns of the received data \n",
       "is assumed to contain the ground-truth labels. This allows the transform \n",
       "method to modify the number of observations, changing the number of rows in \n",
       "the data and in the labels. See `PandasConverter` class in \n",
       "`block_types.core.data_conversion`.\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc (SamplingComponent, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7aed9e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class SklearnComponent (Component):\n",
    "    \"\"\"\n",
    "    Component that saves estimator parameters in pickle format.\n",
    "    \n",
    "    Convenience subclass used when the results can be saved in \n",
    "    pickle format. See `SklearnIO` class in `core.utils`.\n",
    "    \"\"\"\n",
    "    def __init__ (self,\n",
    "                  estimator=None,\n",
    "                  data_io=None,\n",
    "                  transform_uses_labels=False,\n",
    "                  **kwargs):\n",
    "\n",
    "        if data_io is None:\n",
    "            data_io = SklearnIO (**kwargs)\n",
    "        \n",
    "        super().__init__ (estimator=estimator,\n",
    "                          data_io = data_io,\n",
    "                          transform_uses_labels=False,\n",
    "                          **kwargs)\n",
    "\n",
    "# alias\n",
    "PickleSaverComponent = SklearnComponent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "733e429f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h3 id=\"SklearnComponent\" class=\"doc_header\"><code>class</code> <code>SklearnComponent</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h3>\n",
       "\n",
       "> <code>SklearnComponent</code>(**`estimator`**=*`None`*, **`data_io`**=*`None`*, **`transform_uses_labels`**=*`False`*, **\\*\\*`kwargs`**) :: [`Component`](/core.block_types.html#Component)\n",
       "\n",
       "```\n",
       "Component that saves estimator parameters in pickle format.\n",
       "\n",
       "Convenience subclass used when the results can be saved in \n",
       "pickle format. See `SklearnIO` class in `core.utils`.\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc (SklearnComponent, name = 'SklearnComponent', title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "69747f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class NoSaverComponent (Component):\n",
    "    \"\"\"Component that does not save any data.\"\"\"\n",
    "    def __init__ (self,\n",
    "                  estimator=None,\n",
    "                  data_io=None,\n",
    "                  **kwargs):\n",
    "\n",
    "        if data_io is None:\n",
    "            data_io = NoSaverIO (**kwargs)\n",
    "        \n",
    "        super().__init__ (estimator=estimator,\n",
    "                          data_io=data_io,\n",
    "                          **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "215fbbbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h3 id=\"SklearnComponent\" class=\"doc_header\"><code>class</code> <code>SklearnComponent</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h3>\n",
       "\n",
       "> <code>SklearnComponent</code>(**`estimator`**=*`None`*, **`data_io`**=*`None`*, **\\*\\*`kwargs`**) :: [`Component`](/core.block_types.html#Component)\n",
       "\n",
       "```\n",
       "Component that does not save any data.\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc (NoSaverComponent, name = 'SklearnComponent', title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6f88a389",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class OneClassSklearnComponent (SklearnComponent):\n",
    "    \"\"\"Component that uses only normal data (labelled with 0) for fitting parameters.\"\"\"\n",
    "    def __init__ (self,\n",
    "                  estimator=None,\n",
    "                  **kwargs):\n",
    "        super().__init__ (estimator=estimator,\n",
    "                          **kwargs)\n",
    "\n",
    "    def _fit (self, X, y=None):\n",
    "        assert y is not None, 'y must be provided in OneClassSklearnComponent class'\n",
    "        X = X[y==0]\n",
    "\n",
    "        assert self.estimator is not None, 'estimator must be provided in OneClassSklearnComponent class'\n",
    "        self.estimator.fit (X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e264f788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h3 id=\"OneClassSklearnComponent\" class=\"doc_header\"><code>class</code> <code>OneClassSklearnComponent</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h3>\n",
       "\n",
       "> <code>OneClassSklearnComponent</code>(**`estimator`**=*`None`*, **\\*\\*`kwargs`**) :: [`SklearnComponent`](/core.block_types.html#SklearnComponent)\n",
       "\n",
       "```\n",
       "Component that uses only normal data (labelled with 0) for fitting parameters.\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc (OneClassSklearnComponent, name = 'OneClassSklearnComponent', title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4778b9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class PandasComponent (Component):\n",
    "    \"\"\"\n",
    "    Component that preserves the DataFrame format for incoming data and results.\n",
    "    \n",
    "    This component also writes results in parquet format, by default.\n",
    "    See `PandasConverter` in `core.data_conversion` for details on the data \n",
    "    conversion performed.\n",
    "    \"\"\"\n",
    "    def __init__ (self,\n",
    "                  estimator=None,\n",
    "                  data_converter=None,\n",
    "                  data_io=None,\n",
    "                  **kwargs):\n",
    "\n",
    "        if data_converter is None:\n",
    "            data_converter = PandasConverter (**kwargs)\n",
    "        if data_io is None:\n",
    "            data_io = PandasIO (**kwargs)\n",
    "\n",
    "        super().__init__ (estimator=estimator,\n",
    "                          data_converter=data_converter,\n",
    "                          data_io=data_io,\n",
    "                          **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f9e0deab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h3 id=\"PandasComponent\" class=\"doc_header\"><code>class</code> <code>PandasComponent</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h3>\n",
       "\n",
       "> <code>PandasComponent</code>(**`estimator`**=*`None`*, **`data_converter`**=*`None`*, **`data_io`**=*`None`*, **\\*\\*`kwargs`**) :: [`Component`](/core.block_types.html#Component)\n",
       "\n",
       "```\n",
       "Component that preserves the DataFrame format for incoming data and results.\n",
       "\n",
       "This component also writes results in parquet format, by default.\n",
       "See `PandasConverter` in `core.data_conversion` for details on the data \n",
       "conversion performed.\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc (PandasComponent, name='PandasComponent', title_level=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (block_types)",
   "language": "python",
   "name": "block_types"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
