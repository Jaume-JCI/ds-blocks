{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccd85e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "# default_exp core.compose\n",
    "import os\n",
    "from nbdev.showdoc import *\n",
    "if not os.path.exists('settings.ini'):\n",
    "    os.chdir('..')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434bfb86",
   "metadata": {},
   "source": [
    "# Compose transforms\n",
    "\n",
    "> Classes and utilities for composed transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44f392e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import pandas as pd\n",
    "\n",
    "from block_types.core.block_types import Component, PandasComponent, SamplingComponent\n",
    "from block_types.core.data_conversion import PandasConverter\n",
    "from block_types.core.utils import PandasIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ca1edc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class MultiComponent (SamplingComponent):\n",
    "    \"\"\"\n",
    "    Component containing a list of components inside.\n",
    "    \n",
    "    The list must contain at least one component. \n",
    "    \n",
    "    See `Pipeline` class.\n",
    "    \"\"\"\n",
    "    def __init__ (self, separate_labels = False, **kwargs):\n",
    "        \"\"\"Assigns attributes and calls parent constructor.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        separate_labels: bool, optional\n",
    "            whether or not the fit method receives the labels in a separate `y` vector \n",
    "            or in the same input `X`, as an additional variable. See description of \n",
    "            Pipeline class for more details.\n",
    "        \"\"\"\n",
    "        if not hasattr (self, 'components'):\n",
    "            self.components = []\n",
    "        if not hasattr (self, 'finalized_component_list'):\n",
    "            self.finalized_component_list = False\n",
    "        \n",
    "        # we need to call super().__init__() *after* having creating the `components` field,\n",
    "        # since the constructor of Component calls a method that is overriden in Pipeline, \n",
    "        # and this method makes use of the mentioned `components` field\n",
    "        super().__init__ (separate_labels = separate_labels, \n",
    "                          **kwargs)\n",
    "\n",
    "        self.set_training_data_flag(False)\n",
    "        \n",
    "    \n",
    "    def register_components (self, *ms):\n",
    "        \"\"\"\n",
    "        Registering component in `self.components` list.\n",
    "        \n",
    "        Every time that a new component is set as an attribute of the pipeline,\n",
    "        this component is added to the list `self.components`. Same \n",
    "        mechanism as the one used by pytorch's `nn.Module`\n",
    "        \"\"\"\n",
    "        if not hasattr(self, 'components'):\n",
    "            self.components = []\n",
    "            self.finalized_component_list = False\n",
    "        if not self.finalized_component_list:\n",
    "            self.components += ms\n",
    "    \n",
    "    def __setattr__(self, k, v):\n",
    "        \"\"\"\n",
    "        See register_components\n",
    "        \"\"\"\n",
    "        super().__setattr__(k, v)\n",
    "        \n",
    "        if isinstance(v, Component):\n",
    "            self.register_components(v)\n",
    "            \n",
    "    def add_component (self, component):\n",
    "        if not hasattr(self, 'finalized_component_list'):\n",
    "            self.finalized_component_list = False\n",
    "        finalized_component_list = self.finalized_component_list\n",
    "        self.finalized_component_list = False\n",
    "        self.register_components(component)\n",
    "        self.finalized_component_list = finalized_component_list\n",
    "        \n",
    "    def set_components (self, *components):\n",
    "        self.components = components\n",
    "        self.finalized_component_list = True\n",
    "        \n",
    "    def construct_diagram (self, training_data_flag=None, include_url=False, port=4000, project='block_types'):\n",
    "        \"\"\"\n",
    "        Construct diagram of the pipeline components, data flow and dimensionality.\n",
    "        \n",
    "        By default, we use test data to show the number of observations \n",
    "        in the output of each component. This can be changed passing \n",
    "        `training_data_flag=True`\n",
    "        \"\"\"\n",
    "        training_data_flag = self.get_training_data_flag (training_data_flag)\n",
    "\n",
    "        if include_url:\n",
    "            base_url = f'http://localhost:{port}/{project}'\n",
    "        else:\n",
    "            URL = ''\n",
    "\n",
    "        node_name = 'data'\n",
    "        output = 'train / test'\n",
    "\n",
    "        f = Digraph('G', filename='fsm2.svg')\n",
    "        f.attr('node', shape='circle')\n",
    "\n",
    "        f.node(node_name)\n",
    "\n",
    "        f.attr('node', shape='box')\n",
    "        for component in self.components:\n",
    "            last_node_name = node_name\n",
    "            last_output = output\n",
    "            node_name = component.model_plotter.get_node_name()\n",
    "            if include_url:\n",
    "                URL = f'{base_url}/{component.model_plotter.get_module_path()}.html#{node_name}'\n",
    "            f.node(node_name, URL=URL)\n",
    "            f.edge(last_node_name, node_name, label=last_output)\n",
    "            output = component.model_plotter.get_edge_name(training_data_flag=training_data_flag)\n",
    "\n",
    "        last_node_name = node_name\n",
    "        node_name = 'output'\n",
    "        f.attr('node', shape='circle')\n",
    "        f.edge(last_node_name, node_name, label=output)\n",
    "\n",
    "        return f\n",
    "\n",
    "    def show_result_statistics (self, training_data_flag=None):\n",
    "        \"\"\"\n",
    "        Show statistics about results obtained by each component. \n",
    "        \n",
    "        By default, this is shown on test data, although this can change setting \n",
    "        `training_data_flag=True`\n",
    "        \"\"\"\n",
    "        training_data_flag = self.get_training_data_flag (training_data_flag)\n",
    "\n",
    "        for component in self.components:\n",
    "            component.show_result_statistics(training_data_flag=training_data_flag)\n",
    "\n",
    "    def show_summary (self, training_data_flag=None):\n",
    "        \"\"\"\n",
    "        Show list of pipeline components, data flow and dimensionality.\n",
    "        \n",
    "        By default, we use test data to show the number of observations \n",
    "        in the output of each component. This can be changed passing \n",
    "        `training_data_flag=True`\n",
    "        \"\"\"\n",
    "        training_data_flag = self.get_training_data_flag (training_data_flag)\n",
    "\n",
    "        node_name = 'data'\n",
    "        output = 'train / test'\n",
    "\n",
    "        for i, component in enumerate(self.components):\n",
    "            node_name = component.model_plotter.get_node_name()\n",
    "            output = component.model_plotter.get_edge_name(training_data_flag=training_data_flag)\n",
    "            print (f'{\"-\"*100}')\n",
    "            print (f'{i}: {node_name} => {output}')\n",
    "\n",
    "\n",
    "    def get_training_data_flag (self, training_data_flag=None):\n",
    "        if training_data_flag is None:\n",
    "            if self.data_io.training_data_flag is not None:\n",
    "                training_data_flag = self.data_io.training_data_flag\n",
    "            else:\n",
    "                training_data_flag = False\n",
    "\n",
    "        return training_data_flag\n",
    "\n",
    "    def assert_equal (self, path_reference_results, assert_equal_func=pd.testing.assert_frame_equal, **kwargs):\n",
    "        \"\"\"Compare results stored in current run against reference results stored in given path.\"\"\"\n",
    "\n",
    "        for component in self.components:\n",
    "            component.assert_equal (path_reference_results, assert_equal_func=assert_equal_func, **kwargs)\n",
    "        self.logger.info ('both pipelines give the same results')\n",
    "        print ('both pipelines give the same results')\n",
    "        \n",
    "    def load_estimator (self):\n",
    "        for component in self.components:\n",
    "            component.load_estimator ()\n",
    "\n",
    "    # *************************\n",
    "    # setters\n",
    "    # *************************\n",
    "    def set_training_data_flag (self, training_data_flag):\n",
    "        super().set_training_data_flag (training_data_flag)\n",
    "        for component in self.components:\n",
    "            component.set_training_data_flag (training_data_flag)\n",
    "\n",
    "    def set_save_result_flag_test (self, save_result_flag_test):\n",
    "        super().set_save_result_flag_test (save_result_flag_test)\n",
    "        for component in self.components:\n",
    "            component.set_save_result_flag_test (save_result_flag_test)\n",
    "\n",
    "    def set_save_result_flag_training (self, save_result_flag_training):\n",
    "        super().set_save_result_flag_training (save_result_flag_training)\n",
    "        for component in self.components:\n",
    "            component.set_save_result_flag_training (save_result_flag_training)\n",
    "\n",
    "    def set_save_result_flag (self, save_result_flag):\n",
    "        super().set_save_result_flag (save_result_flag)\n",
    "        for component in self.components:\n",
    "            component.set_save_result_flag (save_result_flag)\n",
    "\n",
    "    def set_overwrite (self, overwrite):\n",
    "        super().set_overwrite (overwrite)\n",
    "        for component in self.components:\n",
    "            component.set_overwrite (overwrite)\n",
    "\n",
    "    def set_save_fitting (self, save_fitting):\n",
    "        super().set_save_fitting (save_fitting)\n",
    "        for component in self.components:\n",
    "            component.set_save_fitting (save_fitting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3caa0a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Pipeline (MultiComponent):\n",
    "    \"\"\"\n",
    "    Pipeline composed of a list of components that run sequentially.\n",
    "    \n",
    "    During training, the components of the list are trained one after the other, \n",
    "    where one component is fed the result of transforming the data with the list \n",
    "    of components located before in the pipeline.\n",
    "    \n",
    "    The `Pipeline` class is a subclass of `SamplingComponent`, which itself is a \n",
    "    subclass of `Component`. This provides the functionality of `Component` \n",
    "    to any implemented pipeline, such as logging the messages, loading / saving the \n",
    "    results, and convert the data format so that it can work as part of other \n",
    "    pipelines with potentially other data formats.\n",
    "    \n",
    "    Being a subclass of `SamplingComponent`, the `transform` method \n",
    "    receives an input data  `X` that contains both data and labels. \n",
    "    \n",
    "    Furthermore, the Pipeline constructor sets `separate_labels=False` by default,\n",
    "    which means that the `fit` method also receives an input data `X` that contains \n",
    "    not only data but also labels. This is necessary because some of the components in \n",
    "    the pipeline might be of class `SamplingComponent`, and such components \n",
    "    need the input data `X` to contain labels when calling `transform` (and note that \n",
    "    this method is called when calling `fit` on a pipeline, since we do `fit_transform`\n",
    "    on all the components except for the last one)\n",
    "    \"\"\"\n",
    "    def __init__ (self, **kwargs):\n",
    "        \"\"\"Assigns attributes and calls parent constructor.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        separate_labels: bool, optional\n",
    "            whether or not the fit method receives the labels in a separate `y` vector \n",
    "            or in the same input `X`, as an additional variable. See description of \n",
    "            Pipeline class for more details.\n",
    "        \"\"\"\n",
    "        \n",
    "        super().__init__ (**kwargs)\n",
    "        \n",
    "    def _fit (self, X, y=None):\n",
    "        \"\"\"\n",
    "        Fit components of the pipeline, given data X and labels y.\n",
    "        \n",
    "        By default, y will be None, and the labels are part of `X`, as a variable.\n",
    "        \"\"\"\n",
    "        X = self._fit_apply_except_last (X, y)\n",
    "        self.components[-1].fit (X, y)\n",
    "    \n",
    "    def _fit_apply (self, X, y=None, **kwargs):\n",
    "        X = self._fit_apply_except_last (X, y, **kwargs)\n",
    "        return self.components[-1].fit_apply (X, y, **kwargs)\n",
    "\n",
    "    def _fit_apply_except_last (self, X, y, **kwargs):\n",
    "        #self.set_training_data_flag (True)\n",
    "        for component in self.components[:-1]:\n",
    "            X = component.fit_apply (X, y, **kwargs)\n",
    "        return X\n",
    "    \n",
    "    def _apply (self, X):\n",
    "        \"\"\"Transform data with components of pipeline, and predict labels with last component. \n",
    "        \n",
    "        In the current implementation, we consider prediction a form of mapping, \n",
    "        and therefore a special type of transformation.\"\"\"\n",
    "        #self.set_training_data_flag (False)\n",
    "        for component in self.components:\n",
    "            X = component.transform (X)\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b49ef4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    show_doc (Pipeline, title_level=3)\n",
    "    show_doc (Pipeline.__init__, name='__init__', title_level=4)\n",
    "    show_doc (Pipeline.construct_diagram, name='construct_diagram', title_level=4)\n",
    "    show_doc (Pipeline.show_summary, name='show_summary', title_level=4)\n",
    "    show_doc (Pipeline.show_result_statistics, name='show_result_statistics', title_level=4)\n",
    "    show_doc (Pipeline.assert_equal, name='assert_equal', title_level=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d261ce6c",
   "metadata": {},
   "source": [
    "#### `fit_apply` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21d17546",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fitting new_pipeline\n",
      "fitting transform1\n",
      "applying transform1 transform\n",
      "fitting transform2\n",
      "applying transform2 transform\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[306212]\n",
      " [406212]\n",
      " [506212]]\n"
     ]
    }
   ],
   "source": [
    "# test `fit_apply` method\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import Bunch\n",
    "from block_types.core.block_types import PickleSaverComponent\n",
    "from block_types.utils.utils import remove_previous_results\n",
    "\n",
    "# Transform1: custom Transform\n",
    "class Transform1 (Component):\n",
    "    \n",
    "    def __init__ (self, **kwargs):\n",
    "        super().__init__ (**kwargs)\n",
    "        self.estimator= Bunch(sum = 1)\n",
    "        \n",
    "    def _fit (self, X, y=None):\n",
    "        self.estimator.sum = X.sum(axis=0)\n",
    "    \n",
    "    def _apply (self, x):\n",
    "        return x*1000 + self.estimator.sum\n",
    "    \n",
    "class Transform2 (Component):\n",
    "    \n",
    "    def __init__ (self, **kwargs):\n",
    "        super().__init__ (**kwargs)\n",
    "        self.estimator= Bunch(maxim = 1)\n",
    "        \n",
    "    def _fit (self, X, y=None):\n",
    "        self.estimator.maxim = X.max(axis=0)\n",
    "    \n",
    "    def _apply (self, x):\n",
    "        return x*100 + self.estimator.maxim\n",
    "\n",
    "class NewPipeline (Pipeline):\n",
    "    \n",
    "    def __init__ (self, **kwargs):\n",
    "        super().__init__ (**kwargs)\n",
    "        \n",
    "        # custom transform\n",
    "        self.tr1 = Transform1(**kwargs) \n",
    "        \n",
    "        # slklearn transform\n",
    "        self.tr2 = Transform2(**kwargs) \n",
    "\n",
    "pipeline = NewPipeline()\n",
    "x = np.array([3,4,5])\n",
    "r1 = pipeline.fit_apply (x.reshape(-1,1))\n",
    "print (r1)\n",
    "\n",
    "x1 = x * 1000 + sum(x)\n",
    "x2 = x1 * 100 + max(x1)\n",
    "assert (r1.ravel()==x2).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3bac1ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fitting new_multi\n",
      "fitting transform1\n",
      "fitting transform2\n",
      "applying new_multi transform\n",
      "applying transform1 transform\n",
      "applying transform2 transform\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3317 4417 5517]\n"
     ]
    }
   ],
   "source": [
    "class NewMulti (MultiComponent):\n",
    "    \n",
    "    def __init__ (self, **kwargs):\n",
    "        super().__init__ (**kwargs)\n",
    "        \n",
    "        # custom transform\n",
    "        self.tr1 = Transform1(**kwargs) \n",
    "        \n",
    "        # slklearn transform\n",
    "        self.tr2 = Transform2(**kwargs) \n",
    "        \n",
    "    def _fit (self, X, y=None):\n",
    "        self.tr1.fit (X)\n",
    "        self.tr2.fit (X)\n",
    "        \n",
    "    def _apply (self, X, y=None):\n",
    "        X1=self.tr1.apply (X)\n",
    "        X2=self.tr2.apply (X)\n",
    "        return X1+X2\n",
    "\n",
    "new_multi = NewMulti()\n",
    "r2 = new_multi.fit_apply (x)\n",
    "print (r2)\n",
    "x2b = 100 * x + max(x)\n",
    "assert (r2.ravel()==(x1 + x2b)).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35aacd2b",
   "metadata": {},
   "source": [
    "#### adding new components to pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8167bf05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "applying new_pipeline transform\n",
      "applying function_transformer transform\n",
      "applying function_transformer transform\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "# test automatic creation of pipeline components\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "# 1. by setting components as attributes:\n",
    "class NewPipeline(Pipeline):\n",
    "    def __init__ (self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.tr1 = Component(FunctionTransformer (lambda x: x+1))\n",
    "        self.tr2 = Component(FunctionTransformer (lambda x: x*2))\n",
    "pipeline = NewPipeline()\n",
    "result = pipeline.transform (3)\n",
    "print (result)\n",
    "assert result == 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59ae2602",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "applying new_pipeline transform\n",
      "applying function_transformer transform\n",
      "applying function_transformer transform\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 2\n"
     ]
    }
   ],
   "source": [
    "#2. by using `set_components`\n",
    "class NewPipeline(Pipeline):\n",
    "    def __init__ (self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        tr1 = Component(FunctionTransformer (lambda x: x+1))\n",
    "        tr2 = Component(FunctionTransformer (lambda x: x*2))\n",
    "        self.set_components (tr1, tr2)\n",
    "        \n",
    "        # the following transform is not added to the pipeline component list:\n",
    "        self.tr3 = Component(FunctionTransformer (lambda x: x+1))\n",
    "        \n",
    "        # The reason is that once set_components is called, the component list \n",
    "        # is frozen and inmutable setting new components by attribute doesn't \n",
    "        # result in adding them to the component list\n",
    "        \n",
    "pipeline = NewPipeline()\n",
    "result = pipeline.transform (3)\n",
    "\n",
    "assert result == 8\n",
    "assert len(pipeline.components) == 2\n",
    "print (result, len(pipeline.components))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11918856",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "applying new_pipeline transform\n",
      "applying function_transformer transform\n",
      "applying function_transformer transform\n",
      "applying function_transformer transform\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 3\n"
     ]
    }
   ],
   "source": [
    "#3. after calling `set_components()`, we can add new components with `add_component()`\n",
    "class NewPipeline(Pipeline):\n",
    "    def __init__ (self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        tr1 = Component(FunctionTransformer (lambda x: x+1))\n",
    "        tr2 = Component(FunctionTransformer (lambda x: x*2))\n",
    "        self.set_components (tr1, tr2)\n",
    "        \n",
    "        tr3 = Component(FunctionTransformer (lambda x: x+2))\n",
    "        self.add_component(tr3)\n",
    "        \n",
    "pipeline = NewPipeline()\n",
    "result = pipeline.transform (3)\n",
    "\n",
    "assert result == 10\n",
    "assert len(pipeline.components) == 3\n",
    "print (result, len(pipeline.components))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6221cf2",
   "metadata": {},
   "source": [
    "#### `load_estimator` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19b77022",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fitting new_pipeline\n",
      "fitting transform1\n",
      "fitting standard_scaler\n",
      "applying new_pipeline transform\n",
      "applying transform1 transform\n",
      "applying standard_scaler transform\n",
      "loading from /home/jcidatascience/jaume/workspace/remote/temp/block-types/results/transform1_estimator.pk\n",
      "loading from /home/jcidatascience/jaume/workspace/remote/temp/block-types/results/standard_scaler_estimator.pk\n",
      "applying new_pipeline transform\n",
      "applying transform1 transform\n",
      "applying standard_scaler transform\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.]\n",
      "[4.]\n"
     ]
    }
   ],
   "source": [
    "# test `load_estimator` method\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import Bunch\n",
    "from block_types.core.block_types import PickleSaverComponent\n",
    "from block_types.utils.utils import remove_previous_results\n",
    "\n",
    "# Transform1: custom Transform\n",
    "class Transform1 (PickleSaverComponent):\n",
    "    \n",
    "    def __init__ (self, **kwargs):\n",
    "        super().__init__ (**kwargs)\n",
    "        self.estimator= Bunch(inv_c = 1)\n",
    "        \n",
    "    def _fit (self, X, y=None):\n",
    "        self.estimator.inv_c = X.ravel()[0]\n",
    "    \n",
    "    def _apply (self, x):\n",
    "        return x / self.estimator.inv_c\n",
    "\n",
    "class NewPipeline (Pipeline):\n",
    "    \n",
    "    def __init__ (self, **kwargs):\n",
    "        super().__init__ (**kwargs)\n",
    "        \n",
    "        # custom transform\n",
    "        self.tr1 = Transform1(**kwargs) \n",
    "        \n",
    "        # slklearn transform\n",
    "        self.tr2 = PickleSaverComponent(StandardScaler(), **kwargs)\n",
    "        \n",
    "    def _fit (self, X, y=None):\n",
    "        self.tr1.fit (X)\n",
    "        self.tr2.fit (X)\n",
    "\n",
    "# remove any previously stored files\n",
    "remove_previous_results (path_results='results')\n",
    "\n",
    "pipeline = NewPipeline(path_results='results', save_test_result=False)\n",
    "pipeline.fit (np.array([3,4,5]).reshape(-1,1))\n",
    "result1 = pipeline.transform (np.array([300,400,500]).reshape(-1,1))\n",
    "print (pipeline.tr2.estimator.mean_)\n",
    "\n",
    "del pipeline \n",
    "pipeline = NewPipeline(path_results='results', save_test_result=False)\n",
    "pipeline.load_estimator ()\n",
    "print (pipeline.tr2.estimator.mean_)\n",
    "result2 = pipeline.transform (np.array([300,400,500]).reshape(-1,1))\n",
    "\n",
    "np.testing.assert_array_equal (result1, result2)\n",
    "\n",
    "# remove stored files resulting from running the current test\n",
    "remove_previous_results (path_results='results')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97eaf554",
   "metadata": {},
   "source": [
    "#### make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d1e7e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def make_pipeline(*components, cls=Pipeline, **kwargs):\n",
    "    \"\"\"Create `Pipeline` object of class `cls`, given `components` list.\"\"\"\n",
    "    pipeline = cls (**kwargs)\n",
    "    pipeline.components = list(components)\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6119040d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "applying pipeline transform\n",
      "applying function_transformer transform\n",
      "applying function_transformer transform\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "tr1 = Component(FunctionTransformer (lambda x: x+1))\n",
    "tr2 = Component(FunctionTransformer (lambda x: x*2))\n",
    "pipeline = make_pipeline (tr1, tr2)\n",
    "result = pipeline.transform (3)\n",
    "\n",
    "print (result)\n",
    "assert result == 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "132ca31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def pipeline_factory (pipeline_class, **kwargs):\n",
    "    \"\"\"Creates a pipeline object given its class `pipeline_class`\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    pipeline_class : class or str\n",
    "        Name of the pipeline class used for creating the object. \n",
    "        This can be either of type string or class.\n",
    "    \"\"\"\n",
    "    if type(pipeline_class) is str:\n",
    "        Pipeline = eval(pipeline_class)\n",
    "    elif type(pipeline_class) is type:\n",
    "        Pipeline = pipeline_class\n",
    "    else:\n",
    "        raise ValueError (f'pipeline_class needs to be either string or class, we got {pipeline_class}')\n",
    "\n",
    "    return Pipeline (**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a0ab14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class PandasPipeline (Pipeline):\n",
    "    \"\"\"\n",
    "    Pipeline that saves results in parquet format, and preserves DataFrame format.\n",
    "    \n",
    "    See `Pipeline` class for an explanation of using `separate_labels=False`\n",
    "    \"\"\"\n",
    "    def __init__ (self, \n",
    "                  data_converter=None,\n",
    "                  data_io=None,\n",
    "                  separate_labels=False,\n",
    "                  **kwargs):\n",
    "        if data_converter is None:\n",
    "            data_converter = PandasConverter (separate_labels=separate_labels,\n",
    "                                              **kwargs)\n",
    "        if data_io is None:\n",
    "            data_io = PandasIO (**kwargs)\n",
    "        super().__init__ (self, \n",
    "                          data_converter=data_converter,\n",
    "                          data_io=data_io,\n",
    "                          **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3548404e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ColumnSelector (Component):\n",
    "    def __init__ (self, \n",
    "                  columns=[],\n",
    "                  **kwargs):\n",
    "        super().__init__ (**kwargs)\n",
    "        self.columns = columns\n",
    "    \n",
    "    def _apply (self, df):\n",
    "        return df[self.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a85176fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "applying column_selector transform\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame ({'x1': list(range(5)),\n",
    "                    'x2': list(range(5,10)),\n",
    "                    'x3': list(range(15,20)),\n",
    "                    'x4': list(range(25,30))\n",
    "                   })\n",
    "dfr = ColumnSelector(columns=['x2','x4']).transform(df)\n",
    "assert (dfr==df[['x2','x4']]).all().all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1d44877c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Concat (Component):\n",
    "    def __init__ (self, \n",
    "                  **kwargs):\n",
    "        super().__init__ (**kwargs)\n",
    "        \n",
    "    def _apply (self, *dfs):\n",
    "        return pd.concat(list(dfs), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c8dffe69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class _BaseColumnTransformer (MultiComponent):\n",
    "    def __init__ (self, **kwargs):\n",
    "        super().__init__ (**kwargs)\n",
    "        self.concat = Concat (**kwargs)\n",
    "    \n",
    "    def _fit (self, df, y=None):\n",
    "        for component in self.components:\n",
    "            component.fit (df)\n",
    "        return self\n",
    "    \n",
    "    def _apply (self, df):\n",
    "        dfs = []\n",
    "        for component in self.components:\n",
    "            dfs.append (component.transform (df))\n",
    "        df_result = self.concat.transform (*dfs)\n",
    "        return df_result\n",
    "    \n",
    "class ColumnTransformer (_BaseColumnTransformer):\n",
    "    def __init__ (self, *transformers, **kwargs):\n",
    "        self.components = make_column_transformer_pipelines (*transformers, **kwargs)\n",
    "        super().__init__ (**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "86956ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class Identity (Component):\n",
    "    def __init__ (self, **kwargs):\n",
    "        super ().__init__ (**kwargs)\n",
    "        \n",
    "    def _apply (self, X):\n",
    "        return X\n",
    "    \n",
    "def make_column_transformer_pipelines (*transformers, **kwargs):\n",
    "    pipelines = []\n",
    "    for name, transformer, columns in transformers:\n",
    "        if (type(transformer) is str) and transformer == 'passthrough':\n",
    "            transformer = Identity (**kwargs)\n",
    "        pipeline = make_pipeline(ColumnSelector(columns, **kwargs), \n",
    "                                 transformer, \n",
    "                                 name = name,\n",
    "                                 **kwargs)\n",
    "        pipelines.append (pipeline)\n",
    "    \n",
    "    return pipelines\n",
    "\n",
    "\n",
    "def make_column_transformer (*transformers, **kwargs):\n",
    "    transformers_with_name = []\n",
    "    for transformer, columns in transformers:\n",
    "        columns_name = ''.join([x[0] for x in columns])\n",
    "        if len(columns_name) > 5:\n",
    "            columns_name = columns_name[:5]\n",
    "        if (type(transformer) is str) and transformer == 'passthrough':\n",
    "            transformer_name = 'pass'\n",
    "        elif hasattr(transformer, 'name'):\n",
    "            transformer_name = transformer.name\n",
    "        else:\n",
    "            transformer_name = transformer.__class__.__name__\n",
    "        name = f'{transformer_name}_{columns_name}'\n",
    "        transformers_with_name.append ((name, transformer, columns))\n",
    "    \n",
    "    pipelines = make_column_transformer_pipelines (*transformers_with_name, **kwargs)\n",
    "    column_transformer = _BaseColumnTransformer ()\n",
    "    column_transformer.components = pipelines\n",
    "    return column_transformer\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4ee1d33c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "applying __base_column_transformer transform\n",
      "applying tr1_cc transform\n",
      "applying column_selector transform\n",
      "applying tr1 transform\n",
      "applying tr2_cc transform\n",
      "applying column_selector transform\n",
      "applying tr2 transform\n",
      "applying concat transform\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cont2</th>\n",
       "      <th>cont4</th>\n",
       "      <th>cont2_bis</th>\n",
       "      <th>cat_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>27</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>28</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>29</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cont2  cont4  cont2_bis  cat_1\n",
       "0      6     26         10      2\n",
       "1      7     27         12      4\n",
       "2      8     28         14      6\n",
       "3      9     29         16      4\n",
       "4     10     30         18      2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "applying tr1 transform\n",
      "applying tr2 transform\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "df = pd.DataFrame ({'cont1': list(range(5)),\n",
    "                    'cont2': list(range(5,10)),\n",
    "                    'cont3': list(range(15,20)),\n",
    "                    'cont4': list(range(25,30)),\n",
    "                    'cat_1': list([1,2,3,2,1]),\n",
    "                    'cat_2': list([0,1,1,0,0])\n",
    "                    })\n",
    "\n",
    "tr1 = Component(FunctionTransformer (lambda x: x+1), name='tr1')\n",
    "tr2 = PandasComponent(FunctionTransformer (lambda x: x*2), transformed_columns=['cont2_bis','cat_1'], name='tr2')\n",
    "\n",
    "column_transformer = make_column_transformer (\n",
    "    (tr1, ['cont2', 'cont4']),\n",
    "    (tr2, ['cont2', 'cat_1'])\n",
    ")\n",
    "dfr = column_transformer.transform(df)\n",
    "\n",
    "# display and test\n",
    "display(dfr)\n",
    "assert (dfr[['cont2','cont4']] == tr1(df[['cont2','cont4']])).all().all()\n",
    "assert (dfr[['cont2_bis','cat_1']] == tr2(df[['cont2','cat_1']])).all().all()\n",
    "assert (dfr.columns == ['cont2','cont4', 'cont2_bis','cat_1']).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7d988280",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "applying __base_column_transformer transform\n",
      "applying tr1_cc transform\n",
      "applying column_selector transform\n",
      "applying tr1 transform\n",
      "applying pass_cc transform\n",
      "applying column_selector transform\n",
      "applying identity transform\n",
      "applying concat transform\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cont1</th>\n",
       "      <th>cont4</th>\n",
       "      <th>cont2</th>\n",
       "      <th>cat_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cont1  cont4  cont2  cat_1\n",
       "0      1     26      5      1\n",
       "1      2     27      6      2\n",
       "2      3     28      7      3\n",
       "3      4     29      8      2\n",
       "4      5     30      9      1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "applying tr1 transform\n"
     ]
    }
   ],
   "source": [
    "column_transformer = make_column_transformer (\n",
    "    (tr1, ['cont1', 'cont4']),\n",
    "    ('passthrough', ['cont2', 'cat_1'])\n",
    ")\n",
    "dfr = column_transformer.transform(df)\n",
    "\n",
    "# display and test\n",
    "display(dfr)\n",
    "assert (dfr[['cont1','cont4']] == tr1(df[['cont1','cont4']])).all().all()\n",
    "assert (dfr[['cont2','cat_1']] == df[['cont2','cat_1']]).all().all()\n",
    "assert (dfr.columns == ['cont1','cont4', 'cont2','cat_1']).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d50b6b30",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fitting __base_column_transformer\n",
      "fitting sum_times100_cc\n",
      "fitting column_selector\n",
      "applying column_selector transform\n",
      "fitting sum_times100\n",
      "fitting tr2_cc\n",
      "fitting column_selector\n",
      "applying column_selector transform\n",
      "fitting tr2\n",
      "applying __base_column_transformer transform\n",
      "applying sum_times100_cc transform\n",
      "applying column_selector transform\n",
      "applying sum_times100 transform\n",
      "applying tr2_cc transform\n",
      "applying column_selector transform\n",
      "applying tr2 transform\n",
      "applying concat transform\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c1_times100</th>\n",
       "      <th>c2_times100</th>\n",
       "      <th>c2_times1000</th>\n",
       "      <th>cont2</th>\n",
       "      <th>cat_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3505</td>\n",
       "      <td>13525</td>\n",
       "      <td>135025</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3506</td>\n",
       "      <td>13526</td>\n",
       "      <td>135026</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3507</td>\n",
       "      <td>13527</td>\n",
       "      <td>135027</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3508</td>\n",
       "      <td>13528</td>\n",
       "      <td>135028</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3509</td>\n",
       "      <td>13529</td>\n",
       "      <td>135029</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   c1_times100  c2_times100  c2_times1000  cont2  cat_1\n",
       "0         3505        13525        135025     10      2\n",
       "1         3506        13526        135026     12      4\n",
       "2         3507        13527        135027     14      6\n",
       "3         3508        13528        135028     16      4\n",
       "4         3509        13529        135029     18      2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class SumTimes100 (Component):\n",
    "    def _fit (self, X, y=None):\n",
    "        self.sum = X.sum(axis=0)\n",
    "    def _apply (self, X):\n",
    "        \n",
    "        dfr = pd.DataFrame ({'c1_times100': self.sum.values[0]*100 + X.iloc[:,0].values,\n",
    "                             'c2_times100': self.sum.values[1]*100 + X.iloc[:,1].values,\n",
    "                             'c2_times1000': self.sum.values[1]*1000 + X.iloc[:,1].values})\n",
    "        return dfr\n",
    "        \n",
    "tr1 = SumTimes100 ()\n",
    "tr2 = PandasComponent(FunctionTransformer (lambda x: x*2), name='tr2')\n",
    "\n",
    "column_transformer = make_column_transformer (\n",
    "    (tr1, ['cont2', 'cont4']),\n",
    "    (tr2, ['cont2', 'cat_1'])\n",
    ")\n",
    "dfr = column_transformer.fit_transform(df)\n",
    "\n",
    "# display & test\n",
    "display(dfr)\n",
    "assert (dfr.columns == ['c1_times100','c2_times100', 'c2_times1000','cont2', 'cat_1']).all()\n",
    "assert (dfr['c1_times100'] == sum(df.cont2)*100+df.cont2).all()\n",
    "assert (dfr['c2_times100'] == sum(df.cont4)*100+df.cont4).all()\n",
    "assert (dfr['c2_times1000'] == sum(df.cont4)*1000+df.cont4).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9153fe95",
   "metadata": {},
   "source": [
    "## MultiSplitComponent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce81fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class MultiSplitComponent (MultiComponent):\n",
    "    def __init__ (self, \n",
    "                  component=None, \n",
    "                  fit_training_split = 'training_data',\n",
    "                  fit_additional_splits = [],\n",
    "                  fit_additional_split_names = None,\n",
    "                  apply_to_splits = ['training_data', 'validation_data', 'test_data'],\n",
    "                  **kwargs):\n",
    "        super().__init__ (**kwargs)\n",
    "        if component is not None:\n",
    "            self.set_components (component)\n",
    "            self.component = component\n",
    "        \n",
    "        self.fit_training_split = fit_training_split\n",
    "        self.fit_additional_splits = fit_additional_splits\n",
    "        \n",
    "        # the following is needed in case the input data is a tuple instead of a dictionary\n",
    "        # in such case, fit_additional_splits should be a list of integer indices (to index the tuple) \n",
    "        # and fit_additional_split_names should be a list of string names (to index a dictionary)\n",
    "        # valid names are 'validation_data' and 'test_data'\n",
    "        self.fit_additional_split_names = (fit_additional_split_names if fit_additional_split_names is not None\n",
    "                                           else fit_additional_splits)\n",
    "        \n",
    "        self.apply_to_splits = apply_to_splits\n",
    "    \n",
    "    def _fit (self, X, y=None):\n",
    "        component = self.components[0]\n",
    "        additional_data = {}\n",
    "        for split, split_name in zip(self.fit_additional_splits, self.fit_additional_split_names):\n",
    "            additional_data[split_name] = X[split]\n",
    "            if split_name not in ['validation_data', 'test_data']:\n",
    "                raise ValueError (f'split {split_name} not valid')\n",
    "        \n",
    "        component.fit(X[self.fit_training_split], y=y, **additional_data)\n",
    "    \n",
    "    def _apply (self, X, **kwargs):\n",
    "        component = self.components[0]\n",
    "        result = {}\n",
    "        for split in self.apply_to_splits:\n",
    "            result[split] = component.apply (X[split], **kwargs)\n",
    "        if type(X) is tuple:\n",
    "            result = tuple(result.values())\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43277043",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1, 2], [3, 3])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'a':[1,2], 'b':[3,3]}\n",
    "\n",
    "tuple(d.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42953c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (block_types)",
   "language": "python",
   "name": "block_types"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
