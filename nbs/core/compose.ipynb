{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccd85e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "# default_exp core.compose\n",
    "from nbdev.showdoc import *\n",
    "from block_types.utils.nbdev_utils import nbdev_setup, TestRunner\n",
    "\n",
    "nbdev_setup ()\n",
    "tst = TestRunner (targets=['dummy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434bfb86",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Compose components\n",
    "\n",
    "> Classes and utilities for composed components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44f392e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export\n",
    "import warnings\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from sklearn.utils import Bunch\n",
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    from graphviz import *\n",
    "    imported_graphviz = True\n",
    "except:\n",
    "    imported_graphviz = False\n",
    "\n",
    "from block_types.core.block_types import (Component, \n",
    "                                          PandasComponent, \n",
    "                                          SamplingComponent,\n",
    "                                          NoSaverComponent)\n",
    "from block_types.core.data_conversion import PandasConverter\n",
    "from block_types.core.utils import PandasIO\n",
    "from block_types.utils.utils import get_logging_level, set_empty_logger\n",
    "import block_types.config.bt_defaults as dflt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2082f19d-a4df-45c7-bb19-92a48af413a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for tests\n",
    "from pathlib import Path\n",
    "import pytest \n",
    "import time\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import Bunch\n",
    "\n",
    "from block_types.core.block_types import PickleSaverComponent\n",
    "from block_types.utils.utils import remove_previous_results, set_empty_logger\n",
    "from block_types.core.utils import PickleIO\n",
    "from block_types.utils.utils import check_last_part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3407acbd-4b31-453b-ab5e-3a07aa1001c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for tests\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571bbae6-9f63-4b84-8813-a45a58c1215e",
   "metadata": {},
   "source": [
    "## MultiComponent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ca1edc7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export\n",
    "class MultiComponent (SamplingComponent):\n",
    "    \"\"\"\n",
    "    Component containing a list of components inside.\n",
    "    \n",
    "    The list must contain at least one component. \n",
    "    \n",
    "    See `Pipeline` class.\n",
    "    \"\"\"\n",
    "    def __init__ (self, \n",
    "                  *components,\n",
    "                  separate_labels=dflt.separate_labels, \n",
    "                  warning_if_nick_name_exists=dflt.warning_if_nick_name_exists,\n",
    "                  propagate=dflt.propagate,\n",
    "                  path_results=dflt.path_results,\n",
    "                  path_models=dflt.path_models,\n",
    "                  **kwargs):\n",
    "        \"\"\"Assigns attributes and calls parent constructor.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        separate_labels: bool, optional\n",
    "            whether or not the fit method receives the labels in a separate `y` vector \n",
    "            or in the same input `X`, as an additional variable. See description of \n",
    "            Pipeline class for more details.\n",
    "        \"\"\"\n",
    "        if 'estimator' in kwargs:\n",
    "            self.logger.warning ('estimator passed as key-word argument in MultiComponent')\n",
    "        \n",
    "        self.warning_if_nick_name_exists = warning_if_nick_name_exists\n",
    "        \n",
    "        if len(components) > 0:\n",
    "            self.set_components (*components)\n",
    "        elif not hasattr (self, 'components'):\n",
    "            self.components = []\n",
    "        if not hasattr (self, 'finalized_component_list'):\n",
    "            self.finalized_component_list = False\n",
    "        \n",
    "        \n",
    "        # we need to call super().__init__() *after* having creating the `components` field,\n",
    "        # since the constructor of Component calls a method that is overriden in Pipeline, \n",
    "        # and this method makes use of the mentioned `components` field\n",
    "        super().__init__ (separate_labels=separate_labels, path_results=path_results, path_models=path_models,\n",
    "                          **kwargs)\n",
    "\n",
    "        self.set_split ('whole')\n",
    "        \n",
    "        self.chain_folders (self.data_io.folder)\n",
    "        if self.propagate: \n",
    "            self.set_path_results (self.path_results)\n",
    "            self.set_path_models (self.path_models)\n",
    "        \n",
    "        self.start_idx = dict (apply = dict (training=0, validation=0, test=0, whole=0),\n",
    "                               fit = dict (training=0, validation=0, test=0, whole=0))\n",
    "        self.is_data_source = dict (apply = dict (training=False, validation=False, test=False, whole=False),\n",
    "                               fit = dict (training=False, validation=False, test=False, whole=False))\n",
    "        \n",
    "    \n",
    "    def register_components (self, *components):\n",
    "        \"\"\"\n",
    "        Registering component in `self.components` list.\n",
    "        \n",
    "        Every time that a new component is set as an attribute of the pipeline,\n",
    "        this component is added to the list `self.components`. Same \n",
    "        mechanism as the one used by pytorch's `nn.Module`\n",
    "        \"\"\"\n",
    "        if not hasattr(self, 'components'):\n",
    "            self.components = []\n",
    "            self.finalized_component_list = False\n",
    "        if not self.finalized_component_list:\n",
    "            self.components += components\n",
    "            \n",
    "    def _add_named_attribute (self, component, nick_name):\n",
    "        if not hasattr(self, 'finalized_component_list'):\n",
    "            self.finalized_component_list = False\n",
    "        if not hasattr(self, component.name):\n",
    "            super().__setattr__(component.name, component)\n",
    "        if not self.finalized_component_list:\n",
    "            if hasattr(component, 'nick_name') and self.warning_if_nick_name_exists:\n",
    "                self.logger.warning (f'{component} already has a nick_name: {component.nick_name}')\n",
    "                warnings.warn (f'{component} already has a nick_name: {component.nick_name}')\n",
    "            component.nick_name = nick_name\n",
    "    \n",
    "    def __setattr__(self, k, v):\n",
    "        \"\"\"\n",
    "        See register_components\n",
    "        \"\"\"\n",
    "        super().__setattr__(k, v)\n",
    "        \n",
    "        if isinstance(v, Component):\n",
    "            self.register_components(v)\n",
    "            self._add_named_attribute (v, k)\n",
    "            \n",
    "    def add_component (self, component):\n",
    "        if not hasattr(self, 'finalized_component_list'):\n",
    "            self.finalized_component_list = False\n",
    "        finalized_component_list = self.finalized_component_list\n",
    "        self.finalized_component_list = False\n",
    "        self.register_components(component)\n",
    "        self._add_named_attribute (component, component.name)\n",
    "        self.finalized_component_list = finalized_component_list\n",
    "        \n",
    "    def set_components (self, *components):\n",
    "        self.components = components\n",
    "        for component in components:\n",
    "            self._add_named_attribute (component, component.name)\n",
    "        self.finalized_component_list = True\n",
    "        \n",
    "    def clear_descendants (self):\n",
    "        self.cls = Bunch ()\n",
    "        self.obj = Bunch ()\n",
    "        self.full_obj = Bunch ()\n",
    "        self.full_cls = Bunch ()\n",
    "        for component in self.components:\n",
    "            if isinstance(component, MultiComponent):\n",
    "                component.clear_descendants ()\n",
    "            \n",
    "    def gather_descendants (self, root='', nick_name=True):\n",
    "        if not hasattr (self, 'cls'):\n",
    "            self.cls = Bunch ()\n",
    "            self.obj = Bunch ()\n",
    "            self.full_obj = Bunch ()\n",
    "            self.full_cls = Bunch ()\n",
    "            \n",
    "        if hasattr(self, 'nick_name'):\n",
    "            name = self.nick_name if nick_name else self.name\n",
    "        else:\n",
    "            name = self.name\n",
    "        self.hierarchy_path = f'{root}{name}'\n",
    "        for component in self.components:\n",
    "            self._insert_descendant (self.cls, component, component.class_name)\n",
    "            self._insert_descendant (self.obj, component, component.name)\n",
    "            \n",
    "            name = component.nick_name if nick_name else component.name\n",
    "            component_hierarchy_path = f'{self.hierarchy_path}.{name}'\n",
    "            self._insert_descendant (self.full_cls, component_hierarchy_path, component.class_name)\n",
    "            self._insert_descendant (self.full_obj, component_hierarchy_path, component.name)\n",
    "            if isinstance(component, MultiComponent):\n",
    "                component.gather_descendants (root=f'{self.hierarchy_path}.',\n",
    "                                              nick_name=nick_name)\n",
    "                for name in component.cls:\n",
    "                    self._insert_descendant (self.cls, component.cls[name], name)\n",
    "                    self._insert_descendant (self.full_cls, component.full_cls[name], name)\n",
    "                for name in component.obj:\n",
    "                    self._insert_descendant (self.obj, component.obj[name], name)\n",
    "                    self._insert_descendant (self.full_obj, component.full_obj[name], name)\n",
    "                           \n",
    "    def _insert_descendant (self, cmp_dict, component, name):\n",
    "        if name in cmp_dict:\n",
    "            if not isinstance(cmp_dict[name], list):\n",
    "                cmp_dict[name] = [cmp_dict[name]]\n",
    "            if isinstance(component, list):\n",
    "                cmp_dict[name].extend(component)\n",
    "            else:\n",
    "                cmp_dict[name].append(component)\n",
    "        else:\n",
    "            if isinstance(component, list):\n",
    "                cmp_dict[name] = component.copy()\n",
    "            else:\n",
    "                cmp_dict[name] = component\n",
    "                \n",
    "    def gather_times (self):\n",
    "        dfs = [self.profiler.retrieve_times ()]\n",
    "        for component in self.components:\n",
    "            if isinstance(component, MultiComponent):\n",
    "                dfs.append(component.gather_times ())\n",
    "            else:\n",
    "                dfs.append(component.profiler.retrieve_times (is_leaf=True))\n",
    "        dfs = self.profiler.combine_times (dfs)\n",
    "        return dfs\n",
    "        \n",
    "    def construct_diagram (self, split=None, include_url=False, port=4000, project='block_types'):\n",
    "        \"\"\"\n",
    "        Construct diagram of the pipeline components, data flow and dimensionality.\n",
    "        \n",
    "        By default, we use test data to show the number of observations \n",
    "        in the output of each component. This can be changed passing \n",
    "        `split='train'`\n",
    "        \"\"\"\n",
    "        split = self.get_split (split)\n",
    "\n",
    "        if include_url:\n",
    "            base_url = f'http://localhost:{port}/{project}'\n",
    "        else:\n",
    "            URL = ''\n",
    "\n",
    "        node_name = 'data'\n",
    "        output = 'train / test'\n",
    "\n",
    "        f = Digraph('G', filename='fsm2.svg')\n",
    "        f.attr('node', shape='circle')\n",
    "\n",
    "        f.node(node_name)\n",
    "\n",
    "        f.attr('node', shape='box')\n",
    "        for component in self.components:\n",
    "            last_node_name = node_name\n",
    "            last_output = output\n",
    "            node_name = component.model_plotter.get_node_name()\n",
    "            if include_url:\n",
    "                URL = f'{base_url}/{component.model_plotter.get_module_path()}.html#{node_name}'\n",
    "            f.node(node_name, URL=URL)\n",
    "            f.edge(last_node_name, node_name, label=last_output)\n",
    "            output = component.model_plotter.get_edge_name(split=split)\n",
    "\n",
    "        last_node_name = node_name\n",
    "        node_name = 'output'\n",
    "        f.attr('node', shape='circle')\n",
    "        f.edge(last_node_name, node_name, label=output)\n",
    "\n",
    "        return f\n",
    "\n",
    "    def show_result_statistics (self, split=None):\n",
    "        \"\"\"\n",
    "        Show statistics about results obtained by each component. \n",
    "        \n",
    "        By default, this is shown on test data, although this can change setting \n",
    "        `split='train'`\n",
    "        \"\"\"\n",
    "        split = self.get_split (split)\n",
    "\n",
    "        for component in self.components:\n",
    "            component.show_result_statistics(split=split)\n",
    "\n",
    "    def show_summary (self, split=None, file=sys.stdout):\n",
    "        \"\"\"\n",
    "        Show list of pipeline components, data flow and dimensionality.\n",
    "        \n",
    "        By default, we use test data to show the number of observations \n",
    "        in the output of each component. This can be changed passing \n",
    "        `split='train'`\n",
    "        \"\"\"\n",
    "        split = self.get_split (split)\n",
    "\n",
    "        node_name = 'data'\n",
    "        output = 'train / test'\n",
    "        if isinstance (file, str) or isinstance (file, Path): file = open (file, 'wt')\n",
    "\n",
    "        for i, component in enumerate(self.components):\n",
    "            node_name = component.model_plotter.get_node_name()\n",
    "            output = component.model_plotter.get_edge_name(split=split)\n",
    "            print (f'{\"-\"*100}', file=file)\n",
    "            print (f'{i}: {node_name} => {output}', file=file)\n",
    "\n",
    "\n",
    "    def get_split (self, split=None):\n",
    "        if split is None:\n",
    "            if self.data_io.split is not None:\n",
    "                split = self.data_io.split\n",
    "            else:\n",
    "                split = 'whole'\n",
    "\n",
    "        return split\n",
    "\n",
    "    def assert_all_equal (self, path_reference_results, raise_error=False, recursive=True, \n",
    "                          max_recursion=None, current_recursion=0, verbose=None, **kwargs):\n",
    "        \"\"\"Compare results stored in current run against reference results stored in given path.\"\"\"\n",
    "        if verbose is not None:\n",
    "            self.logger.setLevel(get_logging_level (verbose))\n",
    "        is_equal = True\n",
    "        non_equal_components = []\n",
    "        end_recursion = max_recursion is not None and current_recursion >= max_recursion\n",
    "        components = self.components if not end_recursion else [self]\n",
    "        for component in components:\n",
    "            if isinstance(component, MultiComponent) and recursive and not end_recursion:\n",
    "                this_equal = component.assert_all_equal (path_reference_results, \n",
    "                                                         raise_error=raise_error, \n",
    "                                                         recursive=recursive, \n",
    "                                                         max_recursion=max_recursion,\n",
    "                                                         current_recursion=current_recursion+1,\n",
    "                                                         verbose=verbose,\n",
    "                                                         **kwargs) \n",
    "            else:\n",
    "                this_equal = component.assert_equal (path_reference_results, \n",
    "                                                     raise_error=raise_error,\n",
    "                                                     verbose=verbose,\n",
    "                                                     **kwargs) \n",
    "            if not this_equal:\n",
    "                non_equal_components.append(component.name)\n",
    "            is_equal = this_equal and is_equal\n",
    "            \n",
    "        if not is_equal:\n",
    "            self.logger.warning (f'Results are different in components {non_equal_components}')\n",
    "        else:\n",
    "            self.logger.info ('both pipelines give the same results')\n",
    "        \n",
    "        self.logger.setLevel(get_logging_level (self.verbose))\n",
    "        \n",
    "        return is_equal\n",
    "        \n",
    "    def load_estimator (self):\n",
    "        for component in self.components:\n",
    "            component.load_estimator ()\n",
    "            \n",
    "    def save_result (self, result, split=None, path_results=None, result_file_name=None):\n",
    "        raise NotImplementedError ()\n",
    "        self.data_io.save_result (result, split=split, path_results=path_results, \n",
    "                                  result_file_name=result_file_name)\n",
    "        for component in self.components:\n",
    "            if isinstance (component, MultiComponent):\n",
    "                component.save_result (result, split=split, path_results=path_results, \n",
    "                                       result_file_name=result_file_name)\n",
    "            else:\n",
    "                component.data_io.save_result (result, split=split, path_results=path_results, \n",
    "                                               result_file_name=result_file_name)\n",
    "    # *************************\n",
    "    # setters\n",
    "    # *************************\n",
    "    def set_split (self, split):\n",
    "        super().set_split (split)\n",
    "        for component in self.components:\n",
    "            component.set_split (split)\n",
    "\n",
    "    def set_save_splits (self, save_splits):\n",
    "        super().set_save_splits (save_splits)\n",
    "        for component in self.components:\n",
    "            component.set_save_splits (save_splits)\n",
    "            \n",
    "    def set_load_model (self, load_model):\n",
    "        super().set_load_model (load_model)\n",
    "        for component in self.components:\n",
    "            component.set_load_model (load_model)\n",
    "\n",
    "    def set_save_model (self, save_model):\n",
    "        super().set_save_model (save_model)\n",
    "        for component in self.components:\n",
    "            component.set_save_model (save_model)\n",
    "            \n",
    "    def set_save_result (self, save_result):\n",
    "        super().set_save_result (save_result)\n",
    "        for component in self.components:\n",
    "            component.set_save_result (save_result)\n",
    "            \n",
    "    def set_load_result (self, load_result):\n",
    "        super().set_load_result (load_result)\n",
    "        for component in self.components:\n",
    "            component.set_load_result (load_result)\n",
    "            \n",
    "    def set_path_results (self, path_results):\n",
    "        self.data_io.set_path_results (path_results)\n",
    "        for component in self.components:\n",
    "            if not component.data_io.stop_propagation:\n",
    "                if isinstance (component, MultiComponent):\n",
    "                    component.set_path_results (path_results)\n",
    "                else:\n",
    "                    component.data_io.set_path_results (path_results)\n",
    "    def set_path_models (self, path_models):\n",
    "        self.data_io.set_path_models (path_models)\n",
    "        for component in self.components:\n",
    "            if isinstance (component, MultiComponent):\n",
    "                component.set_path_models (path_models)\n",
    "            else:\n",
    "                component.data_io.set_path_models (path_models)\n",
    "    def chain_folders (self, folder, root=True):\n",
    "        if folder == '':\n",
    "            return\n",
    "        if root:\n",
    "            self.data_io.chain_folders ('')\n",
    "        else:\n",
    "            self.data_io.chain_folders (folder)\n",
    "        for component in self.components:\n",
    "            if isinstance (component, MultiComponent):\n",
    "                component.chain_folders (folder, root=False)\n",
    "            else:\n",
    "                component.data_io.chain_folders (folder)\n",
    "    \n",
    "    def find_last_result (self, split=None):\n",
    "        return False\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aedce8a4-be52-4e77-8069-f67c4f215ca6",
   "metadata": {},
   "source": [
    "### Usage examples / tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9c3340-3525-4afa-b683-bdfee9eae593",
   "metadata": {},
   "source": [
    "#### MultiComponent example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "446961c9-fdb7-427f-a3df-fa118c7664e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports tests.core.test_compose\n",
    "class SimpleMultiComponent (MultiComponent):\n",
    "    def __init__ (self, **kwargs):\n",
    "        data_io = PickleIO (**kwargs)\n",
    "        super().__init__(data_io=data_io,\n",
    "                         **kwargs)\n",
    "\n",
    "        self.tr1 = Component(FunctionTransformer (lambda x: x*3),\n",
    "                             data_io=data_io,\n",
    "                             name='tr1')\n",
    "        self.tr2 = Component(FunctionTransformer (lambda x: x*2),\n",
    "                             data_io=data_io,\n",
    "                             name='tr2')\n",
    "\n",
    "    def _apply (self, X):\n",
    "        return self.tr1 (X) + self.tr2(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3771790d",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Loading / saving all results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "295af9e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# exports tests.core.test_compose\n",
    "#@pytest.mark.reference_fails\n",
    "def test_multi_comp_io ():\n",
    "    path_results = 'multi_component_loading_saving'\n",
    "    remove_previous_results (path_results=path_results)\n",
    "\n",
    "    X = np.array([1,2,3])\n",
    "    composition1 = SimpleMultiComponent (path_results=path_results)\n",
    "    result1 = composition1 (X)\n",
    "\n",
    "    composition2 = SimpleMultiComponent (path_results=path_results)\n",
    "    result2 = composition2.data_io.load_result()\n",
    "    assert (result1==result2).all()\n",
    "\n",
    "    resut_tr1_2 = composition2.tr1.data_io.load_result()\n",
    "    resut_tr2_2 = composition2.tr2.data_io.load_result()\n",
    "    assert (resut_tr1_2==composition1.tr1(X)).all()\n",
    "    assert (resut_tr2_2==composition1.tr2(X)).all()\n",
    "\n",
    "    assert sorted(os.listdir (f'{path_results}/whole'))==['simple_multi_component_result.pk', 'tr1_result.pk', 'tr2_result.pk']\n",
    "\n",
    "    composition1.set_split ('validation')\n",
    "    result1b = composition1 (X)\n",
    "    assert sorted(os.listdir (f'{path_results}/validation'))==['simple_multi_component_result.pk', 'tr1_result.pk', 'tr2_result.pk']\n",
    "\n",
    "    remove_previous_results (path_results=f'{path_results}/whole')\n",
    "\n",
    "    resut_tr1_2 = composition2.tr1.data_io.load_result(split='validation')\n",
    "    resut_tr2_2 = composition2.tr2.data_io.load_result()\n",
    "\n",
    "    assert (resut_tr1_2==composition1.tr1(X)).all()\n",
    "    assert resut_tr2_2 is None\n",
    "\n",
    "    composition2.set_split('validation')\n",
    "    resut_tr1_2 = composition2.tr1.data_io.load_result()\n",
    "    resut_tr2_2 = composition2.tr2.data_io.load_result()\n",
    "\n",
    "    assert (resut_tr1_2==composition1.tr1(X)).all()\n",
    "    assert (resut_tr2_2==composition1.tr2(X)).all()\n",
    "\n",
    "    remove_previous_results (path_results=path_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "724f1765-3171-4a48-9c4a-88f4a3c1bb14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test_multi_comp_io\n"
     ]
    }
   ],
   "source": [
    "tst.run (test_multi_comp_io, tag='dummy', debug=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9752e6-d651-448c-9a23-be5b72b49542",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Getting descendants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a90946e-0a54-4045-8f9b-b44a6ece72fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports tests.core.test_compose\n",
    "#@pytest.mark.reference_fails\n",
    "def test_multi_comp_desc ():\n",
    "    class Intermediate (MultiComponent):\n",
    "        def __init__ (self, name=None, **kwargs):\n",
    "            super().__init__ (name=name, **kwargs)\n",
    "            self.first = Component (name='first_component', **kwargs)\n",
    "            self.second = Component (name='second_component', **kwargs)\n",
    "\n",
    "    class Higher (MultiComponent):\n",
    "        def __init__ (self, **kwargs):\n",
    "            super().__init__ (**kwargs)\n",
    "            self.first = Intermediate (name='first_intermediate', **kwargs)\n",
    "            self.second = Intermediate (name='second_intermediate', **kwargs)\n",
    "            self.gather_descendants(nick_name=False)\n",
    "\n",
    "    higher = Higher()\n",
    "\n",
    "    assert sorted(higher.obj.keys())==['first_component', 'first_intermediate', 'second_component', 'second_intermediate']\n",
    "\n",
    "    # check types\n",
    "    types = map(lambda x: type(x[1]), sorted(higher.obj.items()))\n",
    "    assert list(types)==[list, Intermediate, list, Intermediate]\n",
    "\n",
    "    sorted_list = list(sorted(higher.obj.items()))\n",
    "    types = map(type, sorted_list[0][1])\n",
    "    assert list(types)==[Component,Component]\n",
    "\n",
    "    sorted_list = list(sorted(higher.obj.items()))\n",
    "    types = map(type, sorted_list[2][1])\n",
    "    assert list(types)==[Component,Component]\n",
    "\n",
    "    sorted_keys=list(sorted(higher.cls.keys()))\n",
    "    assert sorted_keys == ['Component', 'Intermediate']\n",
    "\n",
    "    assert list(map(type,higher.cls[sorted_keys[0]]))==[Component, Component, Component, Component]\n",
    "\n",
    "    assert list(map(type,higher.cls[sorted_keys[1]]))==[Intermediate, Intermediate]\n",
    "\n",
    "\n",
    "    # ***********************\n",
    "    # recursive behaviour: higher.first\n",
    "    intermediate = higher.first\n",
    "    assert sorted(intermediate.obj.keys())==['first_component', 'second_component']\n",
    "\n",
    "    # check types\n",
    "    types = map(lambda x: type(x[1]), sorted(intermediate.obj.items()))\n",
    "    assert list(types)==[Component, Component]\n",
    "\n",
    "    sorted_keys=list(sorted(intermediate.cls.keys()))\n",
    "    assert sorted_keys==['Component']\n",
    "\n",
    "    assert list(map(type,intermediate.cls[sorted_keys[0]]))==[Component,Component]\n",
    "\n",
    "    # **********************************************\n",
    "    # recursive behaviour: higher.second\n",
    "    # **********************************************\n",
    "    intermediate = higher.second\n",
    "    assert sorted(intermediate.obj.keys())==['first_component', 'second_component']\n",
    "\n",
    "    # check types\n",
    "    types = map(lambda x: type(x[1]), sorted(intermediate.obj.items()))\n",
    "    assert list(types)==[Component, Component]\n",
    "\n",
    "    sorted_keys=list(sorted(intermediate.cls.keys()))\n",
    "    assert sorted_keys==['Component']\n",
    "\n",
    "    assert list(map(type,intermediate.cls[sorted_keys[0]]))==[Component,Component]\n",
    "\n",
    "    # **********************************************\n",
    "    # full hierarchical paths\n",
    "    # **********************************************\n",
    "    assert list(sorted(higher.full_cls.keys()))==['Component', 'Intermediate']\n",
    "    assert higher.full_cls['Intermediate']==['higher.first_intermediate', 'higher.second_intermediate']\n",
    "    assert higher.full_cls['Component']==['higher.first_intermediate.first_component',\n",
    "      'higher.first_intermediate.second_component',\n",
    "      'higher.second_intermediate.first_component',\n",
    "      'higher.second_intermediate.second_component']\n",
    "\n",
    "    assert higher.first.full_cls['Component']==['higher.first_intermediate.first_component',\n",
    "      'higher.first_intermediate.second_component']\n",
    "\n",
    "    assert list(sorted(higher.full_obj))==['first_component', 'first_intermediate', 'second_component', 'second_intermediate']\n",
    "\n",
    "    assert higher.full_obj['first_intermediate']=='higher.first_intermediate'\n",
    "\n",
    "    assert higher.full_obj['first_component']==['higher.first_intermediate.first_component',\n",
    "      'higher.second_intermediate.first_component']\n",
    "\n",
    "    assert higher.full_obj['second_component']==['higher.first_intermediate.second_component',\n",
    "      'higher.second_intermediate.second_component']\n",
    "\n",
    "    assert higher.full_obj['second_intermediate']=='higher.second_intermediate'\n",
    "\n",
    "    assert list(sorted(higher.second.full_obj))==['first_component', 'second_component']\n",
    "\n",
    "    assert higher.second.full_obj['first_component']=='higher.second_intermediate.first_component'\n",
    "\n",
    "    assert higher.second.full_obj['second_component']=='higher.second_intermediate.second_component'\n",
    "\n",
    "    assert higher.hierarchy_path=='higher'\n",
    "\n",
    "    assert higher.first.hierarchy_path=='higher.first_intermediate'\n",
    "\n",
    "    # with nick_names\n",
    "    higher.clear_descendants()\n",
    "    higher.gather_descendants(nick_name=True)\n",
    "\n",
    "    assert higher.full_cls['Component']==['higher.first.first',\n",
    "     'higher.first.second',\n",
    "     'higher.second.first',\n",
    "     'higher.second.second']\n",
    "\n",
    "    assert higher.full_obj['first_intermediate']=='higher.first'\n",
    "    assert higher.full_obj['first_component']==['higher.first.first', 'higher.second.first']\n",
    "    assert higher.full_obj['second_component']==['higher.first.second', 'higher.second.second']\n",
    "    assert higher.full_obj['second_intermediate']=='higher.second'\n",
    "    \n",
    "    #Check that we always have attributes for each component name\n",
    "    assert higher.first_intermediate is higher.first\n",
    "    assert higher.second_intermediate is higher.second\n",
    "    assert higher.components==[higher.first, higher.second]\n",
    "    \n",
    "    #check that set_components and add_component create self attrs called \n",
    "    # the same as the component\n",
    "    \n",
    "    class Higher (MultiComponent):\n",
    "        def __init__ (self, **kwargs):\n",
    "            super().__init__ (**kwargs)\n",
    "            self.set_components (Intermediate (name='first_intermediate', **kwargs),\n",
    "                                 Intermediate (name='second_intermediate', **kwargs))\n",
    "    higher = Higher()\n",
    "\n",
    "    assert higher.components == (higher.first_intermediate, higher.second_intermediate)\n",
    "\n",
    "    class Higher (MultiComponent):\n",
    "        def __init__ (self, **kwargs):\n",
    "            super().__init__ (**kwargs)\n",
    "            self.add_component (Intermediate (name='first_intermediate', **kwargs))\n",
    "            self.add_component (Intermediate (name='second_intermediate', **kwargs))\n",
    "    higher = Higher()\n",
    "\n",
    "    assert higher.components == [higher.first_intermediate, higher.second_intermediate]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46f37453-7406-42e4-a6c4-309c2fcd936a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test_multi_comp_desc\n"
     ]
    }
   ],
   "source": [
    "tst.run (test_multi_comp_desc, tag='dummy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64b4a043-0929-42f9-9d49-ca475b22bf28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# **********************************************\n",
    "# second example\n",
    "# **********************************************\n",
    "# exports tests.core.test_compose\n",
    "#@pytest.mark.reference_fails\n",
    "def test_athena_pipeline_training ():\n",
    "    class Intermediate (MultiComponent):\n",
    "        def __init__ (self, name=None, **kwargs):\n",
    "            super().__init__ (name=name, **kwargs)\n",
    "            self.first = Component (name=f'{name}_first_component', **kwargs)\n",
    "            self.second = Component (name=f'{name}_second_component', **kwargs)\n",
    "\n",
    "    class Higher (MultiComponent):\n",
    "        def __init__ (self, **kwargs):\n",
    "            super().__init__ (**kwargs)\n",
    "            self.first = Intermediate (name='first_intermediate', **kwargs)\n",
    "            self.second = Intermediate (name='second_intermediate', **kwargs)\n",
    "            self.gather_descendants(nick_name=False)\n",
    "\n",
    "    higher = Higher()\n",
    "\n",
    "    assert sorted(higher.obj.keys())==['first_intermediate', 'first_intermediate_first_component', 'first_intermediate_second_component', 'second_intermediate', 'second_intermediate_first_component', 'second_intermediate_second_component']\n",
    "\n",
    "    # check types\n",
    "    types = map(lambda x: type(x[1]), sorted(higher.obj.items()))\n",
    "\n",
    "    assert list(types)==[Intermediate, Component, Component, Intermediate, Component, Component]\n",
    "\n",
    "    sorted_keys=list(sorted(higher.cls.keys()))\n",
    "    assert sorted_keys == ['Component', 'Intermediate']\n",
    "\n",
    "    assert list(map(type,higher.cls[sorted_keys[0]]))==[Component, Component, Component, Component]\n",
    "    assert list(map(type,higher.cls[sorted_keys[1]]))==[Intermediate, Intermediate]\n",
    "\n",
    "    # ***********************\n",
    "    # recursive behaviour: higher.first\n",
    "    intermediate = higher.first\n",
    "    assert sorted(intermediate.obj.keys())==['first_intermediate_first_component', 'first_intermediate_second_component']\n",
    "\n",
    "    # check types\n",
    "    types = map(lambda x: type(x[1]), sorted(intermediate.obj.items()))\n",
    "    assert list(types)==[Component, Component]\n",
    "\n",
    "    sorted_keys=list(sorted(intermediate.cls.keys()))\n",
    "    assert sorted_keys==['Component']\n",
    "\n",
    "    assert list(map(type,intermediate.cls[sorted_keys[0]]))==[Component,Component]\n",
    "\n",
    "    # ***********************\n",
    "    # recursive behaviour: higher.second\n",
    "    intermediate = higher.second\n",
    "    assert sorted(intermediate.obj.keys())==['second_intermediate_first_component', 'second_intermediate_second_component']\n",
    "\n",
    "    # check types\n",
    "    types = map(lambda x: type(x[1]), sorted(intermediate.obj.items()))\n",
    "    assert list(types)==[Component, Component]\n",
    "\n",
    "    sorted_keys=list(sorted(intermediate.cls.keys()))\n",
    "    assert sorted_keys==['Component']\n",
    "\n",
    "    assert list(map(type,intermediate.cls[sorted_keys[0]]))==[Component,Component]\n",
    "\n",
    "\n",
    "    # **********************************************\n",
    "    # full hierarchical paths\n",
    "    # **********************************************\n",
    "    assert list(sorted(higher.full_cls))==['Component', 'Intermediate']\n",
    "\n",
    "    assert higher.full_cls['Component']==['higher.first_intermediate.first_intermediate_first_component',\n",
    "      'higher.first_intermediate.first_intermediate_second_component',\n",
    "      'higher.second_intermediate.second_intermediate_first_component',\n",
    "      'higher.second_intermediate.second_intermediate_second_component']\n",
    "\n",
    "    assert higher.full_cls['Intermediate']==['higher.first_intermediate', 'higher.second_intermediate']\n",
    "\n",
    "    assert list(higher.first.full_cls)==['Component']\n",
    "\n",
    "    assert higher.first.full_cls['Component']==['higher.first_intermediate.first_intermediate_first_component',\n",
    "      'higher.first_intermediate.first_intermediate_second_component']\n",
    "\n",
    "    assert sorted(list(higher.full_obj))==['first_intermediate',\n",
    "     'first_intermediate_first_component',\n",
    "     'first_intermediate_second_component',\n",
    "     'second_intermediate',\n",
    "     'second_intermediate_first_component',\n",
    "     'second_intermediate_second_component']\n",
    "\n",
    "    assert higher.full_obj['first_intermediate']=='higher.first_intermediate'\n",
    "\n",
    "    assert higher.full_obj['first_intermediate_first_component']=='higher.first_intermediate.first_intermediate_first_component'\n",
    "\n",
    "    assert higher.full_obj['first_intermediate_second_component']=='higher.first_intermediate.first_intermediate_second_component'\n",
    "\n",
    "    assert higher.full_obj['second_intermediate']=='higher.second_intermediate'\n",
    "\n",
    "    assert higher.full_obj['second_intermediate_first_component']=='higher.second_intermediate.second_intermediate_first_component'\n",
    "\n",
    "    assert higher.full_obj['second_intermediate_second_component']=='higher.second_intermediate.second_intermediate_second_component'\n",
    "\n",
    "    assert list(sorted(higher.second.full_obj))==['second_intermediate_first_component', 'second_intermediate_second_component']\n",
    "\n",
    "    assert higher.second.full_obj['second_intermediate_first_component']=='higher.second_intermediate.second_intermediate_first_component'\n",
    "\n",
    "    assert higher.second.full_obj['second_intermediate_second_component']=='higher.second_intermediate.second_intermediate_second_component'\n",
    "\n",
    "    assert higher.hierarchy_path=='higher'\n",
    "\n",
    "    assert higher.first.hierarchy_path=='higher.first_intermediate'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08a0746c-4208-407f-b678-e55e0daab499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test_athena_pipeline_training\n"
     ]
    }
   ],
   "source": [
    "tst.run (test_athena_pipeline_training, tag='dummy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ac147d-d580-4adf-91aa-6922ee440dcf",
   "metadata": {},
   "source": [
    "#### Passing parameters specific of hierarchy level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "abce6461-ba07-49e7-b435-db5e9da4c8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports tests.core.test_compose\n",
    "#@pytest.mark.reference_fails\n",
    "def test_multi_comp_hierarchy ():\n",
    "    class Intermediate (MultiComponent):\n",
    "        def __init__ (self, name=None, z=6, h=10, x=3, **kwargs):\n",
    "            super().__init__ (name=name, **kwargs)\n",
    "            self.first = Component (name='first_component', **kwargs)\n",
    "            self.second = Component (name='second_component', **kwargs)\n",
    "\n",
    "    class Higher (MultiComponent):\n",
    "        def __init__ (self, x=2, y=3, **kwargs):\n",
    "            super().__init__ (**kwargs)\n",
    "            self.first = Intermediate (name='first_intermediate', **kwargs)\n",
    "            self.second = Intermediate (name='second_intermediate', **kwargs)\n",
    "            self.gather_descendants()\n",
    "\n",
    "    higher = Higher()\n",
    "\n",
    "    levels=dict(\n",
    "        until=1,\n",
    "        verbose=1\n",
    "    )\n",
    "    higher = Higher (levels=levels, verbose=0)\n",
    "\n",
    "    assert higher.hierarchy_level==0 and higher.first.hierarchy_level==1 and higher.first.first.hierarchy_level==2\n",
    "\n",
    "    assert higher.verbose==1 and higher.first.verbose==1 and higher.first.first.verbose==0\n",
    "\n",
    "    levels['until']=0\n",
    "    higher = Higher (levels=levels, verbose=0)\n",
    "    assert higher.verbose==1 and higher.first.verbose==0 and higher.first.first.verbose==0\n",
    "\n",
    "    levels['until']=2\n",
    "    higher = Higher (levels=levels, verbose=0)\n",
    "    assert higher.verbose==1 and higher.first.verbose==1 and higher.first.first.verbose==1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20f7366e-ee7a-4acf-8818-2a41d614fde4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test_multi_comp_hierarchy\n"
     ]
    }
   ],
   "source": [
    "tst.run (test_multi_comp_hierarchy, tag='dummy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8dae93-e681-45e2-a91c-9d85d9930a95",
   "metadata": {},
   "source": [
    "#### Profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2537033e-63a6-45e5-9c8e-43886cd75964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports tests.core.test_compose\n",
    "#@pytest.mark.reference_fails\n",
    "def test_multi_comp_profiling ():\n",
    "    class A(Component):\n",
    "        def __init__ (self, time=1, **kwargs):\n",
    "            super().__init__(**kwargs)\n",
    "\n",
    "        def _fit (self, X, y=None):\n",
    "            time.sleep(self.time*2)\n",
    "\n",
    "        def _apply (self, X):\n",
    "            time.sleep(self.time)\n",
    "            return 1\n",
    "\n",
    "    class Intermediate (MultiComponent):\n",
    "        def __init__ (self, name=None, **kwargs):\n",
    "            super().__init__ (name=name, **kwargs)\n",
    "            self.first = A (name=f'{name}_first_component', time=0.01, **kwargs)\n",
    "            self.second = A (name=f'{name}_second_component', time=0.03, **kwargs)\n",
    "        def _fit (self, X, y=None):\n",
    "            self.first.fit (X,y)\n",
    "            self.second.fit (X,y)\n",
    "        def _apply (self, X):\n",
    "            _ = self.first.apply (X)\n",
    "            _ = self.second.apply (X)\n",
    "            return 1\n",
    "\n",
    "    class Higher (MultiComponent):\n",
    "        def __init__ (self, **kwargs):\n",
    "            super().__init__ (**kwargs)\n",
    "            self.first = Intermediate (name='first', **kwargs)\n",
    "            self.second = Intermediate (name='second', **kwargs)\n",
    "        def _fit (self, X, y=None):\n",
    "            self.first.fit (X,y)\n",
    "            self.second.fit (X,y)\n",
    "        def _apply (self, X):\n",
    "            _ = self.first.apply (X)\n",
    "            _ = self.second.apply (X)\n",
    "            return 1\n",
    "\n",
    "    higher = Higher()\n",
    "    higher.fit (1)\n",
    "    _ = higher.apply (1)\n",
    "    dfd = higher.gather_times()\n",
    "\n",
    "    values = dfd.avg[('whole','apply')].values\n",
    "    assert np.abs(values[1:3].sum() - values[0]) < 0.05\n",
    "    assert np.abs(values[3:5].sum() - values[1]) < 0.05\n",
    "    assert np.abs(values[5:7].sum() - values[2]) < 0.05\n",
    "\n",
    "    values = dfd.avg[('whole','fit')].values\n",
    "    assert np.abs(values[1:3].sum() - values[0]) < 0.05\n",
    "    assert np.abs(values[3:5].sum() - values[1]) < 0.05\n",
    "    assert np.abs(values[5:7].sum() - values[2]) < 0.05\n",
    "\n",
    "    display('avg', dfd.avg)\n",
    "\n",
    "    assert (dfd.novh_avg <= dfd.avg).all().all()\n",
    "    assert (dfd.novh_avg < dfd.avg).any().any()\n",
    "\n",
    "    assert ((dfd.novh_avg.iloc[-4:].sum(axis=0).to_frame().T) == dfd.no_overhead_total).all(axis=1).all()\n",
    "\n",
    "    assert ((dfd.avg.iloc[0]-dfd.novh_avg.iloc[-4:].sum(axis=0)).values == dfd.overhead_total.values).all()\n",
    "\n",
    "    display('no_overhead_total', dfd.no_overhead_total)\n",
    "    display('overhead_total', dfd.overhead_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4843c65a-8901-4931-ad01-151dae49a19d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test_multi_comp_profiling\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'avg'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">whole</th>\n",
       "      <th>leaf</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>fit</th>\n",
       "      <th>apply</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th>higher</th>\n",
       "      <td>0.214460</td>\n",
       "      <td>0.111573</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>first</th>\n",
       "      <td>0.100982</td>\n",
       "      <td>0.051975</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>second</th>\n",
       "      <td>0.101104</td>\n",
       "      <td>0.052404</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">2</th>\n",
       "      <th>first_first_component</th>\n",
       "      <td>0.024531</td>\n",
       "      <td>0.012577</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first_second_component</th>\n",
       "      <td>0.064266</td>\n",
       "      <td>0.032427</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>second_first_component</th>\n",
       "      <td>0.024296</td>\n",
       "      <td>0.012392</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>second_second_component</th>\n",
       "      <td>0.064317</td>\n",
       "      <td>0.032549</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              whole             leaf\n",
       "                                fit     apply       \n",
       "0 higher                   0.214460  0.111573  False\n",
       "1 first                    0.100982  0.051975  False\n",
       "  second                   0.101104  0.052404  False\n",
       "2 first_first_component    0.024531  0.012577   True\n",
       "  first_second_component   0.064266  0.032427   True\n",
       "  second_first_component   0.024296  0.012392   True\n",
       "  second_second_component  0.064317  0.032549   True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'no_overhead_total'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">whole</th>\n",
       "      <th>leaf</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>fit</th>\n",
       "      <th>apply</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.16036</td>\n",
       "      <td>0.08031</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     whole          leaf\n",
       "       fit    apply     \n",
       "0  0.16036  0.08031  4.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'overhead_total'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">whole</th>\n",
       "      <th>leaf</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>fit</th>\n",
       "      <th>apply</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th>higher</th>\n",
       "      <td>0.0541</td>\n",
       "      <td>0.031263</td>\n",
       "      <td>-4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           whole           leaf\n",
       "             fit     apply     \n",
       "0 higher  0.0541  0.031263 -4.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tst.run (test_multi_comp_profiling, tag='dummy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edca8c00-ca3a-4643-b589-a351076f6a27",
   "metadata": {},
   "source": [
    "#### assert_all_equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "79317c6b-38fb-4f2e-ba27-9adb98838cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports tests.core.test_compose\n",
    "#@pytest.mark.reference_fails\n",
    "def test_multi_comp_all_equal ():\n",
    "    path_results = 'multi_component_assert_equal'\n",
    "    remove_previous_results (path_results=path_results)\n",
    "\n",
    "    # 1. by setting components as attributes:\n",
    "    class NewComposition(MultiComponent):\n",
    "\n",
    "        def __init__ (self, noise = 0, **kwargs):\n",
    "            super().__init__(**kwargs)\n",
    "\n",
    "            self.tr1 = Component(FunctionTransformer (lambda x: x*3 + noise),\n",
    "                                 name='tr1',\n",
    "                                 **kwargs)\n",
    "            self.tr2 = Component(FunctionTransformer (lambda x: x*2),\n",
    "                                 name='tr2',\n",
    "                                 **kwargs)\n",
    "\n",
    "        def _apply (self, X):\n",
    "            return self.tr1 (X) + self.tr2(X)\n",
    "\n",
    "    X = np.array([1,2,3])\n",
    "\n",
    "    composition1 = NewComposition (path_results=path_results)\n",
    "    result1 = composition1 (X)\n",
    "\n",
    "    path_results2 = 'multi_component_assert_equal_2'\n",
    "    remove_previous_results (path_results=path_results2)\n",
    "    composition2 = NewComposition (path_results=path_results2)\n",
    "    result2 = composition2 (X)\n",
    "    assert composition1.assert_all_equal (path_results2)\n",
    "\n",
    "    remove_previous_results (path_results=path_results2)\n",
    "    composition2 = NewComposition (path_results=path_results2, noise=0.1)\n",
    "    result2 = composition2 (X)\n",
    "    assert not composition1.assert_all_equal (path_results2)\n",
    "\n",
    "    # *************************\n",
    "    # check verbosity\n",
    "    # *************************\n",
    "    composition1 = NewComposition (path_results=path_results, verbose=1)\n",
    "    composition1.logger.info ('\\n******************************')\n",
    "    composition1.logger.info ('verbose')\n",
    "    composition1.logger.info ('******************************')\n",
    "    assert not composition1.assert_all_equal (path_results2)\n",
    "\n",
    "    composition1.logger.info ('\\n******************************')\n",
    "    composition1.logger.info ('not verbose')\n",
    "    composition1.logger.info ('******************************')\n",
    "    assert not composition1.assert_all_equal (path_results2, verbose=0)\n",
    "    composition1.logger.info ('logger works again')\n",
    "    \n",
    "    # *******************************\n",
    "    # check recursion\n",
    "    # *******************************\n",
    "    class NewComposition (MultiComponent):\n",
    "\n",
    "        def __init__ (self, noise = 0, **kwargs):\n",
    "            super().__init__(**kwargs)\n",
    "\n",
    "            self.tr1 = Component(FunctionTransformer (lambda x: x*2 + noise),\n",
    "                                 name='tr1',\n",
    "                                 **kwargs)\n",
    "            self.tr2 = Component(FunctionTransformer (lambda x: x*3),\n",
    "                                 name='tr2',\n",
    "                                 **kwargs)\n",
    "\n",
    "        def _apply (self, X):\n",
    "            return self.tr1 (X) + self.tr2(X)\n",
    "        \n",
    "    path_results3 = 'multi_component_assert_equal_3'\n",
    "    composition3 = NewComposition (path_results=path_results3)\n",
    "    result3 = composition3 (X)\n",
    "    assert not composition3.assert_all_equal (path_results)\n",
    "    assert composition3.assert_all_equal (path_results, max_recursion=0)\n",
    "    assert not composition3.assert_all_equal (path_results, max_recursion=1)\n",
    "    \n",
    "    class NewComposition (MultiComponent):\n",
    "\n",
    "        def __init__ (self, noise = 0, **kwargs):\n",
    "            super().__init__(**kwargs)\n",
    "\n",
    "            self.tr1 = Component(FunctionTransformer (lambda x: x*4 + noise),\n",
    "                                 name='tr1',\n",
    "                                 **kwargs)\n",
    "            self.tr2 = Component(FunctionTransformer (lambda x: x*5),\n",
    "                                 name='tr2',\n",
    "                                 **kwargs)\n",
    "\n",
    "        def _apply (self, X):\n",
    "            return self.tr1 (X) + self.tr2(X)\n",
    "        \n",
    "    remove_previous_results (path_results=path_results3)\n",
    "    composition4 = NewComposition (path_results=path_results3)\n",
    "    result3 = composition4 (X)\n",
    "    assert not composition4.assert_all_equal (path_results)\n",
    "    assert not composition4.assert_all_equal (path_results, max_recursion=0)\n",
    "    assert not composition4.assert_all_equal (path_results, max_recursion=1)\n",
    "        \n",
    "    # *************************\n",
    "    # remove results\n",
    "    # *************************\n",
    "    remove_previous_results (path_results=path_results)\n",
    "    remove_previous_results (path_results=path_results2)\n",
    "    remove_previous_results (path_results=path_results3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4db2e9a2-d71f-4bfa-97ba-2cfb9e2267c0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test_multi_comp_all_equal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Component tr1 => results are different: \n",
      "Not equal to tolerance rtol=1e-07, atol=0\n",
      "\n",
      "Mismatched elements: 3 / 3 (100%)\n",
      "Max absolute difference: 0.1\n",
      "Max relative difference: 0.03225806\n",
      " x: array([3, 6, 9])\n",
      " y: array([3.1, 6.1, 9.1])\n",
      "Results are different in components ['tr1']\n",
      "\n",
      "******************************\n",
      "verbose\n",
      "******************************\n",
      "comparing results for tr1\n",
      "loading our results...\n",
      "loading from /home/jcidatascience/jaume/workspace/remote/block-types/multi_component_assert_equal/whole/tr1_result.pk\n",
      "loading from /home/jcidatascience/jaume/workspace/remote/block-types/multi_component_assert_equal_2/whole/tr1_result.pk\n",
      "Component tr1 => results are different: \n",
      "Not equal to tolerance rtol=1e-07, atol=0\n",
      "\n",
      "Mismatched elements: 3 / 3 (100%)\n",
      "Max absolute difference: 0.1\n",
      "Max relative difference: 0.03225806\n",
      " x: array([3, 6, 9])\n",
      " y: array([3.1, 6.1, 9.1])\n",
      "comparing results for tr2\n",
      "loading our results...\n",
      "loading from /home/jcidatascience/jaume/workspace/remote/block-types/multi_component_assert_equal/whole/tr2_result.pk\n",
      "loading from /home/jcidatascience/jaume/workspace/remote/block-types/multi_component_assert_equal_2/whole/tr2_result.pk\n",
      "Results are equal.\n",
      "\n",
      "Results are different in components ['tr1']\n",
      "\n",
      "******************************\n",
      "not verbose\n",
      "******************************\n",
      "Component tr1 => results are different: \n",
      "Not equal to tolerance rtol=1e-07, atol=0\n",
      "\n",
      "Mismatched elements: 3 / 3 (100%)\n",
      "Max absolute difference: 0.1\n",
      "Max relative difference: 0.03225806\n",
      " x: array([3, 6, 9])\n",
      " y: array([3.1, 6.1, 9.1])\n",
      "Results are different in components ['tr1']\n",
      "logger works again\n",
      "Component tr1 => results are different: \n",
      "Not equal to tolerance rtol=1e-07, atol=0\n",
      "\n",
      "Mismatched elements: 3 / 3 (100%)\n",
      "Max absolute difference: 3\n",
      "Max relative difference: 0.33333333\n",
      " x: array([2, 4, 6])\n",
      " y: array([3, 6, 9])\n",
      "Component tr2 => results are different: \n",
      "Not equal to tolerance rtol=1e-07, atol=0\n",
      "\n",
      "Mismatched elements: 3 / 3 (100%)\n",
      "Max absolute difference: 3\n",
      "Max relative difference: 0.5\n",
      " x: array([3, 6, 9])\n",
      " y: array([2, 4, 6])\n",
      "Results are different in components ['tr1', 'tr2']\n",
      "Component tr1 => results are different: \n",
      "Not equal to tolerance rtol=1e-07, atol=0\n",
      "\n",
      "Mismatched elements: 3 / 3 (100%)\n",
      "Max absolute difference: 3\n",
      "Max relative difference: 0.33333333\n",
      " x: array([2, 4, 6])\n",
      " y: array([3, 6, 9])\n",
      "Component tr2 => results are different: \n",
      "Not equal to tolerance rtol=1e-07, atol=0\n",
      "\n",
      "Mismatched elements: 3 / 3 (100%)\n",
      "Max absolute difference: 3\n",
      "Max relative difference: 0.5\n",
      " x: array([3, 6, 9])\n",
      " y: array([2, 4, 6])\n",
      "Results are different in components ['tr1', 'tr2']\n",
      "Component tr1 => results are different: \n",
      "Not equal to tolerance rtol=1e-07, atol=0\n",
      "\n",
      "Mismatched elements: 3 / 3 (100%)\n",
      "Max absolute difference: 3\n",
      "Max relative difference: 0.33333333\n",
      " x: array([ 4,  8, 12])\n",
      " y: array([3, 6, 9])\n",
      "Component tr2 => results are different: \n",
      "Not equal to tolerance rtol=1e-07, atol=0\n",
      "\n",
      "Mismatched elements: 3 / 3 (100%)\n",
      "Max absolute difference: 9\n",
      "Max relative difference: 1.5\n",
      " x: array([ 5, 10, 15])\n",
      " y: array([2, 4, 6])\n",
      "Results are different in components ['tr1', 'tr2']\n",
      "Component new_composition => results are different: \n",
      "Not equal to tolerance rtol=1e-07, atol=0\n",
      "\n",
      "Mismatched elements: 3 / 3 (100%)\n",
      "Max absolute difference: 12\n",
      "Max relative difference: 0.8\n",
      " x: array([ 9, 18, 27])\n",
      " y: array([ 5, 10, 15])\n",
      "Results are different in components ['new_composition']\n",
      "Component tr1 => results are different: \n",
      "Not equal to tolerance rtol=1e-07, atol=0\n",
      "\n",
      "Mismatched elements: 3 / 3 (100%)\n",
      "Max absolute difference: 3\n",
      "Max relative difference: 0.33333333\n",
      " x: array([ 4,  8, 12])\n",
      " y: array([3, 6, 9])\n",
      "Component tr2 => results are different: \n",
      "Not equal to tolerance rtol=1e-07, atol=0\n",
      "\n",
      "Mismatched elements: 3 / 3 (100%)\n",
      "Max absolute difference: 9\n",
      "Max relative difference: 1.5\n",
      " x: array([ 5, 10, 15])\n",
      " y: array([2, 4, 6])\n",
      "Results are different in components ['tr1', 'tr2']\n"
     ]
    }
   ],
   "source": [
    "tst.run (test_multi_comp_all_equal, tag='dummy', debug=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48c2e04-ce30-4964-aa10-933490c48073",
   "metadata": {},
   "source": [
    "#### setters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "783f6fe1-b1f7-4ed4-a129-37f4bec01d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports tests.core.test_compose\n",
    "#@pytest.mark.reference_fails\n",
    "def test_multi_component_setters ():\n",
    "    multi_component = SimpleMultiComponent ()\n",
    "\n",
    "    all_true = lambda x: all([x.data_io.save_splits[k] for k in x.data_io.save_splits])\n",
    "    assert all_true (multi_component)\n",
    "\n",
    "    c0, c1 = multi_component.components[0], multi_component.components[1]\n",
    "\n",
    "    assert all_true (c0) and all_true (c1)\n",
    "\n",
    "    multi_component.set_save_splits ({'training': True, 'test': False, 'validation': False, 'whole': True})\n",
    "\n",
    "    tv_false = lambda x: (all ([x.data_io.save_splits[k] for k in ['training', 'whole']])\n",
    "                          and all ([(not x.data_io.save_splits[k]) for k in ['test', 'validation']]))\n",
    "    assert tv_false(c0) and tv_false (c1) and tv_false (multi_component)\n",
    "\n",
    "    cond = lambda x: x.data_io.load_model_flag\n",
    "    assert cond (c0) and cond (c1) and cond (multi_component)\n",
    "\n",
    "    multi_component.set_load_model (False)\n",
    "    cond = lambda x: not x.data_io.load_model_flag\n",
    "    assert cond (c0) and cond (c1) and cond (multi_component)\n",
    "\n",
    "    cond = lambda x: x.data_io.save_model_flag\n",
    "    assert cond (c0) and cond (c1) and cond (multi_component)\n",
    "\n",
    "    multi_component.set_save_model (False)\n",
    "    cond = lambda x: not x.data_io.save_model_flag\n",
    "    assert cond (c0) and cond (c1) and cond (multi_component)\n",
    "\n",
    "    #set_save_result\n",
    "    cond = lambda x: x.data_io.save_result_flag\n",
    "    assert cond (c0) and cond (c1) and cond (multi_component)\n",
    "\n",
    "    multi_component.set_save_result (False)\n",
    "    cond = lambda x: not x.data_io.save_result_flag\n",
    "    assert cond (c0) and cond (c1) and cond (multi_component)\n",
    "\n",
    "    # set_load_result\n",
    "    cond = lambda x: x.data_io.load_result_flag\n",
    "    assert cond (c0) and cond (c1) and cond (multi_component)\n",
    "\n",
    "    multi_component.set_load_result (False)\n",
    "    cond = lambda x: not x.data_io.load_result_flag\n",
    "    assert cond (c0) and cond (c1) and cond (multi_component)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9ed6007a-2496-4c93-8ac0-0fe7e9d6436a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test_multi_component_setters\n"
     ]
    }
   ],
   "source": [
    "tst.run (test_multi_component_setters, tag='dummy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a71f72c-9339-4f1c-b7cf-0eb5dfd272be",
   "metadata": {},
   "source": [
    "#### show_result_statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "beca13fc-b839-4e4e-9700-5877e273051b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports tests.core.test_compose\n",
    "#@pytest.mark.reference_fails\n",
    "def test_show_result_statistics ():\n",
    "    path_results = 'show_result_statistics'\n",
    "    remove_previous_results (path_results=path_results)\n",
    "    multi_component = SimpleMultiComponent (path_results=path_results)\n",
    "    X=np.array([1,2,3])\n",
    "    r = multi_component(X)\n",
    "    multi_component.show_result_statistics();\n",
    "\n",
    "    remove_previous_results (path_results=path_results)\n",
    "    X=pd.DataFrame({'a':[4,5,6], 'b':[7,8,9]})\n",
    "    r = multi_component(X)\n",
    "    multi_component.show_result_statistics();\n",
    "    remove_previous_results (path_results=path_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4c1373e4-7b0b-469b-ae84-89dde763a509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test_show_result_statistics\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'tr1'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0\n",
       "count  3.0\n",
       "mean   6.0\n",
       "std    3.0\n",
       "min    3.0\n",
       "25%    4.5\n",
       "50%    6.0\n",
       "75%    7.5\n",
       "max    9.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'tr2'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0\n",
       "count  3.0\n",
       "mean   4.0\n",
       "std    2.0\n",
       "min    2.0\n",
       "25%    3.0\n",
       "50%    4.0\n",
       "75%    5.0\n",
       "max    6.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'tr1'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>15.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>12.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>13.5</td>\n",
       "      <td>22.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>15.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>16.5</td>\n",
       "      <td>25.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>18.0</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          a     b\n",
       "count   3.0   3.0\n",
       "mean   15.0  24.0\n",
       "std     3.0   3.0\n",
       "min    12.0  21.0\n",
       "25%    13.5  22.5\n",
       "50%    15.0  24.0\n",
       "75%    16.5  25.5\n",
       "max    18.0  27.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'tr2'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>8.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>9.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>10.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>11.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>12.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          a     b\n",
       "count   3.0   3.0\n",
       "mean   10.0  16.0\n",
       "std     2.0   2.0\n",
       "min     8.0  14.0\n",
       "25%     9.0  15.0\n",
       "50%    10.0  16.0\n",
       "75%    11.0  17.0\n",
       "max    12.0  18.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tst.run (test_show_result_statistics, tag='dummy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a10eecd-7f04-48b9-bcf7-0842f3dd1280",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Passing list of components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4d949bdd-0bb8-4404-8dfd-ffdb3f83295e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports tests.core.test_compose\n",
    "def test_pass_components ():\n",
    "    config = dict (path_results='my_path', Second=dict(path_results='other_path'))\n",
    "    multi = MultiComponent (Component (name='first', class_name='First', folder='one', **config),\n",
    "                            Component (name='second', class_name='Second', folder='two', **config),\n",
    "                            name='Inner',\n",
    "                            **config)\n",
    "\n",
    "    check_last_part (multi.path_results, 'my_path')\n",
    "    check_last_part (multi.second.path_results, 'other_path')\n",
    "    check_last_part (multi.first.path_results, 'my_path')\n",
    "\n",
    "    assert multi.first.data_io.folder=='one'\n",
    "    assert multi.second.data_io.folder=='two'\n",
    "\n",
    "    def make_inner (folder, name, **kwargs):\n",
    "        return MultiComponent (Component (name='first', class_name='First', folder='folder_first', **kwargs),\n",
    "                               Component (name='second', class_name='Second', folder='folder_second', **kwargs),\n",
    "                               folder=folder,\n",
    "                               class_name='Inner',\n",
    "                               name=name,\n",
    "                               **kwargs)\n",
    "    multi = MultiComponent (make_inner ('one', 'inner1', **config), make_inner ('two', 'inner2', **config), **config)\n",
    "\n",
    "    check_last_part (multi.inner1.first.data_io.get_path_result_file(), \n",
    "        'my_path/one/folder_first/whole/first_result.pk')\n",
    "\n",
    "    check_last_part (multi.inner1.second.data_io.get_path_result_file(),\n",
    "        'other_path/one/folder_second/whole/second_result.pk')\n",
    "\n",
    "    check_last_part (multi.inner2.first.data_io.get_path_result_file(), \n",
    "        'my_path/two/folder_first/whole/first_result.pk')\n",
    "\n",
    "    check_last_part (multi.inner2.second.data_io.get_path_result_file(), \n",
    "        'other_path/two/folder_second/whole/second_result.pk')\n",
    "\n",
    "    config = dict (path_results='my_path', Inner=dict(path_results='other_path'))\n",
    "    def make_inner (folder, name, **kwargs):\n",
    "        return MultiComponent (Component (name='first', class_name='First', folder='folder_first', **kwargs),\n",
    "                               Component (name='second', class_name='Second', folder='folder_second', **kwargs),\n",
    "                               folder=folder,\n",
    "                               class_name='Inner',\n",
    "                               name=name,\n",
    "                               **kwargs)\n",
    "    multi = MultiComponent (make_inner ('one', 'inner1', **config), \n",
    "                            make_inner ('two', 'inner2', **config), \n",
    "                            folder='__class__',\n",
    "                            class_name='Higher',\n",
    "                            name='higher',\n",
    "                            **config)\n",
    "\n",
    "    check_last_part (multi.inner1.first.data_io.get_path_result_file(), \n",
    "        'my_path/higher/one/folder_first/whole/first_result.pk')\n",
    "\n",
    "    check_last_part (multi.inner1.second.data_io.get_path_result_file(), \n",
    "        'my_path/higher/one/folder_second/whole/second_result.pk')\n",
    "\n",
    "    check_last_part (multi.inner2.first.data_io.get_path_result_file(), \n",
    "        'my_path/higher/two/folder_first/whole/first_result.pk')\n",
    "\n",
    "    check_last_part (multi.inner2.second.data_io.get_path_result_file(), \n",
    "        'my_path/higher/two/folder_second/whole/second_result.pk')\n",
    "\n",
    "    check_last_part (multi.inner1.data_io.get_path_result_file(), \n",
    "        'other_path/higher/one/whole/inner1_result.pk')\n",
    "\n",
    "    check_last_part (multi.inner2.data_io.get_path_result_file(), \n",
    "        'other_path/higher/two/whole/inner2_result.pk')\n",
    "\n",
    "    multi = MultiComponent (make_inner ('one', 'inner1', **config, propagate=True), \n",
    "                            make_inner ('two', 'inner2', **config, propagate=True), \n",
    "                            folder='__class__',\n",
    "                            class_name='Higher',\n",
    "                            name='higher',\n",
    "                            **config)\n",
    "\n",
    "    check_last_part (multi.inner1.first.data_io.get_path_result_file(), \n",
    "        'other_path/higher/one/folder_first/whole/first_result.pk')\n",
    "\n",
    "    check_last_part (multi.inner1.second.data_io.get_path_result_file(), \n",
    "                     'other_path/higher/one/folder_second/whole/second_result.pk')\n",
    "\n",
    "    check_last_part (multi.inner2.first.data_io.get_path_result_file(), \n",
    "                     'other_path/higher/two/folder_first/whole/first_result.pk')\n",
    "\n",
    "    check_last_part (multi.inner2.second.data_io.get_path_result_file(), \n",
    "                     'other_path/higher/two/folder_second/whole/second_result.pk')\n",
    "\n",
    "    check_last_part (multi.inner1.data_io.get_path_result_file(), \n",
    "                     'other_path/higher/one/whole/inner1_result.pk')\n",
    "\n",
    "    check_last_part (multi.inner2.data_io.get_path_result_file(), \n",
    "                     'other_path/higher/two/whole/inner2_result.pk')\n",
    "\n",
    "    check_last_part (multi.data_io.get_path_result_file(), \n",
    "                     'my_path/higher/whole/higher_result.pk')\n",
    "\n",
    "    multi = MultiComponent (make_inner ('one', 'inner1', **config), \n",
    "                            make_inner ('two', 'inner2', **config), \n",
    "                            folder='__class__',\n",
    "                            class_name='Higher',\n",
    "                            name='higher',\n",
    "                            propagate=True,\n",
    "                            **config)\n",
    "\n",
    "    check_last_part (multi.inner1.first.data_io.get_path_result_file(), \n",
    "                     'my_path/higher/one/folder_first/whole/first_result.pk')\n",
    "\n",
    "    check_last_part (multi.inner1.second.data_io.get_path_result_file(), \n",
    "                     'my_path/higher/one/folder_second/whole/second_result.pk')\n",
    "\n",
    "    check_last_part (multi.inner2.first.data_io.get_path_result_file(), \n",
    "                     'my_path/higher/two/folder_first/whole/first_result.pk')\n",
    "\n",
    "    check_last_part (multi.inner2.second.data_io.get_path_result_file(), \n",
    "                     'my_path/higher/two/folder_second/whole/second_result.pk')\n",
    "\n",
    "    check_last_part (multi.inner1.data_io.get_path_result_file(), \n",
    "                     'my_path/higher/one/whole/inner1_result.pk')\n",
    "\n",
    "    check_last_part (multi.inner2.data_io.get_path_result_file(), \n",
    "                     'my_path/higher/two/whole/inner2_result.pk')\n",
    "\n",
    "    check_last_part (multi.data_io.get_path_result_file(), \n",
    "                     'my_path/higher/whole/higher_result.pk')\n",
    "\n",
    "    config = dict (path_results='my_path', Inner=dict(path_results='other_path', stop_propagation=True))\n",
    "    multi = MultiComponent (make_inner ('one', 'inner1', **config, propagate=True), \n",
    "                            make_inner ('two', 'inner2', **config, propagate=True), \n",
    "                            folder='__class__',\n",
    "                            class_name='Higher',\n",
    "                            name='higher',\n",
    "                            propagate=True,\n",
    "                            **config)\n",
    "\n",
    "    check_last_part (multi.inner1.first.data_io.get_path_result_file(), \n",
    "                     'other_path/higher/one/folder_first/whole/first_result.pk')\n",
    "\n",
    "    check_last_part (multi.inner1.second.data_io.get_path_result_file(), \n",
    "                     'other_path/higher/one/folder_second/whole/second_result.pk')\n",
    "\n",
    "    check_last_part (multi.inner2.first.data_io.get_path_result_file(), \n",
    "                     'other_path/higher/two/folder_first/whole/first_result.pk')\n",
    "\n",
    "    check_last_part (multi.inner2.second.data_io.get_path_result_file(), \n",
    "                     'other_path/higher/two/folder_second/whole/second_result.pk')\n",
    "\n",
    "    check_last_part (multi.inner1.data_io.get_path_result_file(), \n",
    "                     'other_path/higher/one/whole/inner1_result.pk')\n",
    "\n",
    "    check_last_part (multi.inner2.data_io.get_path_result_file(), \n",
    "                     'other_path/higher/two/whole/inner2_result.pk')\n",
    "\n",
    "    check_last_part (multi.data_io.get_path_result_file(), \n",
    "                     'my_path/higher/whole/higher_result.pk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "578b56a2-44c5-441c-8f1d-26ef5f7e3edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test_pass_components\n"
     ]
    }
   ],
   "source": [
    "tst.run (test_pass_components, tag='dummy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2473308d-3bd8-4cb6-9827-050bdfbe7a19",
   "metadata": {},
   "source": [
    "#### chain_folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "42ce102a-aa16-4e0d-a815-246e30c14e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports tests.core.test_compose\n",
    "def test_chain_folders ():\n",
    "    config = dict (path_results='my_path', Second=dict(path_results='other_path'))\n",
    "    def first_level ():\n",
    "        a0=Component (name='first', class_name='First', folder='folder_first', **config)\n",
    "        b0=Component (name='second', class_name='Second', folder='folder_second', **config)\n",
    "        return a0, b0\n",
    "\n",
    "    a0, b0 = first_level()\n",
    "\n",
    "    assert a0.data_io.folder=='folder_first'\n",
    "\n",
    "    def second_level ():\n",
    "        a0, b0 = first_level ()\n",
    "        a1= MultiComponent (a0, b0, folder='one', class_name='Inner', name='inner1', **config)\n",
    "        a0, b0 = first_level ()\n",
    "        b1= MultiComponent (a0, b0, folder='two', class_name='Inner', name='inner2', **config)\n",
    "        return a1, b1\n",
    "\n",
    "    a1, b1 = second_level ()\n",
    "\n",
    "    assert a1.first.data_io.folder=='one/folder_first'\n",
    "    assert a1.second.data_io.folder=='one/folder_second'\n",
    "    assert b1.first.data_io.folder=='two/folder_first'\n",
    "    assert b1.second.data_io.folder=='two/folder_second'\n",
    "\n",
    "    def third_level ():\n",
    "        a1, b1 = second_level ()\n",
    "        a2= MultiComponent (a1, b1, folder='third1', class_name='Higher', name='higher1', **config)\n",
    "        a1, b1 = second_level ()\n",
    "        b2= MultiComponent (a1, b1, folder='third2', class_name='Higher', name='higher2', **config)\n",
    "        return a2, b2\n",
    "\n",
    "    a2, b2 = third_level ()\n",
    "\n",
    "    assert a2.inner1.first.data_io.folder=='third1/one/folder_first'\n",
    "    assert a2.inner1.second.data_io.folder=='third1/one/folder_second'\n",
    "    assert b2.inner1.first.data_io.folder=='third2/one/folder_first'\n",
    "    assert b2.inner1.second.data_io.folder=='third2/one/folder_second'\n",
    "    assert b2.inner2.first.data_io.folder=='third2/two/folder_first'\n",
    "    assert b2.inner2.second.data_io.folder=='third2/two/folder_second'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4e79d78d-81ea-41d3-826a-a7ec8bd62fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test_chain_folders\n"
     ]
    }
   ],
   "source": [
    "tst.run (test_chain_folders, tag='dummy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7cfe10-762e-4a67-a4b7-956256301858",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Pipeline / Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3caa0a81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export\n",
    "class Pipeline (MultiComponent):\n",
    "    \"\"\"\n",
    "    Pipeline composed of a list of components that run sequentially.\n",
    "    \n",
    "    During training, the components of the list are trained one after the other, \n",
    "    where one component is fed the result of transforming the data with the list \n",
    "    of components located before in the pipeline.\n",
    "    \n",
    "    The `Pipeline` class is a subclass of `SamplingComponent`, which itself is a \n",
    "    subclass of `Component`. This provides the functionality of `Component` \n",
    "    to any implemented pipeline, such as logging the messages, loading / saving the \n",
    "    results, and convert the data format so that it can work as part of other \n",
    "    pipelines with potentially other data formats.\n",
    "    \n",
    "    Being a subclass of `SamplingComponent`, the `transform` method \n",
    "    receives an input data  `X` that contains both data and labels. \n",
    "    \n",
    "    Furthermore, the Pipeline constructor sets `separate_labels=False` by default,\n",
    "    which means that the `fit` method also receives an input data `X` that contains \n",
    "    not only data but also labels. This is necessary because some of the components in \n",
    "    the pipeline might be of class `SamplingComponent`, and such components \n",
    "    need the input data `X` to contain labels when calling `transform` (and note that \n",
    "    this method is called when calling `fit` on a pipeline, since we do `fit_transform`\n",
    "    on all the components except for the last one)\n",
    "    \"\"\"\n",
    "    def __init__ (self, *components, **kwargs):\n",
    "        \"\"\"Assigns attributes and calls parent constructor.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        separate_labels: bool, optional\n",
    "            whether or not the fit method receives the labels in a separate `y` vector \n",
    "            or in the same input `X`, as an additional variable. See description of \n",
    "            Pipeline class for more details.\n",
    "        \"\"\"\n",
    "        \n",
    "        super().__init__ (*components, **kwargs)\n",
    "        \n",
    "    def _fit (self, X, y=None):\n",
    "        \"\"\"\n",
    "        Fit components of the pipeline, given data X and labels y.\n",
    "        \n",
    "        By default, y will be None, and the labels are part of `X`, as a variable.\n",
    "        \"\"\"\n",
    "        X = self._fit_apply_except_last (X, y)\n",
    "        self.components[-1].fit (X, y)\n",
    "    \n",
    "    def _fit_apply (self, X, y=None, **kwargs):\n",
    "        X = self._fit_apply_except_last (X, y, **kwargs)\n",
    "        return self.components[-1].fit_apply (X, y, **kwargs)\n",
    "\n",
    "    def _fit_apply_except_last (self, X, y, **kwargs):\n",
    "        for component in self.components[:-1]:\n",
    "            X = component.fit_apply (X, y, **kwargs)\n",
    "        return X\n",
    "    \n",
    "    def _apply (self, X):\n",
    "        \"\"\"Transform data with components of pipeline, and predict labels with last component. \n",
    "        \n",
    "        In the current implementation, we consider prediction a form of mapping, \n",
    "        and therefore a special type of transformation.\"\"\"\n",
    "        for component in self.components:\n",
    "            X = component.transform (X)\n",
    "\n",
    "        return X\n",
    "    \n",
    "    def find_last_result (self, split=None, func='apply', first=-1):\n",
    "        \n",
    "        idx = None\n",
    "        for i, component in enumerate(self.components[first:0:-1]):\n",
    "            if component.data_io.can_load_result () and component.data_io.exists_result (split=split):\n",
    "                idx = i\n",
    "                break\n",
    "            elif isinstance (component, MultiComponent):\n",
    "                starting_point = component.find_last_result (split=split)\n",
    "                if starting_point:\n",
    "                    idx = i\n",
    "                    break\n",
    "        split = self.data_io.split if split is None else split\n",
    "        if idx is not None:\n",
    "            self.start_idx[func][split] = len(self.components) - idx - 1\n",
    "            self.is_data_source[func][split] = True\n",
    "        else:\n",
    "            self.start_idx[func][split] = 0\n",
    "            self.is_data_source[func][split] = False\n",
    "        return self.is_data_source[func][split]\n",
    "    \n",
    "    def find_last_fitted_model (self, split='training'):\n",
    "        idx = len(self.components)-1\n",
    "        all_components_fitted = True\n",
    "        for i, component in enumerate(self.components):\n",
    "            if isinstance (component, MultiComponent) and not component.find_last_fitted_model (split=split):\n",
    "                idx = i-1\n",
    "                all_components_fitted = False\n",
    "                break\n",
    "            elif (component.is_model and \n",
    "                  not (component.data_io.can_load_model () and component.data_io.exists_model ())):\n",
    "                    idx = i-1\n",
    "                    all_components_fitted = False\n",
    "                    break\n",
    "        \n",
    "        if idx >= 0:\n",
    "            _ = self.find_last_result (split=split, func='fit', first=idx)\n",
    "            all_components_fitted = ((idx==(len(self.components)-1)) \n",
    "                                     and self.start_idx['fit'][split]==(len(self.components)-1))\n",
    "        else:\n",
    "            all_components_fitted = False\n",
    "        return all_components_fitted\n",
    "\n",
    "# Sequential is an alias of Pipeline\n",
    "Sequential = Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e83eb3e-3377-4afa-a676-ef82e287d0f1",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Simple pipeline example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d497336b-6843-4226-a266-3e22424cc9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports tests.core.test_compose\n",
    "class Transform1 (Component):\n",
    "\n",
    "    def __init__ (self, **kwargs):\n",
    "        super().__init__ (**kwargs)\n",
    "        self.estimator= Bunch(sum = 1)\n",
    "\n",
    "    def _fit (self, X, y=None):\n",
    "        self.estimator.sum = X.sum(axis=0)\n",
    "\n",
    "    def _apply (self, x):\n",
    "        return x*1000 + self.estimator.sum\n",
    "\n",
    "class Transform2 (Component):\n",
    "\n",
    "    def __init__ (self, **kwargs):\n",
    "        super().__init__ (**kwargs)\n",
    "        self.estimator= Bunch(maxim = 1)\n",
    "\n",
    "    def _fit (self, X, y=None):\n",
    "        self.estimator.maxim = X.max(axis=0)\n",
    "\n",
    "    def _apply (self, x):\n",
    "        return x*100 + self.estimator.maxim\n",
    "    \n",
    "class SimplePipeline (Pipeline):\n",
    "    def __init__ (self, **kwargs):\n",
    "        super().__init__ (**kwargs)\n",
    "\n",
    "        # custom transform\n",
    "        self.tr1 = Transform1(**kwargs) \n",
    "\n",
    "        # slklearn transform\n",
    "        self.tr2 = Transform2(**kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d261ce6c",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "### Tests for `fit_apply` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3a99f764-a4da-4d97-9ab7-d2f848e40995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports tests.core.test_compose\n",
    "#@pytest.mark.reference_fails\n",
    "def test_pipeline_fit_apply ():\n",
    "    # test `fit_apply` method\n",
    "    pipeline = SimplePipeline()\n",
    "    x = np.array([3,4,5])\n",
    "    r1 = pipeline.fit_apply (x.reshape(-1,1))\n",
    "    print (r1)\n",
    "\n",
    "    x1 = x * 1000 + sum(x)\n",
    "    x2 = x1 * 100 + max(x1)\n",
    "    assert (r1.ravel()==x2).all()\n",
    "    \n",
    "    # *********************************\n",
    "    # Another way of building a pipeline\n",
    "    # *********************************\n",
    "    pipeline = Sequential (Transform1(), \n",
    "                           Transform2())\n",
    "\n",
    "    x = np.array([3,4,5])\n",
    "    r1 = pipeline.fit_apply (x.reshape(-1,1))\n",
    "\n",
    "    x1 = x * 1000 + sum(x)\n",
    "    x2 = x1 * 100 + max(x1)\n",
    "    assert (r1.ravel()==x2).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "078a3f35-fc68-4fbb-bc03-8cb4aa978f33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test_pipeline_fit_apply\n",
      "[[306212]\n",
      " [406212]\n",
      " [506212]]\n"
     ]
    }
   ],
   "source": [
    "tst.run (test_pipeline_fit_apply, tag='dummy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d3bac1ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# exports tests.core.test_compose\n",
    "#@pytest.mark.reference_fails\n",
    "def test_pipeline_fit_apply_bis ():\n",
    "    # test `fit_apply` method\n",
    "    class NewMulti (MultiComponent):\n",
    "\n",
    "        def __init__ (self, **kwargs):\n",
    "            super().__init__ (**kwargs)\n",
    "\n",
    "            # custom transform\n",
    "            self.tr1 = Transform1(**kwargs) \n",
    "\n",
    "            # slklearn transform\n",
    "            self.tr2 = Transform2(**kwargs) \n",
    "\n",
    "        def _fit (self, X, y=None):\n",
    "            self.tr1.fit (X)\n",
    "            self.tr2.fit (X)\n",
    "\n",
    "        def _apply (self, X, y=None):\n",
    "            X1=self.tr1.apply (X)\n",
    "            X2=self.tr2.apply (X)\n",
    "            return X1+X2\n",
    "\n",
    "    new_multi = NewMulti()\n",
    "    x = np.array([3,4,5])\n",
    "    r2 = new_multi.fit_apply (x)\n",
    "    print (r2)\n",
    "    \n",
    "    x2b = 100 * x + max(x)\n",
    "    x1 = x * 1000 + sum(x)\n",
    "    assert (r2.ravel()==(x1 + x2b)).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d64ecafb-d0f4-4c64-9366-409fa45f636c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test_pipeline_fit_apply_bis\n",
      "[3317 4417 5517]\n"
     ]
    }
   ],
   "source": [
    "tst.run (test_pipeline_fit_apply_bis, tag='dummy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35aacd2b",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Adding new components to pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7b4c7306-619f-4164-af8c-2855be023cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports tests.core.test_compose\n",
    "#@pytest.mark.reference_fails\n",
    "def test_pipeline_new_comp ():\n",
    "    # test automatic creation of pipeline components\n",
    "\n",
    "    # 1. by setting components as attributes:\n",
    "    class NewPipeline(Pipeline):\n",
    "        def __init__ (self, **kwargs):\n",
    "            super().__init__(**kwargs)\n",
    "            self.tr1 = Component(FunctionTransformer (lambda x: x+1))\n",
    "            self.tr2 = Component(FunctionTransformer (lambda x: x*2))\n",
    "    pipeline = NewPipeline()\n",
    "    result = pipeline.transform (3)\n",
    "    print (result)\n",
    "    assert result == 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c255ec63-03b6-4bdd-81d0-4161ddb51d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test_pipeline_new_comp\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "tst.run (test_pipeline_new_comp, tag='dummy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "59ae2602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports tests.core.test_compose\n",
    "#@pytest.mark.reference_fails\n",
    "def test_pipeline_set_comp ():\n",
    "    #2. by using `set_components`\n",
    "    class NewPipeline(Pipeline):\n",
    "        def __init__ (self, **kwargs):\n",
    "            super().__init__(**kwargs)\n",
    "            tr1 = Component(FunctionTransformer (lambda x: x+1))\n",
    "            tr2 = Component(FunctionTransformer (lambda x: x*2))\n",
    "            self.set_components (tr1, tr2)\n",
    "\n",
    "            # the following transform is not added to the pipeline component list:\n",
    "            self.tr3 = Component(FunctionTransformer (lambda x: x+1))\n",
    "\n",
    "            # The reason is that once set_components is called, the component list \n",
    "            # is frozen and inmutable setting new components by attribute doesn't \n",
    "            # result in adding them to the component list\n",
    "\n",
    "    pipeline = NewPipeline()\n",
    "    result = pipeline.transform (3)\n",
    "\n",
    "    assert result == 8\n",
    "    assert len(pipeline.components) == 2\n",
    "    print (result, len(pipeline.components))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "30437ae3-3eac-4416-a12b-468b5790a434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test_pipeline_set_comp\n",
      "8 2\n"
     ]
    }
   ],
   "source": [
    "tst.run (test_pipeline_set_comp, tag='dummy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "11918856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports tests.core.test_compose\n",
    "#@pytest.mark.reference_fails\n",
    "def test_athena_pipeline_training ():\n",
    "#3. after calling `set_components()`, we can add new components with `add_component()`\n",
    "    class NewPipeline(Pipeline):\n",
    "        def __init__ (self, **kwargs):\n",
    "            super().__init__(**kwargs)\n",
    "            tr1 = Component(FunctionTransformer (lambda x: x+1))\n",
    "            tr2 = Component(FunctionTransformer (lambda x: x*2))\n",
    "            self.set_components (tr1, tr2)\n",
    "\n",
    "            tr3 = Component(FunctionTransformer (lambda x: x+2))\n",
    "            self.add_component(tr3)\n",
    "\n",
    "    pipeline = NewPipeline()\n",
    "    result = pipeline.transform (3)\n",
    "\n",
    "    assert result == 10\n",
    "    assert len(pipeline.components) == 3\n",
    "    print (result, len(pipeline.components))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b4ed99a3-cb00-4c4a-beb3-7a4130870771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test_athena_pipeline_training\n",
      "10 3\n"
     ]
    }
   ],
   "source": [
    "tst.run (test_athena_pipeline_training, tag='dummy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6221cf2",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Tests for `load_estimator` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ef255940-0efe-4ab1-b0f3-0315a3b97cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports tests.core.test_compose\n",
    "#@pytest.mark.reference_fails\n",
    "def test_pipeline_load_estimator ():\n",
    "    # test `load_estimator` method\n",
    "\n",
    "    # Transform1: custom Transform\n",
    "    class Transform1 (PickleSaverComponent):\n",
    "\n",
    "        def __init__ (self, **kwargs):\n",
    "            super().__init__ (**kwargs)\n",
    "            self.estimator= Bunch(inv_c = 1)\n",
    "\n",
    "        def _fit (self, X, y=None):\n",
    "            self.estimator.inv_c = X.ravel()[0]\n",
    "\n",
    "        def _apply (self, x):\n",
    "            return x / self.estimator.inv_c\n",
    "\n",
    "    class NewPipeline (Pipeline):\n",
    "\n",
    "        def __init__ (self, **kwargs):\n",
    "            super().__init__ (**kwargs)\n",
    "\n",
    "            # custom transform\n",
    "            self.tr1 = Transform1(**kwargs) \n",
    "\n",
    "            # slklearn transform\n",
    "            self.tr2 = PickleSaverComponent(StandardScaler(), **kwargs)\n",
    "\n",
    "        def _fit (self, X, y=None):\n",
    "            self.tr1.fit (X)\n",
    "            self.tr2.fit (X)\n",
    "\n",
    "    # remove any previously stored \n",
    "    path_results = 'pipeline_loading_saving'\n",
    "    remove_previous_results (path_results=path_results)\n",
    "\n",
    "    pipeline = NewPipeline(path_results=path_results, save_test_result=False)\n",
    "    pipeline.fit (np.array([3,4,5]).reshape(-1,1))\n",
    "    result1 = pipeline.transform (np.array([300,400,500]).reshape(-1,1))\n",
    "    print (pipeline.tr2.estimator.mean_)\n",
    "\n",
    "    del pipeline \n",
    "    pipeline = NewPipeline(path_results=path_results, save_test_result=False)\n",
    "    pipeline.load_estimator ()\n",
    "    print (pipeline.tr2.estimator.mean_)\n",
    "    result2 = pipeline.transform (np.array([300,400,500]).reshape(-1,1))\n",
    "\n",
    "    np.testing.assert_array_equal (result1, result2)\n",
    "\n",
    "    # remove stored files resulting from running the current test\n",
    "    remove_previous_results (path_results=path_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9ed265b9-b9a8-405b-b6a7-d4fe7f283b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test_pipeline_load_estimator\n",
      "[4.]\n",
      "[4.]\n"
     ]
    }
   ],
   "source": [
    "tst.run (test_pipeline_load_estimator, tag='dummy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f01cea-8262-413f-bc99-f68915f69ba3",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### construct_diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7cb1c5c3-6486-4028-8b1b-8b0f22206f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports tests.core.test_compose\n",
    "#@pytest.mark.reference_fails\n",
    "\n",
    "def build_pipeline_construct_diagram_1 (path_results):\n",
    "    class Intermediate (MultiComponent):\n",
    "        def __init__ (self, name=None, **kwargs):\n",
    "            super().__init__ (name=name, **kwargs)\n",
    "            self.first = Component (name='first_component', **kwargs)\n",
    "            self.second = Component (name='second_component', **kwargs)\n",
    "\n",
    "    class Higher (Pipeline):\n",
    "        def __init__ (self, **kwargs):\n",
    "            super().__init__ (**kwargs)\n",
    "            self.first = Intermediate (name='first_intermediate', class_name='First', **kwargs)\n",
    "            self.second = Intermediate (name='second_intermediate', class_name='Second', **kwargs)\n",
    "\n",
    "    pipeline = Higher(path_results=path_results)\n",
    "    \n",
    "    return pipeline\n",
    "\n",
    "def build_pipeline_construct_diagram_2 (path_results):\n",
    "    class NewPipeline (Pipeline):\n",
    "        def __init__ (self, **kwargs):\n",
    "            data_io = PickleIO (**kwargs)\n",
    "            super().__init__(data_io=data_io,\n",
    "                             **kwargs)\n",
    "\n",
    "            self.tr1 = Component(FunctionTransformer (lambda x: x*3),\n",
    "                                 data_io=data_io,\n",
    "                                 class_name='FirstTransform',\n",
    "                                 name='tr1')\n",
    "            self.tr2 = Component(FunctionTransformer (lambda x: x*2),\n",
    "                                 data_io=data_io,\n",
    "                                 class_name='SecondTransform',\n",
    "                                 name='tr2')\n",
    "            \n",
    "    pipeline = NewPipeline (path_results=path_results)\n",
    "    \n",
    "    return pipeline\n",
    "\n",
    "def test_construct_diagram ():\n",
    "    path_results = 'construct_diagram'\n",
    "    remove_previous_results (path_results=path_results)\n",
    "\n",
    "    # ********************************************\n",
    "    # example without dimensionality of outputs\n",
    "    # ********************************************\n",
    "    pipeline = build_pipeline_construct_diagram_1 (path_results)\n",
    "    diagram = pipeline.construct_diagram ()\n",
    "    display (diagram)\n",
    "    \n",
    "    # ********************************************\n",
    "    # example that shows dimensionality of outputs\n",
    "    # ********************************************\n",
    "    pipeline = build_pipeline_construct_diagram_2 (path_results)\n",
    "    X = np.array([1,2,3])\n",
    "    result = pipeline (X)\n",
    "\n",
    "    diagram = pipeline.construct_diagram ()\n",
    "    display (diagram)\n",
    "    \n",
    "    remove_previous_results (path_results=path_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "58ad9684-eb99-412e-950d-3b5ff376a6ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test_construct_diagram\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: G Pages: 1 -->\n",
       "<svg width=\"96pt\" height=\"322pt\"\n",
       " viewBox=\"0.00 0.00 96.15 321.99\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 317.9896)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-317.9896 92.1471,-317.9896 92.1471,4 -4,4\"/>\n",
       "<!-- data -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>data</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"33.1471\" cy=\"-288.6419\" rx=\"25.1964\" ry=\"25.1964\"/>\n",
       "<text text-anchor=\"middle\" x=\"33.1471\" y=\"-284.9419\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">data</text>\n",
       "</g>\n",
       "<!-- First -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>First</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"60.1471,-212.2941 6.1471,-212.2941 6.1471,-176.2941 60.1471,-176.2941 60.1471,-212.2941\"/>\n",
       "<text text-anchor=\"middle\" x=\"33.1471\" y=\"-190.5941\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">First</text>\n",
       "</g>\n",
       "<!-- data&#45;&gt;First -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>data&#45;&gt;First</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M33.1471,-262.8609C33.1471,-250.4145 33.1471,-235.4473 33.1471,-222.6765\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"36.6472,-222.5692 33.1471,-212.5692 29.6472,-222.5692 36.6472,-222.5692\"/>\n",
       "<text text-anchor=\"middle\" x=\"60.6471\" y=\"-234.0941\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">train / test</text>\n",
       "</g>\n",
       "<!-- Second -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>Second</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"61.1471,-139.2941 5.1471,-139.2941 5.1471,-103.2941 61.1471,-103.2941 61.1471,-139.2941\"/>\n",
       "<text text-anchor=\"middle\" x=\"33.1471\" y=\"-117.5941\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Second</text>\n",
       "</g>\n",
       "<!-- First&#45;&gt;Second -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>First&#45;&gt;Second</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M33.1471,-176.2492C33.1471,-168.177 33.1471,-158.4705 33.1471,-149.4759\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"36.6472,-149.3844 33.1471,-139.3845 29.6472,-149.3845 36.6472,-149.3844\"/>\n",
       "</g>\n",
       "<!-- output -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>output</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"33.1471\" cy=\"-33.1471\" rx=\"33.2948\" ry=\"33.2948\"/>\n",
       "<text text-anchor=\"middle\" x=\"33.1471\" y=\"-29.4471\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">output</text>\n",
       "</g>\n",
       "<!-- Second&#45;&gt;output -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>Second&#45;&gt;output</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M33.1471,-103.03C33.1471,-95.2531 33.1471,-85.821 33.1471,-76.4362\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"36.6472,-76.3519 33.1471,-66.352 29.6472,-76.352 36.6472,-76.3519\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7fe7a2ea5cd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: G Pages: 1 -->\n",
       "<svg width=\"122pt\" height=\"350pt\"\n",
       " viewBox=\"0.00 0.00 122.00 349.99\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 345.9896)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-345.9896 118,-345.9896 118,4 -4,4\"/>\n",
       "<!-- data -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>data</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"57\" cy=\"-316.6419\" rx=\"25.1964\" ry=\"25.1964\"/>\n",
       "<text text-anchor=\"middle\" x=\"57\" y=\"-312.9419\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">data</text>\n",
       "</g>\n",
       "<!-- FirstTransform -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>FirstTransform</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"106.5,-240.2941 7.5,-240.2941 7.5,-204.2941 106.5,-204.2941 106.5,-240.2941\"/>\n",
       "<text text-anchor=\"middle\" x=\"57\" y=\"-218.5941\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">FirstTransform</text>\n",
       "</g>\n",
       "<!-- data&#45;&gt;FirstTransform -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>data&#45;&gt;FirstTransform</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M57,-290.8609C57,-278.4145 57,-263.4473 57,-250.6765\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"60.5001,-250.5692 57,-240.5692 53.5001,-250.5692 60.5001,-250.5692\"/>\n",
       "<text text-anchor=\"middle\" x=\"84.5\" y=\"-262.0941\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">train / test</text>\n",
       "</g>\n",
       "<!-- SecondTransform -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>SecondTransform</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"114,-153.2941 0,-153.2941 0,-117.2941 114,-117.2941 114,-153.2941\"/>\n",
       "<text text-anchor=\"middle\" x=\"57\" y=\"-131.5941\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">SecondTransform</text>\n",
       "</g>\n",
       "<!-- FirstTransform&#45;&gt;SecondTransform -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>FirstTransform&#45;&gt;SecondTransform</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M57,-204.2677C57,-192.4859 57,-176.8548 57,-163.4522\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"60.5001,-163.2974 57,-153.2975 53.5001,-163.2975 60.5001,-163.2974\"/>\n",
       "<text text-anchor=\"middle\" x=\"69\" y=\"-175.0941\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"> (3,)</text>\n",
       "</g>\n",
       "<!-- output -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>output</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"57\" cy=\"-33.1471\" rx=\"33.2948\" ry=\"33.2948\"/>\n",
       "<text text-anchor=\"middle\" x=\"57\" y=\"-29.4471\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">output</text>\n",
       "</g>\n",
       "<!-- SecondTransform&#45;&gt;output -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>SecondTransform&#45;&gt;output</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M57,-117.0323C57,-105.7651 57,-90.8033 57,-76.6375\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"60.5001,-76.5275 57,-66.5276 53.5001,-76.5276 60.5001,-76.5275\"/>\n",
       "<text text-anchor=\"middle\" x=\"69\" y=\"-88.0941\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"> (3,)</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7fe7a2e2dc10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tst.run (test_construct_diagram, tag='dummy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7c9848-2240-4b1a-ba4d-f14d9c8a92f7",
   "metadata": {},
   "source": [
    "#### show_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3d373b31-afbb-4d83-a0ac-8f07c8d3a038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports tests.core.test_compose\n",
    "#@pytest.mark.reference_fails\n",
    "def test_show_summary ():\n",
    "    path_results = 'show_summary'\n",
    "    remove_previous_results (path_results=path_results)\n",
    "\n",
    "    pipeline = build_pipeline_construct_diagram_2 (path_results)\n",
    "    X = np.array([1,2,3])\n",
    "    result = pipeline (X)\n",
    "\n",
    "    pipeline.show_summary ()\n",
    "    \n",
    "    remove_previous_results (path_results=path_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8d2fa242-a9cf-4c2f-8a8a-e7da0f246270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test_show_summary\n",
      "----------------------------------------------------------------------------------------------------\n",
      "0: FirstTransform =>  (3,)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "1: SecondTransform =>  (3,)\n"
     ]
    }
   ],
   "source": [
    "tst.run (test_show_summary, tag='dummy', do=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97eaf554",
   "metadata": {
    "tags": []
   },
   "source": [
    "## make_pipeline function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0d1e7e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def make_pipeline(*components, cls=Pipeline, **kwargs):\n",
    "    \"\"\"Create `Pipeline` object of class `cls`, given `components` list.\"\"\"\n",
    "    pipeline = cls (**kwargs)\n",
    "    pipeline.set_components(*components)\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9c9624-89ae-442d-8cef-aac9001678a2",
   "metadata": {},
   "source": [
    "### Usage example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a0ac7f77-807e-4af0-8e8f-5ce783e4b39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports tests.core.test_compose\n",
    "#@pytest.mark.reference_fails\n",
    "def test_make_pipeline ():\n",
    "    tr1 = Component(FunctionTransformer (lambda x: x+1))\n",
    "    tr2 = Component(FunctionTransformer (lambda x: x*2))\n",
    "    pipeline = make_pipeline (tr1, tr2)\n",
    "    result = pipeline.transform (3)\n",
    "\n",
    "    print (result)\n",
    "    assert result == 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "abd526cc-8dfb-48c4-a023-c5b737dd0516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test_make_pipeline\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "tst.run (test_make_pipeline, tag='dummy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb6dcb6-b5ff-455d-b74e-00cac7761206",
   "metadata": {},
   "source": [
    "## pipeline_factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "132ca31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def pipeline_factory (pipeline_class, **kwargs):\n",
    "    \"\"\"Creates a pipeline object given its class `pipeline_class`\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    pipeline_class : class or str\n",
    "        Name of the pipeline class used for creating the object. \n",
    "        This can be either of type string or class.\n",
    "    \"\"\"\n",
    "    if type(pipeline_class) is str:\n",
    "        Pipeline = eval(pipeline_class)\n",
    "    elif type(pipeline_class) is type:\n",
    "        Pipeline = pipeline_class\n",
    "    else:\n",
    "        raise ValueError (f'pipeline_class needs to be either string or class, we got {pipeline_class}')\n",
    "\n",
    "    return Pipeline (**kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da359ac-a1cf-4111-b4c8-93e58dc18291",
   "metadata": {},
   "source": [
    "### Usage example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "06564708-0314-455a-b56a-e198c481ffc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports tests.core.test_compose\n",
    "#@pytest.mark.reference_fails\n",
    "def test_pipeline_factory ():\n",
    "    path_results = 'pipeline_factory'\n",
    "    remove_previous_results (path_results=path_results)\n",
    "\n",
    "    pipeline1 = pipeline_factory (SimplePipeline, path_results=path_results)\n",
    "    assert pipeline1.path_results==Path(path_results).resolve()\n",
    "    #pipeline2 = pipeline_factory ('SimplePipeline', path_results=path_results)\n",
    "    #assert pipeline2.path_results==Path(path_results).resolve()\n",
    "\n",
    "    remove_previous_results (path_results=path_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "15b61a8f-bbd1-4b09-9e67-42a0a759af2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test_pipeline_factory\n"
     ]
    }
   ],
   "source": [
    "tst.run (test_pipeline_factory, tag='dummy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34b6623-604d-4790-bafc-9c1404b202f4",
   "metadata": {},
   "source": [
    "## PandasPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7a0ab14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class PandasPipeline (Pipeline):\n",
    "    \"\"\"\n",
    "    Pipeline that saves results in parquet format, and preserves DataFrame format.\n",
    "    \n",
    "    See `Pipeline` class for an explanation of using `separate_labels=False`\n",
    "    \"\"\"\n",
    "    def __init__ (self, \n",
    "                  data_converter='PandasConverter',\n",
    "                  data_io='PandasIO',\n",
    "                  separate_labels=False,\n",
    "                  **kwargs):\n",
    "        super().__init__ (data_converter=data_converter,\n",
    "                          data_io=data_io,\n",
    "                          separate_labels=separate_labels,\n",
    "                          **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d680f08-ebe5-44b1-a2bf-60548c091d2f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Usage example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4440cc1c-c4a9-4c01-bddc-eb610f2953e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports tests.core.test_compose\n",
    "# **********************************************\n",
    "# Good example\n",
    "# **********************************************\n",
    "class PandasTransformWithLabels1 (PandasComponent):\n",
    "\n",
    "    def __init__ (self, **kwargs):\n",
    "        super().__init__ (**kwargs)\n",
    "        self.estimator= Bunch(sum = 1)\n",
    "\n",
    "    def _fit (self, X, y=None):\n",
    "        self.estimator.sum = X[y==1].sum(axis=0)\n",
    "\n",
    "    def _apply (self, X):\n",
    "        r = X*1000 + self.estimator.sum\n",
    "        return r\n",
    "    \n",
    "class PandasTransformWithLabels2 (PandasComponent):\n",
    "\n",
    "    def __init__ (self, **kwargs):\n",
    "        super().__init__ (**kwargs)\n",
    "        self.estimator= Bunch(maxim = 1)\n",
    "\n",
    "    def _fit (self, X, y=None):\n",
    "        self.estimator.maxim = X[y==0].max(axis=0)\n",
    "\n",
    "    def _apply (self, X):\n",
    "        r = X*100 + self.estimator.maxim\n",
    "        return r\n",
    "            \n",
    "class SimplePandasPipeline (PandasPipeline):\n",
    "    def __init__ (self, **kwargs):\n",
    "        super().__init__ (**kwargs)\n",
    "\n",
    "        # custom transform\n",
    "        self.tr1 = PandasTransformWithLabels1(**kwargs) \n",
    "\n",
    "        # slklearn transform\n",
    "        self.tr2 = PandasTransformWithLabels2(**kwargs)\n",
    "        \n",
    "# **********************************************\n",
    "# Bad example\n",
    "# **********************************************\n",
    "class TransformWithLabels1 (Component):\n",
    "\n",
    "    def __init__ (self, **kwargs):\n",
    "        super().__init__ (**kwargs)\n",
    "        self.estimator= Bunch(sum = 1)\n",
    "\n",
    "    def _fit (self, X, y=None):\n",
    "        self.estimator.sum = X[y==1].sum(axis=0)\n",
    "\n",
    "    def _apply (self, x):\n",
    "        return x*1000 + self.estimator.sum\n",
    "\n",
    "class TransformWithLabels2 (Component):\n",
    "\n",
    "    def __init__ (self, **kwargs):\n",
    "        super().__init__ (**kwargs)\n",
    "        self.estimator= Bunch(maxim = 1)\n",
    "\n",
    "    def _fit (self, X, y=None):\n",
    "        self.estimator.maxim = X[y==0].max(axis=0)\n",
    "\n",
    "    def _apply (self, x):\n",
    "        return x*100 + self.estimator.maxim\n",
    "    \n",
    "\n",
    "class SimplePandasPipelineNoPandasComponent (PandasPipeline):\n",
    "    def __init__ (self, **kwargs):\n",
    "        super().__init__ (**kwargs)\n",
    "\n",
    "        # custom transform\n",
    "        self.tr1 = TransformWithLabels1(**kwargs) \n",
    "\n",
    "        # slklearn transform\n",
    "        self.tr2 = TransformWithLabels2(**kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "613ad622-49c1-4ed8-a170-44ab76931cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports tests.core.test_compose\n",
    "#@pytest.mark.reference_fails\n",
    "def test_pandas_pipeline ():\n",
    "    path_results = 'pandas_pipeline'\n",
    "    remove_previous_results (path_results=path_results)\n",
    "    df = pd.DataFrame ({'a':[1,2,3,4], 'b': [5,6,7,8], 'label': [1,0,1,0]})\n",
    "\n",
    "    pipe = SimplePandasPipelineNoPandasComponent ()\n",
    "    with pytest.raises (KeyError):\n",
    "        r = pipe.fit_transform (df)\n",
    "        display (r)\n",
    "\n",
    "    pipe = SimplePandasPipeline ()\n",
    "    r = pipe.fit_transform (df)\n",
    "    display (r)\n",
    "\n",
    "    tr1 = PandasTransformWithLabels1 ()\n",
    "    tr2 = PandasTransformWithLabels2 ()\n",
    "    r1=tr1.fit_transform (df)\n",
    "    r2=tr2.fit_transform (r1)\n",
    "    assert (r==r2).all().all()\n",
    "\n",
    "    df_equal = (r1==df*1000+df[df.label==1].sum(axis=0))[['a','b']]\n",
    "    assert df_equal.all().all()\n",
    "\n",
    "    df_equal = (r2==r1*100+r1[r1.label==0].max(axis=0))[['a','b']]\n",
    "    assert df_equal.all().all()\n",
    "    remove_previous_results (path_results=path_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b689c158-7f7a-43c3-a1de-b4b25e91a21f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test_pandas_pipeline\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>104404</td>\n",
       "      <td>509212</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>204404</td>\n",
       "      <td>609212</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>304404</td>\n",
       "      <td>709212</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>404404</td>\n",
       "      <td>809212</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        a       b  label\n",
       "0  104404  509212      1\n",
       "1  204404  609212      0\n",
       "2  304404  709212      1\n",
       "3  404404  809212      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tst.run (test_pandas_pipeline, tag='dummy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8e9f63-cfcf-477a-ab76-270a3b0420a2",
   "metadata": {},
   "source": [
    "## Parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "08044b8e-68d9-4b42-88e6-9b2a2cbfcc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Parallel (MultiComponent):\n",
    "    \"\"\"\n",
    "    List of components that don't have sequential dependencies.\n",
    "    \n",
    "    As the name suggests, these components could run in parallel,\n",
    "    if a concurrency mechanism is employed.\n",
    "    \"\"\"\n",
    "    def __init__ (self, *components, select_data_before_fitting=None, select_data_before_transforming=None, \n",
    "                  initialize_result=None, join_result=None, **kwargs):\n",
    "        \"\"\"Assigns attributes and calls parent constructor.\n",
    "        \"\"\"\n",
    "        \n",
    "        select_data_before_fitting = (self.select_data_before_fitting if select_data_before_fitting is None\n",
    "                                      else select_data_before_fitting)\n",
    "        self.select_data_before_fitting = select_data_before_fitting\n",
    "        select_data_before_transforming = (self.select_data_before_transforming \n",
    "                                           if select_data_before_transforming is None\n",
    "                                           else select_data_before_transforming)\n",
    "        self.select_data_before_transforming = select_data_before_transforming\n",
    "        initialize_result = (self.initialize_result if initialize_result is None\n",
    "                                      else initialize_result)\n",
    "        self.initialize_result = initialize_result\n",
    "        join_result = (self.join_result if join_result is None\n",
    "                                      else join_result)\n",
    "        self.join_result = join_result\n",
    "        \n",
    "        super().__init__ (*components, **kwargs)\n",
    "        \n",
    "    def select_data_before_fitting (self, X, y, components, i):\n",
    "        return X, y\n",
    "    \n",
    "    def _fit (self, X, y=None):\n",
    "        \"\"\"\n",
    "        Fit components of the pipeline, given data X and labels y.\n",
    "        \n",
    "        By default, y will be None, and the labels are part of `X`, as a variable.\n",
    "        \"\"\"\n",
    "        for i, component in enumerate(self.components):\n",
    "            Xi, yi = self.select_data_before_fitting (X, y, self.components, i)\n",
    "            component.fit (Xi, yi, **kwargs)\n",
    "        \n",
    "    def initialize_result (self):\n",
    "        return []\n",
    "    \n",
    "    def select_data_before_transforming (self, X, components, i):\n",
    "        return X\n",
    "    \n",
    "    def join_result (self, Xr, Xi_r, components, i):\n",
    "        Xr.append (Xi_r)\n",
    "        return Xr\n",
    "    \n",
    "    def _apply (self, X):\n",
    "        \"\"\"Transform data with components of pipeline, and predict labels with last component. \n",
    "        \n",
    "        In the current implementation, we consider prediction a form of mapping, \n",
    "        and therefore a special type of transformation.\"\"\"\n",
    "        Xr = self.initialize_result ()\n",
    "        for i, component in enumerate(self.components):\n",
    "            Xi = self.select_data_before_transforming (X, self.components, i)\n",
    "            Xi_r = component.transform (Xi)\n",
    "            Xr = self.join_result (Xr, Xi_r, self.components, i)\n",
    "\n",
    "        return Xr\n",
    "    \n",
    "    def _fit_apply (self, X, y=None, **kwargs):\n",
    "        Xr = self.initialize_result ()\n",
    "        for i, component in enumerate(self.components):\n",
    "            Xi, yi = self.select_data_before_fitting (X, y, self.components, i)\n",
    "            Xi_r = component.fit_apply (Xi, yi, **kwargs)\n",
    "            Xr = self.join_result (Xr, Xi_r, self.components, i)\n",
    "        \n",
    "        return Xr\n",
    "    \n",
    "    def find_last_result (self, split=None):\n",
    "        self.is_data_source = True\n",
    "        for i, component in self.components:\n",
    "            if not (component.data_io.can_load_result () and component.data_io.exists_result (split=split)):\n",
    "                if isinstance (component, MultiComponent):\n",
    "                    self.is_data_source = self.is_data_source and component.find_last_result (split=split)\n",
    "                else:\n",
    "                    self.is_data_source = False\n",
    "        return self.is_data_source"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d1d49c-d43d-4122-a336-96b1a3263061",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Usage example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "86c29c98-1688-41b4-8610-4229e616dd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports tests.core.test_compose\n",
    "#@pytest.mark.reference_fails\n",
    "def test_parallel ():\n",
    "    x = np.array([3,4,5]).reshape(-1,1)\n",
    "    parallel = Parallel (Transform1 (),\n",
    "                         Transform2 ())\n",
    "    r1 = parallel.fit_apply (x)\n",
    "\n",
    "    x1 = x * 1000 + x.sum(axis=0)\n",
    "    x2 = x * 100 + x.max(axis=0)\n",
    "    r_ref = [x1, x2]\n",
    "    assert all([(x==y).all() for x, y in zip(r1, r_ref)])\n",
    "\n",
    "    parallel = Parallel (Transform1 (),\n",
    "                         Transform2 (),\n",
    "                         initialize_result=lambda : {},\n",
    "                         join_result=lambda Xr, Xi_r, components, i: {**Xr, **{components[i].name:Xi_r}})\n",
    "\n",
    "    r1 = parallel.fit_apply (x)\n",
    "    assert list(r1.keys())==['transform1','transform2']\n",
    "    assert (r1['transform1']==r_ref[0]).all()\n",
    "    assert (r1['transform2']==r_ref[1]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f26c5465-ed2a-4f92-b1ab-c2239aea6f15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test_parallel\n"
     ]
    }
   ],
   "source": [
    "tst.run (test_parallel, tag='dummy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752d0cc8-d9d3-40b1-a30d-ce7a9f06eb6d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## MultiModality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d5489475-b6ef-4261-bf37-1a1b104fbe73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class MultiModality (Parallel):\n",
    "    \"\"\"\n",
    "    Analyzes multiple modalities using Parallel data flow.\n",
    "    \"\"\"\n",
    "    def __init__ (self, *components, use_name=False, component_class=None, configs=None, **kwargs):\n",
    "        \"\"\"Assigns attributes and calls parent constructor.\n",
    "        \"\"\"\n",
    "        \n",
    "        if component_class is not None and configs is not None and isinstance(configs, dict):\n",
    "            new_components = []\n",
    "            for k in configs:\n",
    "                new_components.append (component_class (**configs[k], folder=k, suffix=k))\n",
    "            components = list(components) + new_components\n",
    "        super().__init__ (*components, **kwargs)\n",
    "        for component in components:\n",
    "            component.key = component.name if use_name else component.data_io.folder\n",
    "        \n",
    "    def select_data_before_fitting (self, X, y, components, i):\n",
    "        return X[components[i].key], y\n",
    "           \n",
    "    def initialize_result (self):\n",
    "        return {component.key: None for component in self.components}\n",
    "    \n",
    "    def select_data_before_transforming (self, X, components, i):\n",
    "        return X[components[i].key]\n",
    "    \n",
    "    def join_result (self, Xr, Xi_r, components, i):\n",
    "        Xr[components[i].key] = Xi_r\n",
    "        return Xr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a51fee0-9d69-415d-8d9e-f419a704fe5d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Usage example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "736530dd-e1fb-4f0a-9d76-542d9291035b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports tests.core.test_compose\n",
    "#@pytest.mark.reference_fails\n",
    "class TransformM (Component):\n",
    "\n",
    "    def __init__ (self, modality='', factor=1000, **kwargs):\n",
    "        super().__init__ (**kwargs)\n",
    "        self.estimator= Bunch(sum = 1)\n",
    "\n",
    "    def _fit (self, X, y=None):\n",
    "        self.estimator.sum = X.sum(axis=0)\n",
    "\n",
    "    def _apply (self, x):\n",
    "        return x*self.factor + self.estimator.sum\n",
    "    \n",
    "def test_multi_modality ():\n",
    "    data = {'transform1': np.array([1,2,3]),\n",
    "            'transform2': np.array([10,20,30])}\n",
    "    \n",
    "    parallel = MultiModality (Transform1 (),\n",
    "                              Transform2 (),\n",
    "                              use_name=True)\n",
    "    r = parallel.fit_apply (data)\n",
    "\n",
    "    x1 = data['transform1']\n",
    "    x1 = x1 * 1000 + x1.sum(axis=0)\n",
    "    x2 = data['transform2']\n",
    "    x2 = x2 * 100 + x2.max(axis=0)\n",
    "    assert list(r.keys())==['transform1','transform2']\n",
    "    assert (r['transform1']==x1).all()\n",
    "    assert (r['transform2']==x2).all()\n",
    "    \n",
    "    # with configs\n",
    "    data = dict(modA=np.array([1,2,3]),\n",
    "                modB=np.array([10,20,30]))\n",
    "    configs = dict(modA=dict (modality='A', factor=2000),\n",
    "                   modB=dict (modality='B', factor=3000))\n",
    "\n",
    "    parallel = MultiModality (component_class=TransformM,\n",
    "                              configs=configs)\n",
    "    r = parallel.fit_apply (data)\n",
    "\n",
    "    x1 = data['modA']\n",
    "    x1 = x1 * 2000 + x1.sum(axis=0)\n",
    "    x2 = data['modB']\n",
    "    x2 = x2 * 3000 + x2.sum(axis=0)\n",
    "    assert list(r.keys())==['modA','modB']\n",
    "    assert (r['modA']==x1).all()\n",
    "    assert (r['modB']==x2).all()\n",
    "\n",
    "    assert parallel.transform_m_modA.modality == 'A'\n",
    "    assert parallel.transform_m_modB.modality == 'B'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d6fbc88d-a210-4ebe-b05b-b21f47852e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test_multi_modality\n"
     ]
    }
   ],
   "source": [
    "tst.run (test_multi_modality, tag='dummy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a93851-c398-4a0c-8139-7c0d285ee4c1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## ColumnTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2fc7eb-5cc4-4721-ba16-368d0c46c7a0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### ColumnSelector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3548404e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ColumnSelector (NoSaverComponent):\n",
    "    def __init__ (self, \n",
    "                  columns=[],\n",
    "                  remainder=False,\n",
    "                  verbose=dflt.verbose,\n",
    "                  force_verbose=False,\n",
    "                  logger=None,\n",
    "                  **kwargs):\n",
    "        verbose = 0 if not force_verbose else verbose\n",
    "        if verbose==0:\n",
    "            logger = set_empty_logger ()\n",
    "        super().__init__ (verbose=verbose,\n",
    "                          logger=logger,\n",
    "                          **kwargs)\n",
    "    \n",
    "    def _apply (self, df):\n",
    "        if self.remainder:\n",
    "            return df[[c for c in df.columns if c not in self.columns]]\n",
    "        else:\n",
    "            return df[self.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2942504b-face-438e-86a2-c484a7c11516",
   "metadata": {},
   "source": [
    "#### example usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "277cb35f-4bee-4c7f-b24a-50c2810e8012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports tests.core.test_compose\n",
    "#@pytest.mark.reference_fails\n",
    "def test_column_selector ():\n",
    "    df = pd.DataFrame ({'x1': list(range(5)),\n",
    "                    'x2': list(range(5,10)),\n",
    "                    'x3': list(range(15,20)),\n",
    "                    'x4': list(range(25,30))\n",
    "                   })\n",
    "    dfr = ColumnSelector(columns=['x2','x4']).transform(df)\n",
    "    assert (dfr==df[['x2','x4']]).all().all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "59941c65-c942-4486-8e94-65d110545471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test_column_selector\n"
     ]
    }
   ],
   "source": [
    "tst.run (test_column_selector, tag='dummy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8a1be0-0087-41c1-aa13-31f96c5c172d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1d44877c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Concat (NoSaverComponent):\n",
    "    def __init__ (self, \n",
    "                  verbose=dflt.verbose,\n",
    "                  force_verbose=False,\n",
    "                  logger=None,\n",
    "                  **kwargs):\n",
    "        verbose = 0 if not force_verbose else verbose\n",
    "        if verbose==0:\n",
    "            logger = set_empty_logger ()\n",
    "        super().__init__ (verbose=verbose,\n",
    "                          logger=logger,\n",
    "                          **kwargs)\n",
    "        \n",
    "    def _apply (self, *dfs):\n",
    "        return pd.concat(list(dfs), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0a7ba3-954b-4367-9e57-b4d7ec9000a8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c8dffe69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class _BaseColumnTransformer (MultiComponent):\n",
    "    def __init__ (self, name=None, class_name=None, **kwargs):\n",
    "        super().__init__ (name=name, class_name=class_name, **kwargs)\n",
    "        self.concat = Concat (**kwargs)\n",
    "        del self.concat.nick_name\n",
    "    \n",
    "    def set_components (self, *components):\n",
    "        components = list(components)\n",
    "        components.append (self.concat)\n",
    "        super().set_components (*components)\n",
    "    \n",
    "    def _fit (self, df, y=None):\n",
    "        assert len(self.components) > 0\n",
    "        assert self.components[-1] is self.concat\n",
    "        for component in self.components[:-1]:\n",
    "            component.fit (df)\n",
    "        return self\n",
    "    \n",
    "    def _apply (self, df):\n",
    "        dfs = []\n",
    "        assert len(self.components) > 0\n",
    "        assert self.components[-1] is self.concat\n",
    "        for component in self.components[:-1]:\n",
    "            dfs.append (component.transform (df))\n",
    "        df_result = self.concat.transform (*dfs)\n",
    "        return df_result\n",
    "    \n",
    "class ColumnTransformer (_BaseColumnTransformer):\n",
    "    def __init__ (self, *transformers, remainder = 'drop', **kwargs):\n",
    "        super().__init__ (**kwargs)\n",
    "        components = make_column_transformer_pipelines (*transformers, remainder=remainder, **kwargs)\n",
    "        super().set_components(*components)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96deb0d4-6ea7-4ca3-93e9-e4116012b06e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9a0de61d-786a-438c-ab75-f62629e8d614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class Identity (NoSaverComponent):\n",
    "    def __init__ (self,           \n",
    "                  verbose=dflt.verbose,\n",
    "                  force_verbose=False,\n",
    "                  logger=None,\n",
    "                  **kwargs):\n",
    "        verbose = 0 if not force_verbose else verbose\n",
    "        if verbose==0:\n",
    "            logger = set_empty_logger ()\n",
    "        super().__init__ (verbose=verbose,\n",
    "                          logger=logger,\n",
    "                          **kwargs)\n",
    "        \n",
    "    def _apply (self, X):\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5b9e71-2fd6-4520-bf38-e289df9fe291",
   "metadata": {
    "tags": []
   },
   "source": [
    "### make_column_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "84612d42-4080-4bdc-bffb-d288e246ae2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _append_pipeline (pipelines, name, transformer, columns, remainder= False, **kwargs):\n",
    "    drop = False\n",
    "    if isinstance(transformer, str):\n",
    "        if transformer == 'passthrough':\n",
    "            transformer = Identity (**kwargs)\n",
    "        elif transformer == 'drop':\n",
    "            drop = True\n",
    "        else:\n",
    "            raise ValueError (f'name {transformer} not recognized')\n",
    "    \n",
    "    if not drop:\n",
    "        config=kwargs.copy()\n",
    "        config.update({name:dict(data_io='NoSaverIO')})\n",
    "        pipeline = make_pipeline(ColumnSelector(columns, remainder=remainder, **kwargs), \n",
    "                                 transformer, \n",
    "                                 name=name,\n",
    "                                 **config)\n",
    "        pipelines.append (pipeline)\n",
    "\n",
    "def _get_transformer_name (transformer, columns):\n",
    "    columns_name = ''.join([x[0] for x in columns])\n",
    "    if len(columns_name) > 5:\n",
    "        columns_name = columns_name[:5]\n",
    "    if isinstance(transformer,str): \n",
    "        if transformer == 'passthrough':\n",
    "            transformer_name = 'pass'\n",
    "        elif transformer == 'drop':\n",
    "            transformer_name = 'drop'\n",
    "        else:\n",
    "            raise ValueError (f'name {transformer} not recognized')\n",
    "    elif hasattr(transformer, 'name'):\n",
    "        transformer_name = transformer.name\n",
    "    else:\n",
    "        transformer_name = transformer.__class__.__name__\n",
    "    name = f'{transformer_name}_{columns_name}'\n",
    "    return name\n",
    "        \n",
    "def make_column_transformer_pipelines (*transformers, remainder='drop', **kwargs):\n",
    "    pipelines = []\n",
    "    all_columns = []\n",
    "    for name, transformer, columns in transformers:\n",
    "        _append_pipeline (pipelines, name, transformer, columns, **kwargs)\n",
    "        all_columns.extend(columns)\n",
    "    \n",
    "    all_columns = list(set(all_columns))\n",
    "    name = _get_transformer_name (remainder, ['r','e','m'])\n",
    "    _append_pipeline (pipelines, name, remainder, all_columns, remainder=True, **kwargs)\n",
    "        \n",
    "    return pipelines\n",
    "\n",
    "def make_column_transformer (*transformers, remainder='drop', name=None, class_name=None, **kwargs):\n",
    "    transformers_with_name = []\n",
    "    for transformer, columns in transformers:\n",
    "        transformer_name = _get_transformer_name (transformer, columns)\n",
    "        transformers_with_name.append ((transformer_name, transformer, columns))\n",
    "    \n",
    "    pipelines = make_column_transformer_pipelines (*transformers_with_name, \n",
    "                                                   remainder=remainder, \n",
    "                                                   **kwargs)\n",
    "    column_transformer = _BaseColumnTransformer (name=name, class_name=class_name, **kwargs)\n",
    "    column_transformer.set_components(*pipelines)\n",
    "    return column_transformer\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452c4524-22ae-4bf6-8604-eef035102090",
   "metadata": {},
   "source": [
    "#### Simple example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bb651e51-0619-47fe-acb1-ffad1fc9e1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports tests.core.test_compose\n",
    "def column_transformer_data ():\n",
    "    df = pd.DataFrame ({'cont1': list(range(5)),\n",
    "                        'cont2': list(range(5,10)),\n",
    "                        'cont3': list(range(15,20)),\n",
    "                        'cont4': list(range(25,30)),\n",
    "                        'cat_1': list([1,2,3,2,1]),\n",
    "                        'cat_2': list([0,1,1,0,0])\n",
    "                        })\n",
    "        \n",
    "    tr1 = Component(FunctionTransformer (lambda x: x+1), name='tr1')\n",
    "    \n",
    "    return df, tr1\n",
    "        \n",
    "#@pytest.mark.reference_fails\n",
    "def test_make_column_transformer (column_transformer_data):\n",
    "\n",
    "    df, tr1 = column_transformer_data\n",
    "\n",
    "    tr1 = Component(FunctionTransformer (lambda x: x+1), name='tr1')\n",
    "    tr2 = PandasComponent(FunctionTransformer (lambda x: x*2), transformed_columns=['cont2_bis','cat_1'], name='tr2')\n",
    "\n",
    "    column_transformer = make_column_transformer (\n",
    "        (tr1, ['cont2', 'cont4']),\n",
    "        (tr2, ['cont2', 'cat_1'])\n",
    "    )\n",
    "    dfr = column_transformer.transform(df)\n",
    "\n",
    "    # display and test\n",
    "    display(dfr)\n",
    "    assert (dfr[['cont2','cont4']] == tr1(df[['cont2','cont4']])).all().all()\n",
    "    assert (dfr[['cont2_bis','cat_1']] == tr2(df[['cont2','cat_1']])).all().all()\n",
    "    assert (dfr.columns == ['cont2','cont4', 'cont2_bis','cat_1']).all()\n",
    "    assert (column_transformer.name, column_transformer.class_name) == ('__base_column_transformer', '_BaseColumnTransformer')\n",
    "\n",
    "    # set name of column transformer\n",
    "    column_transformer = make_column_transformer (\n",
    "        (tr1, ['cont2', 'cont4']),\n",
    "        (tr2, ['cont2', 'cat_1']),\n",
    "        name='test_transformer',\n",
    "        class_name='TestTransformer'\n",
    "    )\n",
    "    assert (column_transformer.name, column_transformer.class_name) == ('test_transformer', 'TestTransformer')\n",
    "\n",
    "    # set name of column transformer and parameters that are specific \n",
    "    # for the column_transformer: path_results\n",
    "    column_transformer = make_column_transformer (\n",
    "        (tr1, ['cont2', 'cont4']),\n",
    "        (tr2, ['cont2', 'cat_1']),\n",
    "        name='test_transformer',\n",
    "        class_name='TestTransformer',\n",
    "        TestTransformer=dict(path_results='mine'),\n",
    "        path_results='other'\n",
    "    )\n",
    "    assert column_transformer.path_results.name=='mine'\n",
    "    assert column_transformer.components[0].path_results.name=='other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ab06c055-3f31-4daa-a7f6-5a11f0717089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test_make_column_transformer\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cont2</th>\n",
       "      <th>cont4</th>\n",
       "      <th>cont2_bis</th>\n",
       "      <th>cat_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>27</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>28</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>29</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cont2  cont4  cont2_bis  cat_1\n",
       "0      6     26         10      2\n",
       "1      7     27         12      4\n",
       "2      8     28         14      6\n",
       "3      9     29         16      4\n",
       "4     10     30         18      2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tst.run (test_make_column_transformer, column_transformer_data, tag='dummy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53cf0b4-27cb-41b1-af4a-e4fb90e4db0b",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Using `passthrough`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "03fd5029-f597-4f82-a163-8cadf58b448e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports tests.core.test_compose\n",
    "#@pytest.mark.reference_fails\n",
    "def test_make_column_transformer_passthrough (column_transformer_data):\n",
    "    df, tr1 = column_transformer_data\n",
    "    \n",
    "    column_transformer = make_column_transformer (\n",
    "        (tr1, ['cont1', 'cont4']),\n",
    "        ('passthrough', ['cont2', 'cat_1'])\n",
    "    )\n",
    "    dfr = column_transformer.transform(df)\n",
    "\n",
    "    # display and test\n",
    "    display(dfr)\n",
    "    assert (dfr[['cont1','cont4']] == tr1(df[['cont1','cont4']])).all().all()\n",
    "    assert (dfr[['cont2','cat_1']] == df[['cont2','cat_1']]).all().all()\n",
    "    assert (dfr.columns == ['cont1','cont4', 'cont2','cat_1']).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5ebcea56-538f-4c93-8236-c0f1a7ccfca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test_make_column_transformer_passthrough\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cont1</th>\n",
       "      <th>cont4</th>\n",
       "      <th>cont2</th>\n",
       "      <th>cat_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cont1  cont4  cont2  cat_1\n",
       "0      1     26      5      1\n",
       "1      2     27      6      2\n",
       "2      3     28      7      3\n",
       "3      4     29      8      2\n",
       "4      5     30      9      1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tst.run (test_make_column_transformer_passthrough, column_transformer_data, tag='dummy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6e2d65-5af2-40f6-ab14-9d7bc8eab23f",
   "metadata": {},
   "source": [
    "#### Using remainder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "01424528-9645-4a80-a60e-7f0e6c77d4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports tests.core.test_compose\n",
    "#@pytest.mark.reference_fails\n",
    "def test_make_column_transformer_remainder (column_transformer_data):\n",
    "    \n",
    "    df, tr1 = column_transformer_data\n",
    "    \n",
    "    # remainder is new transformation\n",
    "    tr3 = Component(FunctionTransformer (lambda x: x+100), name='tr3')\n",
    "    column_transformer = make_column_transformer (\n",
    "        (tr1, ['cont1', 'cont4']),\n",
    "        ('passthrough', ['cont2', 'cat_1']),\n",
    "        remainder=tr3\n",
    "    )\n",
    "    dfr = column_transformer.transform(df)\n",
    "\n",
    "    # display and test\n",
    "    display('with tr3', dfr)\n",
    "    assert (dfr[['cont1','cont4']] == tr1(df[['cont1','cont4']])).all().all()\n",
    "    assert (dfr[['cont2','cat_1']] == df[['cont2','cat_1']]).all().all()\n",
    "    assert (dfr[['cont3','cat_2']] == tr3(df[['cont3','cat_2']])).all().all()\n",
    "    assert (dfr.columns == ['cont1','cont4', 'cont2','cat_1','cont3','cat_2']).all()\n",
    "\n",
    "    # remainder is passthrough\n",
    "    del tr1.nick_name\n",
    "    del tr3.nick_name\n",
    "    column_transformer = make_column_transformer (\n",
    "        (tr1, ['cont1', 'cont4']),\n",
    "        (tr3, ['cont2', 'cat_1']),\n",
    "        remainder='passthrough'\n",
    "    )\n",
    "    dfr = column_transformer.transform(df)\n",
    "\n",
    "    display('with passthrough', dfr)\n",
    "    assert (dfr[['cont1','cont4']] == tr1(df[['cont1','cont4']])).all().all()\n",
    "    assert (dfr[['cont2','cat_1']] == tr3(df[['cont2','cat_1']])).all().all()\n",
    "    assert (dfr[['cont3','cat_2']] == df[['cont3','cat_2']]).all().all()\n",
    "    assert (dfr.columns == ['cont1','cont4', 'cont2','cat_1','cont3','cat_2']).all()\n",
    "\n",
    "    # remainder is tr3, and one of the transforms is drop\n",
    "    del tr1.nick_name\n",
    "    del tr3.nick_name\n",
    "    column_transformer = make_column_transformer (\n",
    "        (tr1, ['cont1', 'cont4']),\n",
    "        ('drop', ['cont2', 'cat_1']),\n",
    "        remainder=tr3\n",
    "    )\n",
    "    dfr = column_transformer.transform(df)\n",
    "\n",
    "    display('with drop one of the transforms - cont2, cat_1', dfr)\n",
    "    assert (dfr[['cont1','cont4']] == tr1(df[['cont1','cont4']])).all().all()\n",
    "    assert (dfr[['cont3','cat_2']] == tr3(df[['cont3','cat_2']])).all().all()\n",
    "    assert (dfr.columns == ['cont1','cont4', 'cont3','cat_2']).all()\n",
    "    \n",
    "    # check gather_descendants\n",
    "    column_transformer.gather_descendants()\n",
    "    assert sorted(column_transformer.full_obj.keys())==['column_selector', 'concat', 'tr1', 'tr1_cc', 'tr3', 'tr3_rem']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3d90d630-e296-48ee-b5dd-5c0833a0b7ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test_make_column_transformer_remainder\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'with tr3'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cont1</th>\n",
       "      <th>cont4</th>\n",
       "      <th>cont2</th>\n",
       "      <th>cat_1</th>\n",
       "      <th>cont3</th>\n",
       "      <th>cat_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>115</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>116</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>117</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>118</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>119</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cont1  cont4  cont2  cat_1  cont3  cat_2\n",
       "0      1     26      5      1    115    100\n",
       "1      2     27      6      2    116    101\n",
       "2      3     28      7      3    117    101\n",
       "3      4     29      8      2    118    100\n",
       "4      5     30      9      1    119    100"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'with passthrough'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cont1</th>\n",
       "      <th>cont4</th>\n",
       "      <th>cont2</th>\n",
       "      <th>cat_1</th>\n",
       "      <th>cont3</th>\n",
       "      <th>cat_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>105</td>\n",
       "      <td>101</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>106</td>\n",
       "      <td>102</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>107</td>\n",
       "      <td>103</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>108</td>\n",
       "      <td>102</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>109</td>\n",
       "      <td>101</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cont1  cont4  cont2  cat_1  cont3  cat_2\n",
       "0      1     26    105    101     15      0\n",
       "1      2     27    106    102     16      1\n",
       "2      3     28    107    103     17      1\n",
       "3      4     29    108    102     18      0\n",
       "4      5     30    109    101     19      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'with drop one of the transforms - cont2, cat_1'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cont1</th>\n",
       "      <th>cont4</th>\n",
       "      <th>cont3</th>\n",
       "      <th>cat_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>115</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>116</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>117</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>118</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>119</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cont1  cont4  cont3  cat_2\n",
       "0      1     26    115    100\n",
       "1      2     27    116    101\n",
       "2      3     28    117    101\n",
       "3      4     29    118    100\n",
       "4      5     30    119    100"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tst.run (test_make_column_transformer_remainder, column_transformer_data, tag='dummy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b4cbac-4ad8-4db3-877d-940e5bd56037",
   "metadata": {},
   "source": [
    "#### gather_descendants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1faa72c8-e3d0-4c3b-bfe1-356d5c541652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports tests.core.test_compose\n",
    "#@pytest.mark.reference_fails\n",
    "def test_make_column_transformer_descendants (column_transformer_data):\n",
    "    \n",
    "    df, tr1 = column_transformer_data\n",
    "    \n",
    "    tr3 = Component(FunctionTransformer (lambda x: x+100), name='tr3')\n",
    "    \n",
    "    column_transformer = make_column_transformer (\n",
    "        (tr1, ['cont1', 'cont4']),\n",
    "        ('drop', ['cont2', 'cat_1']),\n",
    "        remainder=tr3\n",
    "    )\n",
    "    \n",
    "    # check gather_descendants\n",
    "    column_transformer.gather_descendants()\n",
    "    assert sorted(column_transformer.full_obj.keys())==['column_selector', 'concat', 'tr1', 'tr1_cc', 'tr3', 'tr3_rem']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cd68e49e-5411-4cb6-a5d0-400f1dd607fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test_make_column_transformer_descendants\n"
     ]
    }
   ],
   "source": [
    "tst.run (test_make_column_transformer_descendants, column_transformer_data, tag='dummy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00994218-f5a5-44af-858d-6e2d07a011fa",
   "metadata": {},
   "source": [
    "#### Example using `fit_transform`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "176ae8ff-ec31-48f7-b4be-8723da40d5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports tests.core.test_compose\n",
    "#@pytest.mark.reference_fails\n",
    "def test_make_column_transformer_fit_transform (column_transformer_data):\n",
    "    \n",
    "    df, tr1 = column_transformer_data\n",
    "    \n",
    "    class SumTimes100 (Component):\n",
    "        def _fit (self, X, y=None):\n",
    "            self.sum = X.sum(axis=0)\n",
    "        def _apply (self, X):\n",
    "\n",
    "            dfr = pd.DataFrame ({'c1_times100': self.sum.values[0]*100 + X.iloc[:,0].values,\n",
    "                                 'c2_times100': self.sum.values[1]*100 + X.iloc[:,1].values,\n",
    "                                 'c2_times1000': self.sum.values[1]*1000 + X.iloc[:,1].values})\n",
    "            return dfr\n",
    "\n",
    "    tr1 = SumTimes100 ()\n",
    "    tr2 = PandasComponent(FunctionTransformer (lambda x: x*2), name='tr2')\n",
    "\n",
    "    column_transformer = make_column_transformer (\n",
    "        (tr1, ['cont2', 'cont4']),\n",
    "        (tr2, ['cont2', 'cat_1'])\n",
    "    )\n",
    "    dfr = column_transformer.fit_transform(df)\n",
    "\n",
    "    # display & test\n",
    "    display(dfr)\n",
    "    assert (dfr.columns == ['c1_times100','c2_times100', 'c2_times1000','cont2', 'cat_1']).all()\n",
    "    assert (dfr['c1_times100'] == sum(df.cont2)*100+df.cont2).all()\n",
    "    assert (dfr['c2_times100'] == sum(df.cont4)*100+df.cont4).all()\n",
    "    assert (dfr['c2_times1000'] == sum(df.cont4)*1000+df.cont4).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8a5799e1-ce4a-4ea9-a328-51ccac19ccd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test_make_column_transformer_fit_transform\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c1_times100</th>\n",
       "      <th>c2_times100</th>\n",
       "      <th>c2_times1000</th>\n",
       "      <th>cont2</th>\n",
       "      <th>cat_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3505</td>\n",
       "      <td>13525</td>\n",
       "      <td>135025</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3506</td>\n",
       "      <td>13526</td>\n",
       "      <td>135026</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3507</td>\n",
       "      <td>13527</td>\n",
       "      <td>135027</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3508</td>\n",
       "      <td>13528</td>\n",
       "      <td>135028</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3509</td>\n",
       "      <td>13529</td>\n",
       "      <td>135029</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   c1_times100  c2_times100  c2_times1000  cont2  cat_1\n",
       "0         3505        13525        135025     10      2\n",
       "1         3506        13526        135026     12      4\n",
       "2         3507        13527        135027     14      6\n",
       "3         3508        13528        135028     16      4\n",
       "4         3509        13529        135029     18      2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tst.run (test_make_column_transformer_fit_transform, column_transformer_data, tag='dummy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ebb69a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## MultiSplitComponent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "450548a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class MultiSplitComponent (MultiComponent):\n",
    "    def __init__ (self, \n",
    "                  component=None, \n",
    "                  name=None,\n",
    "                  class_name=None,\n",
    "                  fit_to = 'training',\n",
    "                  fit_additional = [],\n",
    "                  apply_to = ['training', 'validation', 'test'],\n",
    "                  raise_error_if_split_doesnot_exist=False,\n",
    "                  raise_warning_if_split_doesnot_exist=True,\n",
    "                  **kwargs):\n",
    "        if class_name is None:\n",
    "            if hasattr(component, 'class_name'):\n",
    "                class_name = f'{component.class_name}MultiSplit'\n",
    "            else:\n",
    "                class_name = f'{component.__class__.__name__}MultiSplit'\n",
    "\n",
    "        if name is None:\n",
    "            if hasattr(component, 'name'):\n",
    "                name = f'{component.name}_multi_split'\n",
    "            else:\n",
    "                name = f'{component.__class__.__name__}_multi_split'\n",
    "\n",
    "        super().__init__ (name=name, class_name=class_name, **kwargs)\n",
    "    \n",
    "    def _fit (self, X, y=None):\n",
    "        if not isinstance(X, dict):\n",
    "            X = {self.fit_to: X}\n",
    "        component = self.components[0]\n",
    "        additional_data = {}\n",
    "        for split in self.fit_additional:\n",
    "            if split not in ['validation', 'test']:\n",
    "                raise ValueError (f'split {split} not valid')\n",
    "            if split in X.keys():\n",
    "                additional_data[f'{split}_data'] = X[split]\n",
    "            else:\n",
    "                self._issue_error_or_warning (split, X)\n",
    "        \n",
    "        component.fit(X[self.fit_to], y=y, split='training', **additional_data)\n",
    "    \n",
    "    def _issue_error_or_warning (self, split, X):\n",
    "        message = f'split {split} not found in X keys ({X.keys()})'\n",
    "        if self.raise_error_if_split_doesnot_exist:\n",
    "            raise RuntimeError (message)\n",
    "        elif self.raise_warning_if_split_doesnot_exist:\n",
    "            warnings.warn (message)\n",
    "    \n",
    "    def _apply (self, X, apply_to = None, output_not_dict=False, split=None, **kwargs):\n",
    "        apply_to = self.apply_to if apply_to is None else apply_to\n",
    "        apply_to = apply_to if isinstance(apply_to, list) else [apply_to]\n",
    "        if not isinstance(X, dict):\n",
    "            key = apply_to[0] if len(apply_to)==1 else split if split is not None else 'test'\n",
    "            X = {key: X}\n",
    "            input_not_dict = True\n",
    "        else:\n",
    "            input_not_dict = False\n",
    "            \n",
    "        component = self.components[0]\n",
    "        result = {}\n",
    "        for split in apply_to:\n",
    "            if split in X.keys():\n",
    "                result[split] = component.apply (X[split], split=split, **kwargs)\n",
    "            else:\n",
    "                self._issue_error_or_warning (split, X)\n",
    "        \n",
    "        if input_not_dict:\n",
    "            result = result[key]\n",
    "        elif output_not_dict and len(result)==1:\n",
    "            result = list(result.items())[0][1]\n",
    "        return result\n",
    "        \n",
    "    def find_last_result (self, apply_to = None, split=None, **kwargs):\n",
    "        apply_to = self.apply_to if apply_to is None else apply_to\n",
    "        apply_to = apply_to if isinstance(apply_to, list) else [apply_to]\n",
    "\n",
    "        self.is_data_source = True\n",
    "        for split in apply_to:\n",
    "            if not (component.data_io.can_load_result () and component.data_io.exists_result (split=split)):\n",
    "                if isinstance (component, MultiComponent):\n",
    "                    # TODO: have one flag is_data_source per split\n",
    "                    # or make MultiSplitComponent a Parallel object\n",
    "                    # or always use DataFrame\n",
    "                    self.is_data_source = self.is_data_source and component.find_last_result (split=split)\n",
    "                else:\n",
    "                    self.is_data_source = False\n",
    "        return self.is_data_source\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468ea301",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Tests / usage examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06ac335-6c4f-4efd-9d0e-003ada88881c",
   "metadata": {},
   "source": [
    "#### apply transform on multiple splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b90b5e2f-153c-45f1-a886-3d73fa7c24a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports tests.core.test_compose\n",
    "class Transform1 (Component):\n",
    "    def __init__ (self, **kwargs):\n",
    "        super().__init__ (**kwargs)\n",
    "        self.estimator= Bunch(sum = 1)\n",
    "\n",
    "    def _fit (self, X, y=None):\n",
    "        self.estimator.sum = X.sum(axis=0)\n",
    "\n",
    "    def _apply (self, x):\n",
    "        return x*1000 + self.estimator.sum\n",
    "    \n",
    "class Transform2 (Component):\n",
    "    def __init__ (self, **kwargs):\n",
    "        super().__init__ (**kwargs)\n",
    "        self.estimator= Bunch(maxim = 1)\n",
    "\n",
    "    def _fit (self, X, y=None, validation_data=None, test_data=None):\n",
    "        self.estimator.maxim = X.max(axis=0)\n",
    "\n",
    "        print (f'validation_data: {validation_data}')\n",
    "        print (f'test_data: {test_data}')\n",
    "\n",
    "        self.data = dict (validation=validation_data,\n",
    "                          test=test_data)\n",
    "\n",
    "    def _apply (self, x):\n",
    "        return x*100 + self.estimator.maxim\n",
    "\n",
    "def multi_split_data ():\n",
    "    data = dict(training = np.array([1,2,3]).reshape(-1,1),\n",
    "            validation = np.array([10,20,30]).reshape(-1,1),\n",
    "            test = np.array([100,200,300]).reshape(-1,1)\n",
    "            )\n",
    "    \n",
    "    multi_transform1 = MultiSplitComponent (component = Transform1())\n",
    "    \n",
    "    tr2 = Transform2()\n",
    "    multi_transform2 = MultiSplitComponent (component=tr2,\n",
    "                                            fit_additional = ['validation', 'test'])\n",
    "    \n",
    "    return data, multi_transform1, multi_transform2, tr2\n",
    "\n",
    "#@pytest.mark.reference_fails\n",
    "def test_multi_split_transform (multi_split_data):\n",
    "    # example 1: apply transform on multiple splits\n",
    "    data, multi_transform1, multi_transform2, tr2 = multi_split_data\n",
    "    \n",
    "    result = multi_transform1.fit_transform (data)\n",
    "\n",
    "    assert type(result) is dict\n",
    "    assert result.keys() == data.keys()\n",
    "    for split in result.keys():\n",
    "        assert (result[split]==sum(data['training'].ravel())+data[split]*1000).all()\n",
    "\n",
    "    # check that automatic name given is based on component\n",
    "    assert multi_transform1.name=='transform1_multi_split'\n",
    "    assert multi_transform1.class_name=='Transform1MultiSplit'\n",
    "\n",
    "    # check that we can assign a different name\n",
    "    multi_transform1 = MultiSplitComponent (component = Transform1(), name='different', class_name='Yes')\n",
    "    assert multi_transform1.name=='different'\n",
    "    assert multi_transform1.class_name=='Yes'\n",
    "    # check that this new name is given only to MultiSplitComponent, \n",
    "    # not to the component that it's wrapping\n",
    "    assert multi_transform1.component.name=='transform1'\n",
    "    assert multi_transform1.component.class_name=='Transform1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "00f8372c-4b02-41e5-b702-f4d3c2d0b9be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test_multi_split_transform\n"
     ]
    }
   ],
   "source": [
    "tst.run (test_multi_split_transform, multi_split_data, tag='dummy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b14fb68-e261-4c7c-b741-5ec653596910",
   "metadata": {},
   "source": [
    "#### fit method gets training, validation and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "476d31ea-5432-470f-83d1-23ba038c1ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports tests.core.test_compose\n",
    "#@pytest.mark.reference_fails\n",
    "def test_multi_split_fit (multi_split_data):\n",
    "    # example 2: fit method gets training, validation and test\n",
    "    data, multi_transform1, multi_transform2, tr2 = multi_split_data\n",
    "    # we apply the transform to only test\n",
    "    \n",
    "\n",
    "    # we apply the transform to only test data\n",
    "    result = multi_transform2.fit_transform (data, apply_to='test')\n",
    "\n",
    "    assert type(result) is dict\n",
    "    assert list(result.keys()) == ['test']\n",
    "    for split in result.keys():\n",
    "        assert (result[split]==max(data['training'].ravel())+data[split]*100).all()\n",
    "\n",
    "    for split in ['validation', 'test']:\n",
    "        assert (tr2.data[split] == data[split]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "75d7be15-9e4e-4b19-b021-63b40c6c0fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test_multi_split_fit\n",
      "validation_data: [[10]\n",
      " [20]\n",
      " [30]]\n",
      "test_data: [[100]\n",
      " [200]\n",
      " [300]]\n"
     ]
    }
   ],
   "source": [
    "tst.run (test_multi_split_fit, multi_split_data, tag='dummy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3b93cd-645f-4e07-b363-6e766ca25398",
   "metadata": {},
   "source": [
    "#### chain transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7abace90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports tests.core.test_compose\n",
    "#@pytest.mark.reference_fails\n",
    "def test_multi_split_chain (multi_split_data):\n",
    "    data, multi_transform1, multi_transform2, tr2 = multi_split_data\n",
    "    \n",
    "    # test that we can chain transformations\n",
    "\n",
    "    result = multi_transform1.fit_transform (data)\n",
    "    result = multi_transform2.fit_transform (result, apply_to='test')\n",
    "\n",
    "    import pytest \n",
    "\n",
    "    #check that we have no error if split does not exist\n",
    "    result = multi_transform1.fit_transform (data, apply_to=['training', 'validation'])\n",
    "    result = multi_transform2.fit_transform (result, apply_to=['test'])\n",
    "    assert len(result)==0\n",
    "\n",
    "    #check that we have an error if we set the flag `raise_error_if_split_doesnot_exist=True`\n",
    "    multi_transform2.raise_error_if_split_doesnot_exist = True\n",
    "    result = multi_transform1.fit_transform (data, apply_to=['training', 'validation'])\n",
    "    with pytest.raises (RuntimeError):\n",
    "        result = multi_transform2.fit_transform (result, apply_to=['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "906832b1-71d7-4956-a20d-43cbb42e3f5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test_multi_split_chain\n",
      "validation_data: [[10006]\n",
      " [20006]\n",
      " [30006]]\n",
      "test_data: [[100006]\n",
      " [200006]\n",
      " [300006]]\n",
      "validation_data: [[10006]\n",
      " [20006]\n",
      " [30006]]\n",
      "test_data: None\n"
     ]
    }
   ],
   "source": [
    "tst.run (test_multi_split_chain, multi_split_data, tag='dummy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37de82ce-de20-43c5-9540-c43642b15ee7",
   "metadata": {},
   "source": [
    "#### loading / saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "704b6354",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# exports tests.core.test_compose\n",
    "#@pytest.mark.reference_fails\n",
    "def test_multi_split_io (multi_split_data):\n",
    "    \n",
    "    data, multi_transform1, multi_transform2, tr2 = multi_split_data\n",
    "    \n",
    "    # check loading / saving\n",
    "    from block_types.utils.utils import remove_previous_results\n",
    "    from block_types.core.utils import PickleIO\n",
    "\n",
    "    path_results = 'results_multi_split'\n",
    "\n",
    "    remove_previous_results (path_results=path_results)\n",
    "\n",
    "    tr = PickleSaverComponent (FunctionTransformer (lambda x: x*2),\n",
    "                    name='times2',\n",
    "                    path_results=path_results)\n",
    "\n",
    "    multi_transform = MultiSplitComponent (component=tr,\n",
    "                                           apply_to = ['validation', 'test'],\n",
    "                                           path_results = path_results,\n",
    "                                           data_io=PickleIO (path_results = path_results))\n",
    "\n",
    "    result = multi_transform (data)\n",
    "\n",
    "    multi_transform2 = MultiSplitComponent (data_io=PickleIO (path_results = path_results), name='times2_multi_split')\n",
    "\n",
    "    result2 = multi_transform2.data_io.load_result ()\n",
    "\n",
    "    for k in result.keys():\n",
    "        assert (result[k] == result2[k]).all()\n",
    "\n",
    "    assert result.keys()==result2.keys()\n",
    "\n",
    "    assert sorted(os.listdir(path_results))==['test', 'validation', 'whole']\n",
    "\n",
    "    assert (tr.data_io.load_result(split='test') == result['test']).all()\n",
    "\n",
    "    assert (tr.data_io.load_result(split='validation') == result['validation']).all()\n",
    "\n",
    "    assert os.listdir(f'{path_results}/validation')==['times2_result.pk']\n",
    "\n",
    "    assert os.listdir(f'{path_results}/test')==['times2_result.pk']\n",
    "\n",
    "    assert os.listdir(f'{path_results}/whole')==['times2_multi_split_result.pk']\n",
    "\n",
    "    remove_previous_results (path_results=path_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7e75a9b8-0335-4bda-a333-d8f96ef56152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test_multi_split_io\n"
     ]
    }
   ],
   "source": [
    "tst.run (test_multi_split_io, multi_split_data, tag='dummy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca94e1bf-39e4-4e20-8548-43a01ecd8742",
   "metadata": {},
   "source": [
    "### With non-dictionary input / output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2e40a7c6-8546-4abe-b07c-066c48dc555d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports tests.core.test_compose\n",
    "#@pytest.mark.reference_fails\n",
    "def test_multi_split_non_dict ():\n",
    "    # check loading / saving\n",
    "    tr = Component (FunctionTransformer (lambda x: x*2))\n",
    "\n",
    "    multi_transform = MultiSplitComponent (tr, apply_to = ['test'])\n",
    "\n",
    "    data = np.array([100,200,300]).reshape(-1,1)\n",
    "    result = multi_transform (data)\n",
    "\n",
    "    assert type(result)==np.ndarray\n",
    "    assert (result==data*2).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "dece23e3-823a-4fa5-bc8a-2c1e43faa52d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test_multi_split_non_dict\n"
     ]
    }
   ],
   "source": [
    "tst.run (test_multi_split_non_dict, tag='dummy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19c3b90-f00c-44ab-81bc-e3b27b50b41e",
   "metadata": {},
   "source": [
    "output applied to single split, converted to non-dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e9daee36-e729-4bb7-9570-65fbc9014d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports tests.core.test_compose\n",
    "#@pytest.mark.reference_fails\n",
    "def test_multi_split_non_dict_bis ():\n",
    "    tr = Component (FunctionTransformer (lambda x: x*2))\n",
    "\n",
    "    multi_transform = MultiSplitComponent (tr, apply_to = ['test'])\n",
    "    \n",
    "    # output applied to single split, converted to non-dictionary\n",
    "    data = dict(training = np.array([1,2,3]).reshape(-1,1),\n",
    "                validation = np.array([10,20,30]).reshape(-1,1),\n",
    "                test = np.array([100,200,300]).reshape(-1,1))\n",
    "    result = multi_transform (data, output_not_dict=True)\n",
    "\n",
    "    assert type(result)==np.ndarray\n",
    "    assert (result==data['test']*2).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "fb5d3190-e661-4dc3-be3d-5f5a252874ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test_multi_split_non_dict_bis\n"
     ]
    }
   ],
   "source": [
    "tst.run (test_multi_split_non_dict_bis, tag='dummy')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (block_types)",
   "language": "python",
   "name": "block_types"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
