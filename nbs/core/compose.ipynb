{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccd85e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "# default_exp core.compose\n",
    "from nbdev.showdoc import *\n",
    "from block_types.utils.nbdev_utils import nbdev_setup, TestRunner\n",
    "\n",
    "nbdev_setup ()\n",
    "tst = TestRunner (targets=['dummy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434bfb86",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Compose components\n",
    "\n",
    "> Classes and utilities for composed components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44f392e1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from sklearn.utils import Bunch\n",
    "\n",
    "try:\n",
    "    from graphviz import *\n",
    "    imported_graphviz = True\n",
    "except:\n",
    "    imported_graphviz = False\n",
    "\n",
    "from block_types.core.block_types import (Component, \n",
    "                                          PandasComponent, \n",
    "                                          SamplingComponent,\n",
    "                                          NoSaverComponent)\n",
    "from block_types.core.data_conversion import PandasConverter\n",
    "from block_types.core.utils import PandasIO\n",
    "from block_types.utils.utils import get_logging_level\n",
    "import block_types.config.bt_defaults as dflt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2082f19d-a4df-45c7-bb19-92a48af413a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for tests\n",
    "from pathlib import Path\n",
    "import pytest \n",
    "import time\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import Bunch\n",
    "\n",
    "from block_types.core.block_types import PickleSaverComponent\n",
    "from block_types.utils.utils import remove_previous_results\n",
    "from block_types.core.utils import PickleIO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571bbae6-9f63-4b84-8813-a45a58c1215e",
   "metadata": {},
   "source": [
    "## MultiComponent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ca1edc7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export\n",
    "class MultiComponent (SamplingComponent):\n",
    "    \"\"\"\n",
    "    Component containing a list of components inside.\n",
    "    \n",
    "    The list must contain at least one component. \n",
    "    \n",
    "    See `Pipeline` class.\n",
    "    \"\"\"\n",
    "    def __init__ (self, \n",
    "                  separate_labels=False, \n",
    "                  warning_if_nick_name_exists=False,\n",
    "                  **kwargs):\n",
    "        \"\"\"Assigns attributes and calls parent constructor.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        separate_labels: bool, optional\n",
    "            whether or not the fit method receives the labels in a separate `y` vector \n",
    "            or in the same input `X`, as an additional variable. See description of \n",
    "            Pipeline class for more details.\n",
    "        \"\"\"\n",
    "        if 'estimator' in kwargs:\n",
    "            self.logger.warning ('estimator passed as key-word argument in MultiComponent')\n",
    "        \n",
    "        if not hasattr (self, 'components'):\n",
    "            self.components = []\n",
    "        if not hasattr (self, 'finalized_component_list'):\n",
    "            self.finalized_component_list = False\n",
    "        \n",
    "        # we need to call super().__init__() *after* having creating the `components` field,\n",
    "        # since the constructor of Component calls a method that is overriden in Pipeline, \n",
    "        # and this method makes use of the mentioned `components` field\n",
    "        super().__init__ (separate_labels = separate_labels, \n",
    "                          **kwargs)\n",
    "\n",
    "        self.set_split ('whole')\n",
    "        \n",
    "    \n",
    "    def register_components (self, *components):\n",
    "        \"\"\"\n",
    "        Registering component in `self.components` list.\n",
    "        \n",
    "        Every time that a new component is set as an attribute of the pipeline,\n",
    "        this component is added to the list `self.components`. Same \n",
    "        mechanism as the one used by pytorch's `nn.Module`\n",
    "        \"\"\"\n",
    "        if not hasattr(self, 'components'):\n",
    "            self.components = []\n",
    "            self.finalized_component_list = False\n",
    "        if not self.finalized_component_list:\n",
    "            self.components += components\n",
    "    \n",
    "    def __setattr__(self, k, v):\n",
    "        \"\"\"\n",
    "        See register_components\n",
    "        \"\"\"\n",
    "        super().__setattr__(k, v)\n",
    "        \n",
    "        if isinstance(v, Component):\n",
    "            self.register_components(v)\n",
    "            if not hasattr(self, v.name):\n",
    "                super().__setattr__(v.name, v)\n",
    "            if not self.finalized_component_list:\n",
    "                if hasattr(v, 'nick_name') and self.warning_if_nick_name_exists:\n",
    "                    self.logger.warning (f'{v} already has a nick_name: {v.nick_name}')\n",
    "                    warnings.warn (f'{v} already has a nick_name: {v.nick_name}')\n",
    "                v.nick_name = k\n",
    "            \n",
    "    def add_component (self, component):\n",
    "        if not hasattr(self, 'finalized_component_list'):\n",
    "            self.finalized_component_list = False\n",
    "        finalized_component_list = self.finalized_component_list\n",
    "        self.finalized_component_list = False\n",
    "        self.register_components(component)\n",
    "        self.finalized_component_list = finalized_component_list\n",
    "        \n",
    "        if hasattr(component, 'nick_name') and self.warning_if_nick_name_exists:\n",
    "            self.logger.warning (f'{component} already has a nick_name: {component.nick_name}')\n",
    "            warnings.warn (f'{component} already has a nick_name: {component.nick_name}')\n",
    "        component.nick_name = component.name\n",
    "        if not hasattr(self, component.name):\n",
    "            super().__setattr__ (component.name, component)\n",
    "        \n",
    "    def set_components (self, *components):\n",
    "        self.components = components\n",
    "        self.finalized_component_list = True\n",
    "        for component in components:\n",
    "            if hasattr(component, 'nick_name') and self.warning_if_nick_name_exists:\n",
    "                self.logger.warning (f'{component} already has a nick_name: {component.nick_name}')\n",
    "                warnings.warn (f'{component} already has a nick_name: {component.nick_name}')\n",
    "            component.nick_name = component.name\n",
    "            if not hasattr(self, component.name):\n",
    "                super().__setattr__ (component.name, component)\n",
    "        \n",
    "    def clear_descendants (self):\n",
    "        self.cls = Bunch ()\n",
    "        self.obj = Bunch ()\n",
    "        self.full_obj = Bunch ()\n",
    "        self.full_cls = Bunch ()\n",
    "        for component in self.components:\n",
    "            if isinstance(component, MultiComponent):\n",
    "                component.clear_descendants ()\n",
    "            \n",
    "    def gather_descendants (self, root='', nick_name=True):\n",
    "        if not hasattr (self, 'cls'):\n",
    "            self.cls = Bunch ()\n",
    "            self.obj = Bunch ()\n",
    "            self.full_obj = Bunch ()\n",
    "            self.full_cls = Bunch ()\n",
    "            \n",
    "        if hasattr(self, 'nick_name'):\n",
    "            name = self.nick_name if nick_name else self.name\n",
    "        else:\n",
    "            name = self.name\n",
    "        self.hierarchy_path = f'{root}{name}'\n",
    "        for component in self.components:\n",
    "            self._insert_descendant (self.cls, component, component.class_name)\n",
    "            self._insert_descendant (self.obj, component, component.name)\n",
    "            \n",
    "            name = component.nick_name if nick_name else component.name\n",
    "            component_hierarchy_path = f'{self.hierarchy_path}.{name}'\n",
    "            self._insert_descendant (self.full_cls, component_hierarchy_path, component.class_name)\n",
    "            self._insert_descendant (self.full_obj, component_hierarchy_path, component.name)\n",
    "            if isinstance(component, MultiComponent):\n",
    "                component.gather_descendants (root=f'{self.hierarchy_path}.',\n",
    "                                              nick_name=nick_name)\n",
    "                for name in component.cls:\n",
    "                    self._insert_descendant (self.cls, component.cls[name], name)\n",
    "                    self._insert_descendant (self.full_cls, component.full_cls[name], name)\n",
    "                for name in component.obj:\n",
    "                    self._insert_descendant (self.obj, component.obj[name], name)\n",
    "                    self._insert_descendant (self.full_obj, component.full_obj[name], name)\n",
    "                           \n",
    "    def _insert_descendant (self, cmp_dict, component, name):\n",
    "        if name in cmp_dict:\n",
    "            if not isinstance(cmp_dict[name], list):\n",
    "                cmp_dict[name] = [cmp_dict[name]]\n",
    "            if isinstance(component, list):\n",
    "                cmp_dict[name].extend(component)\n",
    "            else:\n",
    "                cmp_dict[name].append(component)\n",
    "        else:\n",
    "            if isinstance(component, list):\n",
    "                cmp_dict[name] = component.copy()\n",
    "            else:\n",
    "                cmp_dict[name] = component\n",
    "                \n",
    "    def gather_times (self):\n",
    "        dfs = [self.profiler.retrieve_times ()]\n",
    "        for component in self.components:\n",
    "            if isinstance(component, MultiComponent):\n",
    "                dfs.append(component.gather_times ())\n",
    "            else:\n",
    "                dfs.append(component.profiler.retrieve_times (is_leaf=True))\n",
    "        dfs = self.profiler.combine_times (dfs)\n",
    "        return dfs\n",
    "        \n",
    "    def construct_diagram (self, split=None, include_url=False, port=4000, project='block_types'):\n",
    "        \"\"\"\n",
    "        Construct diagram of the pipeline components, data flow and dimensionality.\n",
    "        \n",
    "        By default, we use test data to show the number of observations \n",
    "        in the output of each component. This can be changed passing \n",
    "        `split='train'`\n",
    "        \"\"\"\n",
    "        split = self.get_split (split)\n",
    "\n",
    "        if include_url:\n",
    "            base_url = f'http://localhost:{port}/{project}'\n",
    "        else:\n",
    "            URL = ''\n",
    "\n",
    "        node_name = 'data'\n",
    "        output = 'train / test'\n",
    "\n",
    "        f = Digraph('G', filename='fsm2.svg')\n",
    "        f.attr('node', shape='circle')\n",
    "\n",
    "        f.node(node_name)\n",
    "\n",
    "        f.attr('node', shape='box')\n",
    "        for component in self.components:\n",
    "            last_node_name = node_name\n",
    "            last_output = output\n",
    "            node_name = component.model_plotter.get_node_name()\n",
    "            if include_url:\n",
    "                URL = f'{base_url}/{component.model_plotter.get_module_path()}.html#{node_name}'\n",
    "            f.node(node_name, URL=URL)\n",
    "            f.edge(last_node_name, node_name, label=last_output)\n",
    "            output = component.model_plotter.get_edge_name(split=split)\n",
    "\n",
    "        last_node_name = node_name\n",
    "        node_name = 'output'\n",
    "        f.attr('node', shape='circle')\n",
    "        f.edge(last_node_name, node_name, label=output)\n",
    "\n",
    "        return f\n",
    "\n",
    "    def show_result_statistics (self, split=None):\n",
    "        \"\"\"\n",
    "        Show statistics about results obtained by each component. \n",
    "        \n",
    "        By default, this is shown on test data, although this can change setting \n",
    "        `split='train'`\n",
    "        \"\"\"\n",
    "        split = self.get_split (split)\n",
    "\n",
    "        for component in self.components:\n",
    "            component.show_result_statistics(split=split)\n",
    "\n",
    "    def show_summary (self, split=None):\n",
    "        \"\"\"\n",
    "        Show list of pipeline components, data flow and dimensionality.\n",
    "        \n",
    "        By default, we use test data to show the number of observations \n",
    "        in the output of each component. This can be changed passing \n",
    "        `split='train'`\n",
    "        \"\"\"\n",
    "        split = self.get_split (split)\n",
    "\n",
    "        node_name = 'data'\n",
    "        output = 'train / test'\n",
    "\n",
    "        for i, component in enumerate(self.components):\n",
    "            node_name = component.model_plotter.get_node_name()\n",
    "            output = component.model_plotter.get_edge_name(split=split)\n",
    "            print (f'{\"-\"*100}')\n",
    "            print (f'{i}: {node_name} => {output}')\n",
    "\n",
    "\n",
    "    def get_split (self, split=None):\n",
    "        if split is None:\n",
    "            if self.data_io.split is not None:\n",
    "                split = self.data_io.split\n",
    "            else:\n",
    "                split = 'whole'\n",
    "\n",
    "        return split\n",
    "\n",
    "    def assert_all_equal (self, path_reference_results, raise_error=False, recursive=True, \n",
    "                          max_recursion=None, current_recursion=0, verbose=None, **kwargs):\n",
    "        \"\"\"Compare results stored in current run against reference results stored in given path.\"\"\"\n",
    "        if verbose is not None:\n",
    "            self.logger.setLevel(get_logging_level (verbose))\n",
    "        is_equal = True\n",
    "        non_equal_components = []\n",
    "        end_recursion = max_recursion is not None and current_recursion > max_recursion\n",
    "        if end_recursion:\n",
    "            self.logger.setLevel(get_logging_level (self.verbose))\n",
    "            return True\n",
    "        for component in self.components:\n",
    "            if isinstance(component, MultiComponent) and recursive and not end_recursion:\n",
    "                this_equal = component.assert_all_equal (path_reference_results, \n",
    "                                                         raise_error=raise_error, \n",
    "                                                         recursive=recursive, \n",
    "                                                         max_recursion=max_recursion,\n",
    "                                                         current_recursion=current_recursion+1,\n",
    "                                                         verbose=verbose,\n",
    "                                                         **kwargs) \n",
    "            else:\n",
    "                this_equal = component.assert_equal (path_reference_results, \n",
    "                                                     raise_error=raise_error,\n",
    "                                                     verbose=verbose,\n",
    "                                                     **kwargs) \n",
    "            if not this_equal:\n",
    "                non_equal_components.append(component.name)\n",
    "            is_equal = this_equal and is_equal\n",
    "            \n",
    "        if not is_equal:\n",
    "            self.logger.warning (f'Results are different in components {non_equal_components}')\n",
    "        else:\n",
    "            self.logger.info ('both pipelines give the same results')\n",
    "        \n",
    "        self.logger.setLevel(get_logging_level (self.verbose))\n",
    "        \n",
    "        return is_equal\n",
    "        \n",
    "    def load_estimator (self):\n",
    "        for component in self.components:\n",
    "            component.load_estimator ()\n",
    "\n",
    "    # *************************\n",
    "    # setters\n",
    "    # *************************\n",
    "    def set_split (self, split):\n",
    "        super().set_split (split)\n",
    "        for component in self.components:\n",
    "            component.set_split (split)\n",
    "\n",
    "    def set_save_splits (self, save_splits):\n",
    "        super().set_save_splits (save_splits)\n",
    "        for component in self.components:\n",
    "            component.set_save_splits (save_splits)\n",
    "            \n",
    "    def set_load_model (self, load_model):\n",
    "        super().set_load_model (load_model)\n",
    "        for component in self.components:\n",
    "            component.set_load_model (load_model)\n",
    "\n",
    "    def set_save_model (self, save_model):\n",
    "        super().set_save_model (save_model)\n",
    "        for component in self.components:\n",
    "            component.set_save_model (save_model)\n",
    "            \n",
    "    def set_save_result (self, save_result):\n",
    "        super().set_save_result (save_result)\n",
    "        for component in self.components:\n",
    "            component.set_save_result (save_result)\n",
    "            \n",
    "    def set_load_result (self, load_result):\n",
    "        super().set_load_result (load_result)\n",
    "        for component in self.components:\n",
    "            component.set_load_result (load_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aedce8a4-be52-4e77-8069-f67c4f215ca6",
   "metadata": {},
   "source": [
    "### Usage examples / tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3771790d",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Loading / saving all results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "295af9e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# exports tests.core.test_compose\n",
    "#@pytest.mark.reference_fails\n",
    "def test_multi_comp_io ():\n",
    "\n",
    "    path_results = 'multi_component_loading_saving'\n",
    "    remove_previous_results (path_results=path_results)\n",
    "\n",
    "    # 1. by setting components as attributes:\n",
    "    class NewComposition(MultiComponent):\n",
    "\n",
    "        def __init__ (self, **kwargs):\n",
    "            data_io = PickleIO (**kwargs)\n",
    "            super().__init__(data_io=data_io,\n",
    "                             **kwargs)\n",
    "\n",
    "            self.tr1 = Component(FunctionTransformer (lambda x: x*3),\n",
    "                                 data_io=data_io,\n",
    "                                 name='tr1')\n",
    "            self.tr2 = Component(FunctionTransformer (lambda x: x*2),\n",
    "                                 data_io=data_io,\n",
    "                                 name='tr2')\n",
    "\n",
    "        def _apply (self, X):\n",
    "            return self.tr1 (X) + self.tr2(X)\n",
    "\n",
    "    X = np.array([1,2,3])\n",
    "\n",
    "    composition1 = NewComposition (path_results=path_results)\n",
    "    result1 = composition1 (X)\n",
    "\n",
    "    composition2 = NewComposition (path_results=path_results)\n",
    "    result2 = composition2.data_io.load_result()\n",
    "    assert (result1==result2).all()\n",
    "\n",
    "    resut_tr1_2 = composition2.tr1.data_io.load_result()\n",
    "    resut_tr2_2 = composition2.tr2.data_io.load_result()\n",
    "    assert (resut_tr1_2==composition1.tr1(X)).all()\n",
    "    assert (resut_tr2_2==composition1.tr2(X)).all()\n",
    "\n",
    "    assert sorted(os.listdir (f'{path_results}/whole'))==['new_composition_result.pk', 'tr1_result.pk', 'tr2_result.pk']\n",
    "\n",
    "    composition1.set_split ('validation')\n",
    "    result1b = composition1 (X)\n",
    "    assert sorted(os.listdir (f'{path_results}/validation'))==['new_composition_result.pk', 'tr1_result.pk', 'tr2_result.pk']\n",
    "\n",
    "    remove_previous_results (path_results=f'{path_results}/whole')\n",
    "\n",
    "    resut_tr1_2 = composition2.tr1.data_io.load_result(split='validation')\n",
    "    resut_tr2_2 = composition2.tr2.data_io.load_result()\n",
    "\n",
    "    assert (resut_tr1_2==composition1.tr1(X)).all()\n",
    "    assert resut_tr2_2 is None\n",
    "\n",
    "    composition2.set_split('validation')\n",
    "    resut_tr1_2 = composition2.tr1.data_io.load_result()\n",
    "    resut_tr2_2 = composition2.tr2.data_io.load_result()\n",
    "\n",
    "    assert (resut_tr1_2==composition1.tr1(X)).all()\n",
    "    assert (resut_tr2_2==composition1.tr2(X)).all()\n",
    "\n",
    "    remove_previous_results (path_results=path_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "724f1765-3171-4a48-9c4a-88f4a3c1bb14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test_multi_comp_io\n"
     ]
    }
   ],
   "source": [
    "tst.run (test_multi_comp_io, tag='dummy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9752e6-d651-448c-9a23-be5b72b49542",
   "metadata": {},
   "source": [
    "#### Getting descendants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a90946e-0a54-4045-8f9b-b44a6ece72fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports tests.core.test_compose\n",
    "#@pytest.mark.reference_fails\n",
    "def test_multi_comp_desc ():\n",
    "    class Intermediate (MultiComponent):\n",
    "        def __init__ (self, name=None, **kwargs):\n",
    "            super().__init__ (name=name, **kwargs)\n",
    "            self.first = Component (name='first_component', **kwargs)\n",
    "            self.second = Component (name='second_component', **kwargs)\n",
    "\n",
    "    class Higher (MultiComponent):\n",
    "        def __init__ (self, **kwargs):\n",
    "            super().__init__ (**kwargs)\n",
    "            self.first = Intermediate (name='first_intermediate', **kwargs)\n",
    "            self.second = Intermediate (name='second_intermediate', **kwargs)\n",
    "            self.gather_descendants(nick_name=False)\n",
    "\n",
    "    higher = Higher()\n",
    "\n",
    "    assert sorted(higher.obj.keys())==['first_component', 'first_intermediate', 'second_component', 'second_intermediate']\n",
    "\n",
    "    # check types\n",
    "    types = map(lambda x: type(x[1]), sorted(higher.obj.items()))\n",
    "    assert list(types)==[list, Intermediate, list, Intermediate]\n",
    "\n",
    "    sorted_list = list(sorted(higher.obj.items()))\n",
    "    types = map(type, sorted_list[0][1])\n",
    "    assert list(types)==[Component,Component]\n",
    "\n",
    "    sorted_list = list(sorted(higher.obj.items()))\n",
    "    types = map(type, sorted_list[2][1])\n",
    "    assert list(types)==[Component,Component]\n",
    "\n",
    "    sorted_keys=list(sorted(higher.cls.keys()))\n",
    "    assert sorted_keys == ['Component', 'Intermediate']\n",
    "\n",
    "    assert list(map(type,higher.cls[sorted_keys[0]]))==[Component, Component, Component, Component]\n",
    "\n",
    "    assert list(map(type,higher.cls[sorted_keys[1]]))==[Intermediate, Intermediate]\n",
    "\n",
    "\n",
    "    # ***********************\n",
    "    # recursive behaviour: higher.first\n",
    "    intermediate = higher.first\n",
    "    assert sorted(intermediate.obj.keys())==['first_component', 'second_component']\n",
    "\n",
    "    # check types\n",
    "    types = map(lambda x: type(x[1]), sorted(intermediate.obj.items()))\n",
    "    assert list(types)==[Component, Component]\n",
    "\n",
    "    sorted_keys=list(sorted(intermediate.cls.keys()))\n",
    "    assert sorted_keys==['Component']\n",
    "\n",
    "    assert list(map(type,intermediate.cls[sorted_keys[0]]))==[Component,Component]\n",
    "\n",
    "    # **********************************************\n",
    "    # recursive behaviour: higher.second\n",
    "    # **********************************************\n",
    "    intermediate = higher.second\n",
    "    assert sorted(intermediate.obj.keys())==['first_component', 'second_component']\n",
    "\n",
    "    # check types\n",
    "    types = map(lambda x: type(x[1]), sorted(intermediate.obj.items()))\n",
    "    assert list(types)==[Component, Component]\n",
    "\n",
    "    sorted_keys=list(sorted(intermediate.cls.keys()))\n",
    "    assert sorted_keys==['Component']\n",
    "\n",
    "    assert list(map(type,intermediate.cls[sorted_keys[0]]))==[Component,Component]\n",
    "\n",
    "    # **********************************************\n",
    "    # full hierarchical paths\n",
    "    # **********************************************\n",
    "    assert list(sorted(higher.full_cls.keys()))==['Component', 'Intermediate']\n",
    "    assert higher.full_cls['Intermediate']==['higher.first_intermediate', 'higher.second_intermediate']\n",
    "    assert higher.full_cls['Component']==['higher.first_intermediate.first_component',\n",
    "      'higher.first_intermediate.second_component',\n",
    "      'higher.second_intermediate.first_component',\n",
    "      'higher.second_intermediate.second_component']\n",
    "\n",
    "    assert higher.first.full_cls['Component']==['higher.first_intermediate.first_component',\n",
    "      'higher.first_intermediate.second_component']\n",
    "\n",
    "    assert list(sorted(higher.full_obj))==['first_component', 'first_intermediate', 'second_component', 'second_intermediate']\n",
    "\n",
    "    assert higher.full_obj['first_intermediate']=='higher.first_intermediate'\n",
    "\n",
    "    assert higher.full_obj['first_component']==['higher.first_intermediate.first_component',\n",
    "      'higher.second_intermediate.first_component']\n",
    "\n",
    "    assert higher.full_obj['second_component']==['higher.first_intermediate.second_component',\n",
    "      'higher.second_intermediate.second_component']\n",
    "\n",
    "    assert higher.full_obj['second_intermediate']=='higher.second_intermediate'\n",
    "\n",
    "    assert list(sorted(higher.second.full_obj))==['first_component', 'second_component']\n",
    "\n",
    "    assert higher.second.full_obj['first_component']=='higher.second_intermediate.first_component'\n",
    "\n",
    "    assert higher.second.full_obj['second_component']=='higher.second_intermediate.second_component'\n",
    "\n",
    "    assert higher.hierarchy_path=='higher'\n",
    "\n",
    "    assert higher.first.hierarchy_path=='higher.first_intermediate'\n",
    "\n",
    "    # with nick_names\n",
    "    higher.clear_descendants()\n",
    "    higher.gather_descendants(nick_name=True)\n",
    "\n",
    "    assert higher.full_cls['Component']==['higher.first.first',\n",
    "     'higher.first.second',\n",
    "     'higher.second.first',\n",
    "     'higher.second.second']\n",
    "\n",
    "    assert higher.full_obj['first_intermediate']=='higher.first'\n",
    "    assert higher.full_obj['first_component']==['higher.first.first', 'higher.second.first']\n",
    "    assert higher.full_obj['second_component']==['higher.first.second', 'higher.second.second']\n",
    "    assert higher.full_obj['second_intermediate']=='higher.second'\n",
    "    \n",
    "    #Check that we always have attributes for each component name\n",
    "    assert higher.first_intermediate is higher.first\n",
    "    assert higher.second_intermediate is higher.second\n",
    "    assert higher.components==[higher.first, higher.second]\n",
    "    \n",
    "    #check that set_components and add_component create self attrs called \n",
    "    # the same as the component\n",
    "    \n",
    "    class Higher (MultiComponent):\n",
    "        def __init__ (self, **kwargs):\n",
    "            super().__init__ (**kwargs)\n",
    "            self.set_components (Intermediate (name='first_intermediate', **kwargs),\n",
    "                                 Intermediate (name='second_intermediate', **kwargs))\n",
    "    higher = Higher()\n",
    "\n",
    "    assert higher.components == (higher.first_intermediate, higher.second_intermediate)\n",
    "\n",
    "    class Higher (MultiComponent):\n",
    "        def __init__ (self, **kwargs):\n",
    "            super().__init__ (**kwargs)\n",
    "            self.add_component (Intermediate (name='first_intermediate', **kwargs))\n",
    "            self.add_component (Intermediate (name='second_intermediate', **kwargs))\n",
    "    higher = Higher()\n",
    "\n",
    "    assert higher.components == [higher.first_intermediate, higher.second_intermediate]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46f37453-7406-42e4-a6c4-309c2fcd936a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test_multi_comp_desc\n"
     ]
    }
   ],
   "source": [
    "tst.run (test_multi_comp_desc, tag='dummy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64b4a043-0929-42f9-9d49-ca475b22bf28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# **********************************************\n",
    "# second example\n",
    "# **********************************************\n",
    "# exports tests.core.test_compose\n",
    "#@pytest.mark.reference_fails\n",
    "def test_athena_pipeline_training ():\n",
    "    class Intermediate (MultiComponent):\n",
    "        def __init__ (self, name=None, **kwargs):\n",
    "            super().__init__ (name=name, **kwargs)\n",
    "            self.first = Component (name=f'{name}_first_component', **kwargs)\n",
    "            self.second = Component (name=f'{name}_second_component', **kwargs)\n",
    "\n",
    "    class Higher (MultiComponent):\n",
    "        def __init__ (self, **kwargs):\n",
    "            super().__init__ (**kwargs)\n",
    "            self.first = Intermediate (name='first_intermediate', **kwargs)\n",
    "            self.second = Intermediate (name='second_intermediate', **kwargs)\n",
    "            self.gather_descendants(nick_name=False)\n",
    "\n",
    "    higher = Higher()\n",
    "\n",
    "    assert sorted(higher.obj.keys())==['first_intermediate', 'first_intermediate_first_component', 'first_intermediate_second_component', 'second_intermediate', 'second_intermediate_first_component', 'second_intermediate_second_component']\n",
    "\n",
    "    # check types\n",
    "    types = map(lambda x: type(x[1]), sorted(higher.obj.items()))\n",
    "\n",
    "    assert list(types)==[Intermediate, Component, Component, Intermediate, Component, Component]\n",
    "\n",
    "    sorted_keys=list(sorted(higher.cls.keys()))\n",
    "    assert sorted_keys == ['Component', 'Intermediate']\n",
    "\n",
    "    assert list(map(type,higher.cls[sorted_keys[0]]))==[Component, Component, Component, Component]\n",
    "    assert list(map(type,higher.cls[sorted_keys[1]]))==[Intermediate, Intermediate]\n",
    "\n",
    "    # ***********************\n",
    "    # recursive behaviour: higher.first\n",
    "    intermediate = higher.first\n",
    "    assert sorted(intermediate.obj.keys())==['first_intermediate_first_component', 'first_intermediate_second_component']\n",
    "\n",
    "    # check types\n",
    "    types = map(lambda x: type(x[1]), sorted(intermediate.obj.items()))\n",
    "    assert list(types)==[Component, Component]\n",
    "\n",
    "    sorted_keys=list(sorted(intermediate.cls.keys()))\n",
    "    assert sorted_keys==['Component']\n",
    "\n",
    "    assert list(map(type,intermediate.cls[sorted_keys[0]]))==[Component,Component]\n",
    "\n",
    "    # ***********************\n",
    "    # recursive behaviour: higher.second\n",
    "    intermediate = higher.second\n",
    "    assert sorted(intermediate.obj.keys())==['second_intermediate_first_component', 'second_intermediate_second_component']\n",
    "\n",
    "    # check types\n",
    "    types = map(lambda x: type(x[1]), sorted(intermediate.obj.items()))\n",
    "    assert list(types)==[Component, Component]\n",
    "\n",
    "    sorted_keys=list(sorted(intermediate.cls.keys()))\n",
    "    assert sorted_keys==['Component']\n",
    "\n",
    "    assert list(map(type,intermediate.cls[sorted_keys[0]]))==[Component,Component]\n",
    "\n",
    "\n",
    "    # **********************************************\n",
    "    # full hierarchical paths\n",
    "    # **********************************************\n",
    "    assert list(sorted(higher.full_cls))==['Component', 'Intermediate']\n",
    "\n",
    "    assert higher.full_cls['Component']==['higher.first_intermediate.first_intermediate_first_component',\n",
    "      'higher.first_intermediate.first_intermediate_second_component',\n",
    "      'higher.second_intermediate.second_intermediate_first_component',\n",
    "      'higher.second_intermediate.second_intermediate_second_component']\n",
    "\n",
    "    assert higher.full_cls['Intermediate']==['higher.first_intermediate', 'higher.second_intermediate']\n",
    "\n",
    "    assert list(higher.first.full_cls)==['Component']\n",
    "\n",
    "    assert higher.first.full_cls['Component']==['higher.first_intermediate.first_intermediate_first_component',\n",
    "      'higher.first_intermediate.first_intermediate_second_component']\n",
    "\n",
    "    assert sorted(list(higher.full_obj))==['first_intermediate',\n",
    "     'first_intermediate_first_component',\n",
    "     'first_intermediate_second_component',\n",
    "     'second_intermediate',\n",
    "     'second_intermediate_first_component',\n",
    "     'second_intermediate_second_component']\n",
    "\n",
    "    assert higher.full_obj['first_intermediate']=='higher.first_intermediate'\n",
    "\n",
    "    assert higher.full_obj['first_intermediate_first_component']=='higher.first_intermediate.first_intermediate_first_component'\n",
    "\n",
    "    assert higher.full_obj['first_intermediate_second_component']=='higher.first_intermediate.first_intermediate_second_component'\n",
    "\n",
    "    assert higher.full_obj['second_intermediate']=='higher.second_intermediate'\n",
    "\n",
    "    assert higher.full_obj['second_intermediate_first_component']=='higher.second_intermediate.second_intermediate_first_component'\n",
    "\n",
    "    assert higher.full_obj['second_intermediate_second_component']=='higher.second_intermediate.second_intermediate_second_component'\n",
    "\n",
    "    assert list(sorted(higher.second.full_obj))==['second_intermediate_first_component', 'second_intermediate_second_component']\n",
    "\n",
    "    assert higher.second.full_obj['second_intermediate_first_component']=='higher.second_intermediate.second_intermediate_first_component'\n",
    "\n",
    "    assert higher.second.full_obj['second_intermediate_second_component']=='higher.second_intermediate.second_intermediate_second_component'\n",
    "\n",
    "    assert higher.hierarchy_path=='higher'\n",
    "\n",
    "    assert higher.first.hierarchy_path=='higher.first_intermediate'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08a0746c-4208-407f-b678-e55e0daab499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test_athena_pipeline_training\n"
     ]
    }
   ],
   "source": [
    "tst.run (test_athena_pipeline_training, tag='dummy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ac147d-d580-4adf-91aa-6922ee440dcf",
   "metadata": {},
   "source": [
    "#### Passing parameters specific of hierarchy level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "abce6461-ba07-49e7-b435-db5e9da4c8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports tests.core.test_compose\n",
    "#@pytest.mark.reference_fails\n",
    "def test_multi_comp_hierarchy ():\n",
    "    class Intermediate (MultiComponent):\n",
    "        def __init__ (self, name=None, z=6, h=10, x=3, **kwargs):\n",
    "            super().__init__ (name=name, **kwargs)\n",
    "            self.first = Component (name='first_component', **kwargs)\n",
    "            self.second = Component (name='second_component', **kwargs)\n",
    "\n",
    "    class Higher (MultiComponent):\n",
    "        def __init__ (self, x=2, y=3, **kwargs):\n",
    "            super().__init__ (**kwargs)\n",
    "            self.first = Intermediate (name='first_intermediate', **kwargs)\n",
    "            self.second = Intermediate (name='second_intermediate', **kwargs)\n",
    "            self.gather_descendants()\n",
    "\n",
    "    higher = Higher()\n",
    "\n",
    "    levels=dict(\n",
    "        until=1,\n",
    "        verbose=1\n",
    "    )\n",
    "    higher = Higher (levels=levels, verbose=0)\n",
    "\n",
    "    assert higher.hierarchy_level==0 and higher.first.hierarchy_level==1 and higher.first.first.hierarchy_level==2\n",
    "\n",
    "    assert higher.verbose==1 and higher.first.verbose==1 and higher.first.first.verbose==0\n",
    "\n",
    "    levels['until']=0\n",
    "    higher = Higher (levels=levels, verbose=0)\n",
    "    assert higher.verbose==1 and higher.first.verbose==0 and higher.first.first.verbose==0\n",
    "\n",
    "    levels['until']=2\n",
    "    higher = Higher (levels=levels, verbose=0)\n",
    "    assert higher.verbose==1 and higher.first.verbose==1 and higher.first.first.verbose==1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20f7366e-ee7a-4acf-8818-2a41d614fde4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test_multi_comp_hierarchy\n"
     ]
    }
   ],
   "source": [
    "tst.run (test_multi_comp_hierarchy, tag='dummy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8dae93-e681-45e2-a91c-9d85d9930a95",
   "metadata": {},
   "source": [
    "#### Profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2537033e-63a6-45e5-9c8e-43886cd75964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports tests.core.test_compose\n",
    "#@pytest.mark.reference_fails\n",
    "def test_multi_comp_profiling ():\n",
    "    class A(Component):\n",
    "        def __init__ (self, time=1, **kwargs):\n",
    "            super().__init__(**kwargs)\n",
    "\n",
    "        def _fit (self, X, y=None):\n",
    "            time.sleep(self.time*2)\n",
    "\n",
    "        def _apply (self, X):\n",
    "            time.sleep(self.time)\n",
    "            return 1\n",
    "\n",
    "    class Intermediate (MultiComponent):\n",
    "        def __init__ (self, name=None, **kwargs):\n",
    "            super().__init__ (name=name, **kwargs)\n",
    "            self.first = A (name=f'{name}_first_component', time=0.01, **kwargs)\n",
    "            self.second = A (name=f'{name}_second_component', time=0.03, **kwargs)\n",
    "        def _fit (self, X, y=None):\n",
    "            self.first.fit (X,y)\n",
    "            self.second.fit (X,y)\n",
    "        def _apply (self, X):\n",
    "            _ = self.first.apply (X)\n",
    "            _ = self.second.apply (X)\n",
    "            return 1\n",
    "\n",
    "    class Higher (MultiComponent):\n",
    "        def __init__ (self, **kwargs):\n",
    "            super().__init__ (**kwargs)\n",
    "            self.first = Intermediate (name='first', **kwargs)\n",
    "            self.second = Intermediate (name='second', **kwargs)\n",
    "        def _fit (self, X, y=None):\n",
    "            self.first.fit (X,y)\n",
    "            self.second.fit (X,y)\n",
    "        def _apply (self, X):\n",
    "            _ = self.first.apply (X)\n",
    "            _ = self.second.apply (X)\n",
    "            return 1\n",
    "\n",
    "    higher = Higher()\n",
    "    higher.fit (1)\n",
    "    _ = higher.apply (1)\n",
    "    dfd = higher.gather_times()\n",
    "\n",
    "    values = dfd.avg[('whole','apply')].values\n",
    "    assert np.abs(values[1:3].sum() - values[0]) < 0.05\n",
    "    assert np.abs(values[3:5].sum() - values[1]) < 0.05\n",
    "    assert np.abs(values[5:7].sum() - values[2]) < 0.05\n",
    "\n",
    "    values = dfd.avg[('whole','fit')].values\n",
    "    assert np.abs(values[1:3].sum() - values[0]) < 0.05\n",
    "    assert np.abs(values[3:5].sum() - values[1]) < 0.05\n",
    "    assert np.abs(values[5:7].sum() - values[2]) < 0.05\n",
    "\n",
    "    display('avg', dfd.avg)\n",
    "\n",
    "    assert (dfd.novh_avg <= dfd.avg).all().all()\n",
    "    assert (dfd.novh_avg < dfd.avg).any().any()\n",
    "\n",
    "    assert ((dfd.novh_avg.iloc[-4:].sum(axis=0).to_frame().T) == dfd.no_overhead_total).all(axis=1).all()\n",
    "\n",
    "    assert ((dfd.avg.iloc[0]-dfd.novh_avg.iloc[-4:].sum(axis=0)).values == dfd.overhead_total.values).all()\n",
    "\n",
    "    display('no_overhead_total', dfd.no_overhead_total)\n",
    "    display('overhead_total', dfd.overhead_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4843c65a-8901-4931-ad01-151dae49a19d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test_multi_comp_profiling\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'avg'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">whole</th>\n",
       "      <th>leaf</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>fit</th>\n",
       "      <th>apply</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th>higher</th>\n",
       "      <td>0.215343</td>\n",
       "      <td>0.114031</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>first</th>\n",
       "      <td>0.101879</td>\n",
       "      <td>0.052737</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>second</th>\n",
       "      <td>0.101203</td>\n",
       "      <td>0.053760</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">2</th>\n",
       "      <th>first_first_component</th>\n",
       "      <td>0.024875</td>\n",
       "      <td>0.012652</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first_second_component</th>\n",
       "      <td>0.064743</td>\n",
       "      <td>0.032600</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>second_first_component</th>\n",
       "      <td>0.024284</td>\n",
       "      <td>0.013474</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>second_second_component</th>\n",
       "      <td>0.064595</td>\n",
       "      <td>0.033019</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              whole             leaf\n",
       "                                fit     apply       \n",
       "0 higher                   0.215343  0.114031  False\n",
       "1 first                    0.101879  0.052737  False\n",
       "  second                   0.101203  0.053760  False\n",
       "2 first_first_component    0.024875  0.012652   True\n",
       "  first_second_component   0.064743  0.032600   True\n",
       "  second_first_component   0.024284  0.013474   True\n",
       "  second_second_component  0.064595  0.033019   True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'no_overhead_total'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">whole</th>\n",
       "      <th>leaf</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>fit</th>\n",
       "      <th>apply</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.160405</td>\n",
       "      <td>0.081296</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      whole           leaf\n",
       "        fit     apply     \n",
       "0  0.160405  0.081296  4.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'overhead_total'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">whole</th>\n",
       "      <th>leaf</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>fit</th>\n",
       "      <th>apply</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th>higher</th>\n",
       "      <td>0.054938</td>\n",
       "      <td>0.032735</td>\n",
       "      <td>-4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             whole           leaf\n",
       "               fit     apply     \n",
       "0 higher  0.054938  0.032735 -4.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tst.run (test_multi_comp_profiling, tag='dummy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edca8c00-ca3a-4643-b589-a351076f6a27",
   "metadata": {},
   "source": [
    "#### assert_all_equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "79317c6b-38fb-4f2e-ba27-9adb98838cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports tests.core.test_compose\n",
    "#@pytest.mark.reference_fails\n",
    "def test_multi_comp_all_equal ():\n",
    "    path_results = 'multi_component_assert_equal'\n",
    "    remove_previous_results (path_results=path_results)\n",
    "\n",
    "    # 1. by setting components as attributes:\n",
    "    class NewComposition(MultiComponent):\n",
    "\n",
    "        def __init__ (self, noise = 0, **kwargs):\n",
    "            super().__init__(**kwargs)\n",
    "\n",
    "            self.tr1 = Component(FunctionTransformer (lambda x: x*3 + noise),\n",
    "                                 name='tr1',\n",
    "                                 **kwargs)\n",
    "            self.tr2 = Component(FunctionTransformer (lambda x: x*2),\n",
    "                                 name='tr2',\n",
    "                                 **kwargs)\n",
    "\n",
    "        def _apply (self, X):\n",
    "            return self.tr1 (X) + self.tr2(X)\n",
    "\n",
    "    X = np.array([1,2,3])\n",
    "\n",
    "    composition1 = NewComposition (path_results=path_results)\n",
    "    result1 = composition1 (X)\n",
    "\n",
    "    path_results2 = 'multi_component_assert_equal_2'\n",
    "    remove_previous_results (path_results=path_results2)\n",
    "    composition2 = NewComposition (path_results=path_results2)\n",
    "    result2 = composition2 (X)\n",
    "    assert composition1.assert_all_equal (path_results2)\n",
    "\n",
    "    remove_previous_results (path_results=path_results2)\n",
    "    composition2 = NewComposition (path_results=path_results2, noise=0.1)\n",
    "    result2 = composition2 (X)\n",
    "    assert not composition1.assert_all_equal (path_results2)\n",
    "\n",
    "    # *************************\n",
    "    # check verbosity\n",
    "    # *************************\n",
    "    composition1 = NewComposition (path_results=path_results, verbose=1)\n",
    "    composition1.logger.info ('\\n******************************')\n",
    "    composition1.logger.info ('verbose')\n",
    "    composition1.logger.info ('******************************')\n",
    "    assert not composition1.assert_all_equal (path_results2)\n",
    "\n",
    "    composition1.logger.info ('\\n******************************')\n",
    "    composition1.logger.info ('not verbose')\n",
    "    composition1.logger.info ('******************************')\n",
    "    assert not composition1.assert_all_equal (path_results2, verbose=0)\n",
    "    composition1.logger.info ('logger works again')\n",
    "\n",
    "    # *************************\n",
    "    # remove results\n",
    "    # *************************\n",
    "    remove_previous_results (path_results=path_results)\n",
    "    remove_previous_results (path_results=path_results2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4db2e9a2-d71f-4bfa-97ba-2cfb9e2267c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test_multi_comp_all_equal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Component tr1 => results are different: \n",
      "Not equal to tolerance rtol=1e-07, atol=0\n",
      "\n",
      "Mismatched elements: 3 / 3 (100%)\n",
      "Max absolute difference: 0.1\n",
      "Max relative difference: 0.03225806\n",
      " x: array([3, 6, 9])\n",
      " y: array([3.1, 6.1, 9.1])\n",
      "Results are different in components ['tr1']\n",
      "\n",
      "******************************\n",
      "verbose\n",
      "******************************\n",
      "comparing results for tr1\n",
      "loading our results...\n",
      "loading from /home/jcidatascience/jaume/workspace/remote/block-types/multi_component_assert_equal/whole/tr1_result.pk\n",
      "loading from /home/jcidatascience/jaume/workspace/remote/block-types/multi_component_assert_equal_2/whole/tr1_result.pk\n",
      "Component tr1 => results are different: \n",
      "Not equal to tolerance rtol=1e-07, atol=0\n",
      "\n",
      "Mismatched elements: 3 / 3 (100%)\n",
      "Max absolute difference: 0.1\n",
      "Max relative difference: 0.03225806\n",
      " x: array([3, 6, 9])\n",
      " y: array([3.1, 6.1, 9.1])\n",
      "comparing results for tr2\n",
      "loading our results...\n",
      "loading from /home/jcidatascience/jaume/workspace/remote/block-types/multi_component_assert_equal/whole/tr2_result.pk\n",
      "loading from /home/jcidatascience/jaume/workspace/remote/block-types/multi_component_assert_equal_2/whole/tr2_result.pk\n",
      "Results are equal.\n",
      "\n",
      "Results are different in components ['tr1']\n",
      "\n",
      "******************************\n",
      "not verbose\n",
      "******************************\n",
      "Component tr1 => results are different: \n",
      "Not equal to tolerance rtol=1e-07, atol=0\n",
      "\n",
      "Mismatched elements: 3 / 3 (100%)\n",
      "Max absolute difference: 0.1\n",
      "Max relative difference: 0.03225806\n",
      " x: array([3, 6, 9])\n",
      " y: array([3.1, 6.1, 9.1])\n",
      "Results are different in components ['tr1']\n",
      "logger works again\n"
     ]
    }
   ],
   "source": [
    "tst.run (test_multi_comp_all_equal, tag='dummy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7cfe10-762e-4a67-a4b7-956256301858",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3caa0a81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export\n",
    "class Pipeline (MultiComponent):\n",
    "    \"\"\"\n",
    "    Pipeline composed of a list of components that run sequentially.\n",
    "    \n",
    "    During training, the components of the list are trained one after the other, \n",
    "    where one component is fed the result of transforming the data with the list \n",
    "    of components located before in the pipeline.\n",
    "    \n",
    "    The `Pipeline` class is a subclass of `SamplingComponent`, which itself is a \n",
    "    subclass of `Component`. This provides the functionality of `Component` \n",
    "    to any implemented pipeline, such as logging the messages, loading / saving the \n",
    "    results, and convert the data format so that it can work as part of other \n",
    "    pipelines with potentially other data formats.\n",
    "    \n",
    "    Being a subclass of `SamplingComponent`, the `transform` method \n",
    "    receives an input data  `X` that contains both data and labels. \n",
    "    \n",
    "    Furthermore, the Pipeline constructor sets `separate_labels=False` by default,\n",
    "    which means that the `fit` method also receives an input data `X` that contains \n",
    "    not only data but also labels. This is necessary because some of the components in \n",
    "    the pipeline might be of class `SamplingComponent`, and such components \n",
    "    need the input data `X` to contain labels when calling `transform` (and note that \n",
    "    this method is called when calling `fit` on a pipeline, since we do `fit_transform`\n",
    "    on all the components except for the last one)\n",
    "    \"\"\"\n",
    "    def __init__ (self, **kwargs):\n",
    "        \"\"\"Assigns attributes and calls parent constructor.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        separate_labels: bool, optional\n",
    "            whether or not the fit method receives the labels in a separate `y` vector \n",
    "            or in the same input `X`, as an additional variable. See description of \n",
    "            Pipeline class for more details.\n",
    "        \"\"\"\n",
    "        \n",
    "        super().__init__ (**kwargs)\n",
    "        \n",
    "    def _fit (self, X, y=None):\n",
    "        \"\"\"\n",
    "        Fit components of the pipeline, given data X and labels y.\n",
    "        \n",
    "        By default, y will be None, and the labels are part of `X`, as a variable.\n",
    "        \"\"\"\n",
    "        X = self._fit_apply_except_last (X, y)\n",
    "        self.components[-1].fit (X, y)\n",
    "    \n",
    "    def _fit_apply (self, X, y=None, **kwargs):\n",
    "        X = self._fit_apply_except_last (X, y, **kwargs)\n",
    "        return self.components[-1].fit_apply (X, y, **kwargs)\n",
    "\n",
    "    def _fit_apply_except_last (self, X, y, **kwargs):\n",
    "        for component in self.components[:-1]:\n",
    "            X = component.fit_apply (X, y, **kwargs)\n",
    "        return X\n",
    "    \n",
    "    def _apply (self, X):\n",
    "        \"\"\"Transform data with components of pipeline, and predict labels with last component. \n",
    "        \n",
    "        In the current implementation, we consider prediction a form of mapping, \n",
    "        and therefore a special type of transformation.\"\"\"\n",
    "        for component in self.components:\n",
    "            X = component.transform (X)\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02171cf-cadd-4315-8efa-292648ee3a31",
   "metadata": {},
   "source": [
    "### Usage examples / tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d261ce6c",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "#### Tests for `fit_apply` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3a99f764-a4da-4d97-9ab7-d2f848e40995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports tests.core.test_compose\n",
    "# Transform1: custom Transform\n",
    "class Transform1 (Component):\n",
    "\n",
    "    def __init__ (self, **kwargs):\n",
    "        super().__init__ (**kwargs)\n",
    "        self.estimator= Bunch(sum = 1)\n",
    "\n",
    "    def _fit (self, X, y=None):\n",
    "        self.estimator.sum = X.sum(axis=0)\n",
    "\n",
    "    def _apply (self, x):\n",
    "        return x*1000 + self.estimator.sum\n",
    "\n",
    "class Transform2 (Component):\n",
    "\n",
    "    def __init__ (self, **kwargs):\n",
    "        super().__init__ (**kwargs)\n",
    "        self.estimator= Bunch(maxim = 1)\n",
    "\n",
    "    def _fit (self, X, y=None):\n",
    "        self.estimator.maxim = X.max(axis=0)\n",
    "\n",
    "    def _apply (self, x):\n",
    "        return x*100 + self.estimator.maxim\n",
    "#@pytest.mark.reference_fails\n",
    "def test_pipeline_fit_apply ():\n",
    "    # test `fit_apply` method\n",
    "\n",
    "    class NewPipeline (Pipeline):\n",
    "\n",
    "        def __init__ (self, **kwargs):\n",
    "            super().__init__ (**kwargs)\n",
    "\n",
    "            # custom transform\n",
    "            self.tr1 = Transform1(**kwargs) \n",
    "\n",
    "            # slklearn transform\n",
    "            self.tr2 = Transform2(**kwargs) \n",
    "\n",
    "    pipeline = NewPipeline()\n",
    "    x = np.array([3,4,5])\n",
    "    r1 = pipeline.fit_apply (x.reshape(-1,1))\n",
    "    print (r1)\n",
    "\n",
    "    x1 = x * 1000 + sum(x)\n",
    "    x2 = x1 * 100 + max(x1)\n",
    "    assert (r1.ravel()==x2).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "078a3f35-fc68-4fbb-bc03-8cb4aa978f33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test_pipeline_fit_apply\n",
      "[[306212]\n",
      " [406212]\n",
      " [506212]]\n"
     ]
    }
   ],
   "source": [
    "tst.run (test_pipeline_fit_apply, tag='dummy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d3bac1ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# exports tests.core.test_compose\n",
    "#@pytest.mark.reference_fails\n",
    "def test_pipeline_fit_apply_bis ():\n",
    "    # test `fit_apply` method\n",
    "    class NewMulti (MultiComponent):\n",
    "\n",
    "        def __init__ (self, **kwargs):\n",
    "            super().__init__ (**kwargs)\n",
    "\n",
    "            # custom transform\n",
    "            self.tr1 = Transform1(**kwargs) \n",
    "\n",
    "            # slklearn transform\n",
    "            self.tr2 = Transform2(**kwargs) \n",
    "\n",
    "        def _fit (self, X, y=None):\n",
    "            self.tr1.fit (X)\n",
    "            self.tr2.fit (X)\n",
    "\n",
    "        def _apply (self, X, y=None):\n",
    "            X1=self.tr1.apply (X)\n",
    "            X2=self.tr2.apply (X)\n",
    "            return X1+X2\n",
    "\n",
    "    new_multi = NewMulti()\n",
    "    x = np.array([3,4,5])\n",
    "    r2 = new_multi.fit_apply (x)\n",
    "    print (r2)\n",
    "    \n",
    "    x2b = 100 * x + max(x)\n",
    "    x1 = x * 1000 + sum(x)\n",
    "    assert (r2.ravel()==(x1 + x2b)).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d64ecafb-d0f4-4c64-9366-409fa45f636c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test_pipeline_fit_apply_bis\n",
      "[3317 4417 5517]\n"
     ]
    }
   ],
   "source": [
    "tst.run (test_pipeline_fit_apply_bis, tag='dummy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35aacd2b",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Adding new components to pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7b4c7306-619f-4164-af8c-2855be023cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports tests.core.test_compose\n",
    "#@pytest.mark.reference_fails\n",
    "def test_pipeline_new_comp ():\n",
    "    # test automatic creation of pipeline components\n",
    "\n",
    "    # 1. by setting components as attributes:\n",
    "    class NewPipeline(Pipeline):\n",
    "        def __init__ (self, **kwargs):\n",
    "            super().__init__(**kwargs)\n",
    "            self.tr1 = Component(FunctionTransformer (lambda x: x+1))\n",
    "            self.tr2 = Component(FunctionTransformer (lambda x: x*2))\n",
    "    pipeline = NewPipeline()\n",
    "    result = pipeline.transform (3)\n",
    "    print (result)\n",
    "    assert result == 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c255ec63-03b6-4bdd-81d0-4161ddb51d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test_pipeline_new_comp\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "tst.run (test_pipeline_new_comp, tag='dummy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "59ae2602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports tests.core.test_compose\n",
    "#@pytest.mark.reference_fails\n",
    "def test_pipeline_set_comp ():\n",
    "    #2. by using `set_components`\n",
    "    class NewPipeline(Pipeline):\n",
    "        def __init__ (self, **kwargs):\n",
    "            super().__init__(**kwargs)\n",
    "            tr1 = Component(FunctionTransformer (lambda x: x+1))\n",
    "            tr2 = Component(FunctionTransformer (lambda x: x*2))\n",
    "            self.set_components (tr1, tr2)\n",
    "\n",
    "            # the following transform is not added to the pipeline component list:\n",
    "            self.tr3 = Component(FunctionTransformer (lambda x: x+1))\n",
    "\n",
    "            # The reason is that once set_components is called, the component list \n",
    "            # is frozen and inmutable setting new components by attribute doesn't \n",
    "            # result in adding them to the component list\n",
    "\n",
    "    pipeline = NewPipeline()\n",
    "    result = pipeline.transform (3)\n",
    "\n",
    "    assert result == 8\n",
    "    assert len(pipeline.components) == 2\n",
    "    print (result, len(pipeline.components))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "30437ae3-3eac-4416-a12b-468b5790a434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test_pipeline_set_comp\n",
      "8 2\n"
     ]
    }
   ],
   "source": [
    "tst.run (test_pipeline_set_comp, tag='dummy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "11918856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports tests.core.test_compose\n",
    "#@pytest.mark.reference_fails\n",
    "def test_athena_pipeline_training ():\n",
    "#3. after calling `set_components()`, we can add new components with `add_component()`\n",
    "    class NewPipeline(Pipeline):\n",
    "        def __init__ (self, **kwargs):\n",
    "            super().__init__(**kwargs)\n",
    "            tr1 = Component(FunctionTransformer (lambda x: x+1))\n",
    "            tr2 = Component(FunctionTransformer (lambda x: x*2))\n",
    "            self.set_components (tr1, tr2)\n",
    "\n",
    "            tr3 = Component(FunctionTransformer (lambda x: x+2))\n",
    "            self.add_component(tr3)\n",
    "\n",
    "    pipeline = NewPipeline()\n",
    "    result = pipeline.transform (3)\n",
    "\n",
    "    assert result == 10\n",
    "    assert len(pipeline.components) == 3\n",
    "    print (result, len(pipeline.components))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b4ed99a3-cb00-4c4a-beb3-7a4130870771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test_athena_pipeline_training\n",
      "10 3\n"
     ]
    }
   ],
   "source": [
    "tst.run (test_athena_pipeline_training, tag='dummy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6221cf2",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Tests for `load_estimator` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ef255940-0efe-4ab1-b0f3-0315a3b97cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports tests.core.test_compose\n",
    "#@pytest.mark.reference_fails\n",
    "def test_pipeline_load_estimator ():\n",
    "    # test `load_estimator` method\n",
    "\n",
    "    # Transform1: custom Transform\n",
    "    class Transform1 (PickleSaverComponent):\n",
    "\n",
    "        def __init__ (self, **kwargs):\n",
    "            super().__init__ (**kwargs)\n",
    "            self.estimator= Bunch(inv_c = 1)\n",
    "\n",
    "        def _fit (self, X, y=None):\n",
    "            self.estimator.inv_c = X.ravel()[0]\n",
    "\n",
    "        def _apply (self, x):\n",
    "            return x / self.estimator.inv_c\n",
    "\n",
    "    class NewPipeline (Pipeline):\n",
    "\n",
    "        def __init__ (self, **kwargs):\n",
    "            super().__init__ (**kwargs)\n",
    "\n",
    "            # custom transform\n",
    "            self.tr1 = Transform1(**kwargs) \n",
    "\n",
    "            # slklearn transform\n",
    "            self.tr2 = PickleSaverComponent(StandardScaler(), **kwargs)\n",
    "\n",
    "        def _fit (self, X, y=None):\n",
    "            self.tr1.fit (X)\n",
    "            self.tr2.fit (X)\n",
    "\n",
    "    # remove any previously stored \n",
    "    path_results = 'pipeline_loading_saving'\n",
    "    remove_previous_results (path_results=path_results)\n",
    "\n",
    "    pipeline = NewPipeline(path_results=path_results, save_test_result=False)\n",
    "    pipeline.fit (np.array([3,4,5]).reshape(-1,1))\n",
    "    result1 = pipeline.transform (np.array([300,400,500]).reshape(-1,1))\n",
    "    print (pipeline.tr2.estimator.mean_)\n",
    "\n",
    "    del pipeline \n",
    "    pipeline = NewPipeline(path_results=path_results, save_test_result=False)\n",
    "    pipeline.load_estimator ()\n",
    "    print (pipeline.tr2.estimator.mean_)\n",
    "    result2 = pipeline.transform (np.array([300,400,500]).reshape(-1,1))\n",
    "\n",
    "    np.testing.assert_array_equal (result1, result2)\n",
    "\n",
    "    # remove stored files resulting from running the current test\n",
    "    remove_previous_results (path_results=path_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9ed265b9-b9a8-405b-b6a7-d4fe7f283b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test_pipeline_load_estimator\n",
      "[4.]\n",
      "[4.]\n"
     ]
    }
   ],
   "source": [
    "tst.run (test_pipeline_load_estimator, tag='dummy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f01cea-8262-413f-bc99-f68915f69ba3",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### construct_diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7cb1c5c3-6486-4028-8b1b-8b0f22206f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports tests.core.test_compose\n",
    "#@pytest.mark.reference_fails\n",
    "\n",
    "def build_pipeline_construct_diagram_1 (path_results):\n",
    "    class Intermediate (MultiComponent):\n",
    "        def __init__ (self, name=None, **kwargs):\n",
    "            super().__init__ (name=name, **kwargs)\n",
    "            self.first = Component (name='first_component', **kwargs)\n",
    "            self.second = Component (name='second_component', **kwargs)\n",
    "\n",
    "    class Higher (Pipeline):\n",
    "        def __init__ (self, **kwargs):\n",
    "            super().__init__ (**kwargs)\n",
    "            self.first = Intermediate (name='first_intermediate', class_name='First', **kwargs)\n",
    "            self.second = Intermediate (name='second_intermediate', class_name='Second', **kwargs)\n",
    "\n",
    "    pipeline = Higher(path_results=path_results)\n",
    "    \n",
    "    return pipeline\n",
    "\n",
    "def build_pipeline_construct_diagram_2 (path_results):\n",
    "    class NewPipeline (Pipeline):\n",
    "        def __init__ (self, **kwargs):\n",
    "            data_io = PickleIO (**kwargs)\n",
    "            super().__init__(data_io=data_io,\n",
    "                             **kwargs)\n",
    "\n",
    "            self.tr1 = Component(FunctionTransformer (lambda x: x*3),\n",
    "                                 data_io=data_io,\n",
    "                                 class_name='FirstTransform',\n",
    "                                 name='tr1')\n",
    "            self.tr2 = Component(FunctionTransformer (lambda x: x*2),\n",
    "                                 data_io=data_io,\n",
    "                                 class_name='SecondTransform',\n",
    "                                 name='tr2')\n",
    "            \n",
    "    pipeline = NewPipeline (path_results=path_results)\n",
    "    \n",
    "    return pipeline\n",
    "\n",
    "def test_construct_diagram ():\n",
    "    path_results = 'construct_diagram'\n",
    "    remove_previous_results (path_results=path_results)\n",
    "\n",
    "    # ********************************************\n",
    "    # example without dimensionality of outputs\n",
    "    # ********************************************\n",
    "    pipeline = build_pipeline_construct_diagram_1 (path_results)\n",
    "    diagram = pipeline.construct_diagram ()\n",
    "    display (diagram)\n",
    "    \n",
    "    # ********************************************\n",
    "    # example that shows dimensionality of outputs\n",
    "    # ********************************************\n",
    "    pipeline = build_pipeline_construct_diagram_2 (path_results)\n",
    "    X = np.array([1,2,3])\n",
    "    result = pipeline (X)\n",
    "\n",
    "    diagram = pipeline.construct_diagram ()\n",
    "    display (diagram)\n",
    "    \n",
    "    remove_previous_results (path_results=path_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "58ad9684-eb99-412e-950d-3b5ff376a6ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test_construct_diagram\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: G Pages: 1 -->\n",
       "<svg width=\"96pt\" height=\"322pt\"\n",
       " viewBox=\"0.00 0.00 96.15 321.99\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 317.9896)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-317.9896 92.1471,-317.9896 92.1471,4 -4,4\"/>\n",
       "<!-- data -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>data</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"33.1471\" cy=\"-288.6419\" rx=\"25.1964\" ry=\"25.1964\"/>\n",
       "<text text-anchor=\"middle\" x=\"33.1471\" y=\"-284.9419\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">data</text>\n",
       "</g>\n",
       "<!-- First -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>First</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"60.1471,-212.2941 6.1471,-212.2941 6.1471,-176.2941 60.1471,-176.2941 60.1471,-212.2941\"/>\n",
       "<text text-anchor=\"middle\" x=\"33.1471\" y=\"-190.5941\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">First</text>\n",
       "</g>\n",
       "<!-- data&#45;&gt;First -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>data&#45;&gt;First</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M33.1471,-262.8609C33.1471,-250.4145 33.1471,-235.4473 33.1471,-222.6765\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"36.6472,-222.5692 33.1471,-212.5692 29.6472,-222.5692 36.6472,-222.5692\"/>\n",
       "<text text-anchor=\"middle\" x=\"60.6471\" y=\"-234.0941\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">train / test</text>\n",
       "</g>\n",
       "<!-- Second -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>Second</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"61.1471,-139.2941 5.1471,-139.2941 5.1471,-103.2941 61.1471,-103.2941 61.1471,-139.2941\"/>\n",
       "<text text-anchor=\"middle\" x=\"33.1471\" y=\"-117.5941\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Second</text>\n",
       "</g>\n",
       "<!-- First&#45;&gt;Second -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>First&#45;&gt;Second</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M33.1471,-176.2492C33.1471,-168.177 33.1471,-158.4705 33.1471,-149.4759\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"36.6472,-149.3844 33.1471,-139.3845 29.6472,-149.3845 36.6472,-149.3844\"/>\n",
       "</g>\n",
       "<!-- output -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>output</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"33.1471\" cy=\"-33.1471\" rx=\"33.2948\" ry=\"33.2948\"/>\n",
       "<text text-anchor=\"middle\" x=\"33.1471\" y=\"-29.4471\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">output</text>\n",
       "</g>\n",
       "<!-- Second&#45;&gt;output -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>Second&#45;&gt;output</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M33.1471,-103.03C33.1471,-95.2531 33.1471,-85.821 33.1471,-76.4362\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"36.6472,-76.3519 33.1471,-66.352 29.6472,-76.352 36.6472,-76.3519\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7f271d0c7a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: G Pages: 1 -->\n",
       "<svg width=\"122pt\" height=\"350pt\"\n",
       " viewBox=\"0.00 0.00 122.00 349.99\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 345.9896)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-345.9896 118,-345.9896 118,4 -4,4\"/>\n",
       "<!-- data -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>data</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"57\" cy=\"-316.6419\" rx=\"25.1964\" ry=\"25.1964\"/>\n",
       "<text text-anchor=\"middle\" x=\"57\" y=\"-312.9419\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">data</text>\n",
       "</g>\n",
       "<!-- FirstTransform -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>FirstTransform</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"106.5,-240.2941 7.5,-240.2941 7.5,-204.2941 106.5,-204.2941 106.5,-240.2941\"/>\n",
       "<text text-anchor=\"middle\" x=\"57\" y=\"-218.5941\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">FirstTransform</text>\n",
       "</g>\n",
       "<!-- data&#45;&gt;FirstTransform -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>data&#45;&gt;FirstTransform</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M57,-290.8609C57,-278.4145 57,-263.4473 57,-250.6765\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"60.5001,-250.5692 57,-240.5692 53.5001,-250.5692 60.5001,-250.5692\"/>\n",
       "<text text-anchor=\"middle\" x=\"84.5\" y=\"-262.0941\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">train / test</text>\n",
       "</g>\n",
       "<!-- SecondTransform -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>SecondTransform</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"114,-153.2941 0,-153.2941 0,-117.2941 114,-117.2941 114,-153.2941\"/>\n",
       "<text text-anchor=\"middle\" x=\"57\" y=\"-131.5941\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">SecondTransform</text>\n",
       "</g>\n",
       "<!-- FirstTransform&#45;&gt;SecondTransform -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>FirstTransform&#45;&gt;SecondTransform</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M57,-204.2677C57,-192.4859 57,-176.8548 57,-163.4522\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"60.5001,-163.2974 57,-153.2975 53.5001,-163.2975 60.5001,-163.2974\"/>\n",
       "<text text-anchor=\"middle\" x=\"69\" y=\"-175.0941\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"> (3,)</text>\n",
       "</g>\n",
       "<!-- output -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>output</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"57\" cy=\"-33.1471\" rx=\"33.2948\" ry=\"33.2948\"/>\n",
       "<text text-anchor=\"middle\" x=\"57\" y=\"-29.4471\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">output</text>\n",
       "</g>\n",
       "<!-- SecondTransform&#45;&gt;output -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>SecondTransform&#45;&gt;output</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M57,-117.0323C57,-105.7651 57,-90.8033 57,-76.6375\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"60.5001,-76.5275 57,-66.5276 53.5001,-76.5276 60.5001,-76.5275\"/>\n",
       "<text text-anchor=\"middle\" x=\"69\" y=\"-88.0941\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"> (3,)</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7f271d139a50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tst.run (test_construct_diagram, tag='dummy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7c9848-2240-4b1a-ba4d-f14d9c8a92f7",
   "metadata": {},
   "source": [
    "#### show_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3d373b31-afbb-4d83-a0ac-8f07c8d3a038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports tests.core.test_compose\n",
    "#@pytest.mark.reference_fails\n",
    "def test_show_summary ():\n",
    "    path_results = 'show_summary'\n",
    "    remove_previous_results (path_results=path_results)\n",
    "\n",
    "    pipeline = build_pipeline_construct_diagram_2 (path_results)\n",
    "    X = np.array([1,2,3])\n",
    "    result = pipeline (X)\n",
    "\n",
    "    pipeline.show_summary ()\n",
    "    \n",
    "    remove_previous_results (path_results=path_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8d2fa242-a9cf-4c2f-8a8a-e7da0f246270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test_show_summary\n",
      "----------------------------------------------------------------------------------------------------\n",
      "0: FirstTransform =>  (3,)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "1: SecondTransform =>  (3,)\n"
     ]
    }
   ],
   "source": [
    "tst.run (test_show_summary, tag='dummy', do=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97eaf554",
   "metadata": {
    "tags": []
   },
   "source": [
    "### make_pipeline function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0d1e7e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def make_pipeline(*components, cls=Pipeline, **kwargs):\n",
    "    \"\"\"Create `Pipeline` object of class `cls`, given `components` list.\"\"\"\n",
    "    pipeline = cls (**kwargs)\n",
    "    pipeline.set_components(*components)\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a0ac7f77-807e-4af0-8e8f-5ce783e4b39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports tests.core.test_compose\n",
    "#@pytest.mark.reference_fails\n",
    "def test_make_pipeline ():\n",
    "    tr1 = Component(FunctionTransformer (lambda x: x+1))\n",
    "    tr2 = Component(FunctionTransformer (lambda x: x*2))\n",
    "    pipeline = make_pipeline (tr1, tr2)\n",
    "    result = pipeline.transform (3)\n",
    "\n",
    "    print (result)\n",
    "    assert result == 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "abd526cc-8dfb-48c4-a023-c5b737dd0516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test_make_pipeline\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "tst.run (test_make_pipeline, tag='dummy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb6dcb6-b5ff-455d-b74e-00cac7761206",
   "metadata": {},
   "source": [
    "### pipeline_factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "132ca31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def pipeline_factory (pipeline_class, **kwargs):\n",
    "    \"\"\"Creates a pipeline object given its class `pipeline_class`\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    pipeline_class : class or str\n",
    "        Name of the pipeline class used for creating the object. \n",
    "        This can be either of type string or class.\n",
    "    \"\"\"\n",
    "    if type(pipeline_class) is str:\n",
    "        Pipeline = eval(pipeline_class)\n",
    "    elif type(pipeline_class) is type:\n",
    "        Pipeline = pipeline_class\n",
    "    else:\n",
    "        raise ValueError (f'pipeline_class needs to be either string or class, we got {pipeline_class}')\n",
    "\n",
    "    return Pipeline (**kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da359ac-a1cf-4111-b4c8-93e58dc18291",
   "metadata": {},
   "source": [
    "#### pipeline_factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "06564708-0314-455a-b56a-e198c481ffc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports tests.core.test_compose\n",
    "#@pytest.mark.reference_fails\n",
    "def test_pipeline_factory ():\n",
    "    path_results = 'pipeline_factory'\n",
    "    remove_previous_results (path_results=path_results)\n",
    "\n",
    "    class Higher (Pipeline):\n",
    "        def __init__ (self, **kwargs):\n",
    "            super().__init__ (**kwargs)\n",
    "            self.first = Component (name='first_intermediate', class_name='First', **kwargs)\n",
    "            self.second = Component (name='second_intermediate', class_name='Second', **kwargs)\n",
    "\n",
    "    pipeline1 = pipeline_factory (Higher, path_results=path_results)\n",
    "    pipeline2 = pipeline_factory ('Higher', path_results=path_results)\n",
    "    \n",
    "    assert pipeline1.path_results==Path(path_results).resolve()\n",
    "    assert pipeline2.path_results==Path(path_results).resolve()\n",
    "\n",
    "    remove_previous_results (path_results=path_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "15b61a8f-bbd1-4b09-9e67-42a0a759af2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test_pipeline_factory\n"
     ]
    }
   ],
   "source": [
    "tst.run (test_pipeline_factory, tag='dummy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790ceccb-012a-435e-a596-300efe152cf4",
   "metadata": {},
   "source": [
    "#### other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "783f6fe1-b1f7-4ed4-a129-37f4bec01d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports tests.core.test_compose\n",
    "#@pytest.mark.reference_fails\n",
    "def test_construct_diagram ():\n",
    "    path_results = 'construct_diagram'\n",
    "    remove_previous_results (path_results=path_results)\n",
    "\n",
    "    remove_previous_results (path_results=path_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9ed6007a-2496-4c93-8ac0-0fe7e9d6436a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tst.run (test_construct_diagram, tag='dummy', do=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34b6623-604d-4790-bafc-9c1404b202f4",
   "metadata": {},
   "source": [
    "### PandasPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7a0ab14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class PandasPipeline (Pipeline):\n",
    "    \"\"\"\n",
    "    Pipeline that saves results in parquet format, and preserves DataFrame format.\n",
    "    \n",
    "    See `Pipeline` class for an explanation of using `separate_labels=False`\n",
    "    \"\"\"\n",
    "    def __init__ (self, \n",
    "                  data_converter=None,\n",
    "                  data_io=None,\n",
    "                  separate_labels=False,\n",
    "                  **kwargs):\n",
    "        if data_converter is None:\n",
    "            data_converter = PandasConverter (separate_labels=separate_labels,\n",
    "                                              **kwargs)\n",
    "        if data_io is None:\n",
    "            data_io = PandasIO (**kwargs)\n",
    "        super().__init__ (self, \n",
    "                          data_converter=data_converter,\n",
    "                          data_io=data_io,\n",
    "                          **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a93851-c398-4a0c-8139-7c0d285ee4c1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## ColumnTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2fc7eb-5cc4-4721-ba16-368d0c46c7a0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### ColumnSelector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3548404e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ColumnSelector (NoSaverComponent):\n",
    "    def __init__ (self, \n",
    "                  columns=[],\n",
    "                  remainder=False,\n",
    "                  verbose=dflt.verbose,\n",
    "                  force_verbose=False,\n",
    "                  logger=None,\n",
    "                  **kwargs):\n",
    "        verbose = 0 if not force_verbose else verbose\n",
    "        if verbose==0:\n",
    "            logger=None\n",
    "        super().__init__ (verbose=verbose,\n",
    "                          logger=logger,\n",
    "                          **kwargs)\n",
    "    \n",
    "    def _apply (self, df):\n",
    "        if self.remainder:\n",
    "            return df[[c for c in df.columns if c not in self.columns]]\n",
    "        else:\n",
    "            return df[self.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2942504b-face-438e-86a2-c484a7c11516",
   "metadata": {},
   "source": [
    "### Example / test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "277cb35f-4bee-4c7f-b24a-50c2810e8012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports tests.core.test_compose\n",
    "#@pytest.mark.reference_fails\n",
    "def test_column_selector ():\n",
    "    df = pd.DataFrame ({'x1': list(range(5)),\n",
    "                    'x2': list(range(5,10)),\n",
    "                    'x3': list(range(15,20)),\n",
    "                    'x4': list(range(25,30))\n",
    "                   })\n",
    "    dfr = ColumnSelector(columns=['x2','x4']).transform(df)\n",
    "    assert (dfr==df[['x2','x4']]).all().all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "59941c65-c942-4486-8e94-65d110545471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test_column_selector\n"
     ]
    }
   ],
   "source": [
    "tst.run (test_column_selector, tag='dummy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8a1be0-0087-41c1-aa13-31f96c5c172d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1d44877c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Concat (NoSaverComponent):\n",
    "    def __init__ (self, \n",
    "                  verbose=dflt.verbose,\n",
    "                  force_verbose=False,\n",
    "                  logger=None,\n",
    "                  **kwargs):\n",
    "        verbose = 0 if not force_verbose else verbose\n",
    "        if verbose==0:\n",
    "            logger=None\n",
    "        super().__init__ (verbose=verbose,\n",
    "                          logger=logger,\n",
    "                          **kwargs)\n",
    "        \n",
    "    def _apply (self, *dfs):\n",
    "        return pd.concat(list(dfs), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0a7ba3-954b-4367-9e57-b4d7ec9000a8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c8dffe69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class _BaseColumnTransformer (MultiComponent):\n",
    "    def __init__ (self, name=None, class_name=None, **kwargs):\n",
    "        super().__init__ (name=name, class_name=class_name, **kwargs)\n",
    "        self.concat = Concat (**kwargs)\n",
    "        del self.concat.nick_name\n",
    "    \n",
    "    def set_components (self, *components):\n",
    "        components = list(components)\n",
    "        components.append (self.concat)\n",
    "        super().set_components (*components)\n",
    "    \n",
    "    def _fit (self, df, y=None):\n",
    "        assert len(self.components) > 0\n",
    "        assert self.components[-1] is self.concat\n",
    "        for component in self.components[:-1]:\n",
    "            component.fit (df)\n",
    "        return self\n",
    "    \n",
    "    def _apply (self, df):\n",
    "        dfs = []\n",
    "        assert len(self.components) > 0\n",
    "        assert self.components[-1] is self.concat\n",
    "        for component in self.components[:-1]:\n",
    "            dfs.append (component.transform (df))\n",
    "        df_result = self.concat.transform (*dfs)\n",
    "        return df_result\n",
    "    \n",
    "class ColumnTransformer (_BaseColumnTransformer):\n",
    "    def __init__ (self, *transformers, remainder = 'drop', **kwargs):\n",
    "        super().__init__ (**kwargs)\n",
    "        components = make_column_transformer_pipelines (*transformers, remainder=remainder, **kwargs)\n",
    "        super().set_components(*components)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96deb0d4-6ea7-4ca3-93e9-e4116012b06e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9a0de61d-786a-438c-ab75-f62629e8d614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class Identity (NoSaverComponent):\n",
    "    def __init__ (self,           \n",
    "                  verbose=dflt.verbose,\n",
    "                  force_verbose=False,\n",
    "                  logger=None,\n",
    "                  **kwargs):\n",
    "        verbose = 0 if not force_verbose else verbose\n",
    "        if verbose==0:\n",
    "            logger=None\n",
    "        super().__init__ (verbose=verbose,\n",
    "                          logger=logger,\n",
    "                          **kwargs)\n",
    "        \n",
    "    def _apply (self, X):\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5b9e71-2fd6-4520-bf38-e289df9fe291",
   "metadata": {
    "tags": []
   },
   "source": [
    "### make_column_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "84612d42-4080-4bdc-bffb-d288e246ae2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _append_pipeline (pipelines, name, transformer, columns, remainder= False, **kwargs):\n",
    "    drop = False\n",
    "    if isinstance(transformer, str):\n",
    "        if transformer == 'passthrough':\n",
    "            transformer = Identity (**kwargs)\n",
    "        elif transformer == 'drop':\n",
    "            drop = True\n",
    "        else:\n",
    "            raise ValueError (f'name {transformer} not recognized')\n",
    "    \n",
    "    if not drop:\n",
    "        config=kwargs.copy()\n",
    "        config.update({name:dict(data_io='NoSaverIO')})\n",
    "        pipeline = make_pipeline(ColumnSelector(columns, remainder=remainder, **kwargs), \n",
    "                                 transformer, \n",
    "                                 name=name,\n",
    "                                 **config)\n",
    "        pipelines.append (pipeline)\n",
    "\n",
    "def _get_transformer_name (transformer, columns):\n",
    "    columns_name = ''.join([x[0] for x in columns])\n",
    "    if len(columns_name) > 5:\n",
    "        columns_name = columns_name[:5]\n",
    "    if isinstance(transformer,str): \n",
    "        if transformer == 'passthrough':\n",
    "            transformer_name = 'pass'\n",
    "        elif transformer == 'drop':\n",
    "            transformer_name = 'drop'\n",
    "        else:\n",
    "            raise ValueError (f'name {transformer} not recognized')\n",
    "    elif hasattr(transformer, 'name'):\n",
    "        transformer_name = transformer.name\n",
    "    else:\n",
    "        transformer_name = transformer.__class__.__name__\n",
    "    name = f'{transformer_name}_{columns_name}'\n",
    "    return name\n",
    "        \n",
    "def make_column_transformer_pipelines (*transformers, remainder='drop', **kwargs):\n",
    "    pipelines = []\n",
    "    all_columns = []\n",
    "    for name, transformer, columns in transformers:\n",
    "        _append_pipeline (pipelines, name, transformer, columns, **kwargs)\n",
    "        all_columns.extend(columns)\n",
    "    \n",
    "    all_columns = list(set(all_columns))\n",
    "    name = _get_transformer_name (remainder, ['r','e','m'])\n",
    "    _append_pipeline (pipelines, name, remainder, all_columns, remainder=True, **kwargs)\n",
    "        \n",
    "    return pipelines\n",
    "\n",
    "def make_column_transformer (*transformers, remainder='drop', name=None, class_name=None, **kwargs):\n",
    "    transformers_with_name = []\n",
    "    for transformer, columns in transformers:\n",
    "        transformer_name = _get_transformer_name (transformer, columns)\n",
    "        transformers_with_name.append ((transformer_name, transformer, columns))\n",
    "    \n",
    "    pipelines = make_column_transformer_pipelines (*transformers_with_name, \n",
    "                                                   remainder=remainder, \n",
    "                                                   **kwargs)\n",
    "    column_transformer = _BaseColumnTransformer (name=name, class_name=class_name, **kwargs)\n",
    "    column_transformer.set_components(*pipelines)\n",
    "    return column_transformer\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6797f513-28eb-4561-8fc7-f0aa382522fc",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Tests / usage examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452c4524-22ae-4bf6-8604-eef035102090",
   "metadata": {},
   "source": [
    "#### Simple example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bb651e51-0619-47fe-acb1-ffad1fc9e1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports tests.core.test_compose\n",
    "def column_transformer_data ():\n",
    "    df = pd.DataFrame ({'cont1': list(range(5)),\n",
    "                        'cont2': list(range(5,10)),\n",
    "                        'cont3': list(range(15,20)),\n",
    "                        'cont4': list(range(25,30)),\n",
    "                        'cat_1': list([1,2,3,2,1]),\n",
    "                        'cat_2': list([0,1,1,0,0])\n",
    "                        })\n",
    "        \n",
    "    tr1 = Component(FunctionTransformer (lambda x: x+1), name='tr1')\n",
    "    \n",
    "    return df, tr1\n",
    "        \n",
    "#@pytest.mark.reference_fails\n",
    "def test_make_column_transformer (column_transformer_data):\n",
    "\n",
    "    df, tr1 = column_transformer_data\n",
    "\n",
    "    tr1 = Component(FunctionTransformer (lambda x: x+1), name='tr1')\n",
    "    tr2 = PandasComponent(FunctionTransformer (lambda x: x*2), transformed_columns=['cont2_bis','cat_1'], name='tr2')\n",
    "\n",
    "    column_transformer = make_column_transformer (\n",
    "        (tr1, ['cont2', 'cont4']),\n",
    "        (tr2, ['cont2', 'cat_1'])\n",
    "    )\n",
    "    dfr = column_transformer.transform(df)\n",
    "\n",
    "    # display and test\n",
    "    display(dfr)\n",
    "    assert (dfr[['cont2','cont4']] == tr1(df[['cont2','cont4']])).all().all()\n",
    "    assert (dfr[['cont2_bis','cat_1']] == tr2(df[['cont2','cat_1']])).all().all()\n",
    "    assert (dfr.columns == ['cont2','cont4', 'cont2_bis','cat_1']).all()\n",
    "    assert (column_transformer.name, column_transformer.class_name) == ('__base_column_transformer', '_BaseColumnTransformer')\n",
    "\n",
    "    # set name of column transformer\n",
    "    column_transformer = make_column_transformer (\n",
    "        (tr1, ['cont2', 'cont4']),\n",
    "        (tr2, ['cont2', 'cat_1']),\n",
    "        name='test_transformer',\n",
    "        class_name='TestTransformer'\n",
    "    )\n",
    "    assert (column_transformer.name, column_transformer.class_name) == ('test_transformer', 'TestTransformer')\n",
    "\n",
    "    # set name of column transformer and parameters that are specific \n",
    "    # for the column_transformer: path_results\n",
    "    column_transformer = make_column_transformer (\n",
    "        (tr1, ['cont2', 'cont4']),\n",
    "        (tr2, ['cont2', 'cat_1']),\n",
    "        name='test_transformer',\n",
    "        class_name='TestTransformer',\n",
    "        TestTransformer=dict(path_results='mine'),\n",
    "        path_results='other'\n",
    "    )\n",
    "    assert column_transformer.path_results.name=='mine'\n",
    "    assert column_transformer.components[0].path_results.name=='other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ab06c055-3f31-4daa-a7f6-5a11f0717089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test_make_column_transformer\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cont2</th>\n",
       "      <th>cont4</th>\n",
       "      <th>cont2_bis</th>\n",
       "      <th>cat_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>27</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>28</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>29</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cont2  cont4  cont2_bis  cat_1\n",
       "0      6     26         10      2\n",
       "1      7     27         12      4\n",
       "2      8     28         14      6\n",
       "3      9     29         16      4\n",
       "4     10     30         18      2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tst.run (test_make_column_transformer, column_transformer_data, tag='dummy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53cf0b4-27cb-41b1-af4a-e4fb90e4db0b",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Using `passthrough`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "03fd5029-f597-4f82-a163-8cadf58b448e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports tests.core.test_compose\n",
    "#@pytest.mark.reference_fails\n",
    "def test_make_column_transformer_passthrough (column_transformer_data):\n",
    "    df, tr1 = column_transformer_data\n",
    "    \n",
    "    column_transformer = make_column_transformer (\n",
    "        (tr1, ['cont1', 'cont4']),\n",
    "        ('passthrough', ['cont2', 'cat_1'])\n",
    "    )\n",
    "    dfr = column_transformer.transform(df)\n",
    "\n",
    "    # display and test\n",
    "    display(dfr)\n",
    "    assert (dfr[['cont1','cont4']] == tr1(df[['cont1','cont4']])).all().all()\n",
    "    assert (dfr[['cont2','cat_1']] == df[['cont2','cat_1']]).all().all()\n",
    "    assert (dfr.columns == ['cont1','cont4', 'cont2','cat_1']).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5ebcea56-538f-4c93-8236-c0f1a7ccfca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test_make_column_transformer_passthrough\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cont1</th>\n",
       "      <th>cont4</th>\n",
       "      <th>cont2</th>\n",
       "      <th>cat_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cont1  cont4  cont2  cat_1\n",
       "0      1     26      5      1\n",
       "1      2     27      6      2\n",
       "2      3     28      7      3\n",
       "3      4     29      8      2\n",
       "4      5     30      9      1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tst.run (test_make_column_transformer_passthrough, column_transformer_data, tag='dummy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6e2d65-5af2-40f6-ab14-9d7bc8eab23f",
   "metadata": {},
   "source": [
    "#### Using remainder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "01424528-9645-4a80-a60e-7f0e6c77d4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports tests.core.test_compose\n",
    "#@pytest.mark.reference_fails\n",
    "def test_make_column_transformer_remainder (column_transformer_data):\n",
    "    \n",
    "    df, tr1 = column_transformer_data\n",
    "    \n",
    "    # remainder is new transformation\n",
    "    tr3 = Component(FunctionTransformer (lambda x: x+100), name='tr3')\n",
    "    column_transformer = make_column_transformer (\n",
    "        (tr1, ['cont1', 'cont4']),\n",
    "        ('passthrough', ['cont2', 'cat_1']),\n",
    "        remainder=tr3\n",
    "    )\n",
    "    dfr = column_transformer.transform(df)\n",
    "\n",
    "    # display and test\n",
    "    display('with tr3', dfr)\n",
    "    assert (dfr[['cont1','cont4']] == tr1(df[['cont1','cont4']])).all().all()\n",
    "    assert (dfr[['cont2','cat_1']] == df[['cont2','cat_1']]).all().all()\n",
    "    assert (dfr[['cont3','cat_2']] == tr3(df[['cont3','cat_2']])).all().all()\n",
    "    assert (dfr.columns == ['cont1','cont4', 'cont2','cat_1','cont3','cat_2']).all()\n",
    "\n",
    "    # remainder is passthrough\n",
    "    del tr1.nick_name\n",
    "    del tr3.nick_name\n",
    "    column_transformer = make_column_transformer (\n",
    "        (tr1, ['cont1', 'cont4']),\n",
    "        (tr3, ['cont2', 'cat_1']),\n",
    "        remainder='passthrough'\n",
    "    )\n",
    "    dfr = column_transformer.transform(df)\n",
    "\n",
    "    display('with passthrough', dfr)\n",
    "    assert (dfr[['cont1','cont4']] == tr1(df[['cont1','cont4']])).all().all()\n",
    "    assert (dfr[['cont2','cat_1']] == tr3(df[['cont2','cat_1']])).all().all()\n",
    "    assert (dfr[['cont3','cat_2']] == df[['cont3','cat_2']]).all().all()\n",
    "    assert (dfr.columns == ['cont1','cont4', 'cont2','cat_1','cont3','cat_2']).all()\n",
    "\n",
    "    # remainder is tr3, and one of the transforms is drop\n",
    "    del tr1.nick_name\n",
    "    del tr3.nick_name\n",
    "    column_transformer = make_column_transformer (\n",
    "        (tr1, ['cont1', 'cont4']),\n",
    "        ('drop', ['cont2', 'cat_1']),\n",
    "        remainder=tr3\n",
    "    )\n",
    "    dfr = column_transformer.transform(df)\n",
    "\n",
    "    display('with drop one of the transforms - cont2, cat_1', dfr)\n",
    "    assert (dfr[['cont1','cont4']] == tr1(df[['cont1','cont4']])).all().all()\n",
    "    assert (dfr[['cont3','cat_2']] == tr3(df[['cont3','cat_2']])).all().all()\n",
    "    assert (dfr.columns == ['cont1','cont4', 'cont3','cat_2']).all()\n",
    "    \n",
    "    # check gather_descendants\n",
    "    column_transformer.gather_descendants()\n",
    "    assert sorted(column_transformer.full_obj.keys())==['column_selector', 'concat', 'tr1', 'tr1_cc', 'tr3', 'tr3_rem']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3d90d630-e296-48ee-b5dd-5c0833a0b7ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test_make_column_transformer_remainder\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'with tr3'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cont1</th>\n",
       "      <th>cont4</th>\n",
       "      <th>cont2</th>\n",
       "      <th>cat_1</th>\n",
       "      <th>cont3</th>\n",
       "      <th>cat_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>115</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>116</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>117</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>118</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>119</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cont1  cont4  cont2  cat_1  cont3  cat_2\n",
       "0      1     26      5      1    115    100\n",
       "1      2     27      6      2    116    101\n",
       "2      3     28      7      3    117    101\n",
       "3      4     29      8      2    118    100\n",
       "4      5     30      9      1    119    100"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'with passthrough'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cont1</th>\n",
       "      <th>cont4</th>\n",
       "      <th>cont2</th>\n",
       "      <th>cat_1</th>\n",
       "      <th>cont3</th>\n",
       "      <th>cat_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>105</td>\n",
       "      <td>101</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>106</td>\n",
       "      <td>102</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>107</td>\n",
       "      <td>103</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>108</td>\n",
       "      <td>102</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>109</td>\n",
       "      <td>101</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cont1  cont4  cont2  cat_1  cont3  cat_2\n",
       "0      1     26    105    101     15      0\n",
       "1      2     27    106    102     16      1\n",
       "2      3     28    107    103     17      1\n",
       "3      4     29    108    102     18      0\n",
       "4      5     30    109    101     19      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'with drop one of the transforms - cont2, cat_1'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cont1</th>\n",
       "      <th>cont4</th>\n",
       "      <th>cont3</th>\n",
       "      <th>cat_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>115</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>116</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>117</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>118</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>119</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cont1  cont4  cont3  cat_2\n",
       "0      1     26    115    100\n",
       "1      2     27    116    101\n",
       "2      3     28    117    101\n",
       "3      4     29    118    100\n",
       "4      5     30    119    100"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tst.run (test_make_column_transformer_remainder, column_transformer_data, tag='dummy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b4cbac-4ad8-4db3-877d-940e5bd56037",
   "metadata": {},
   "source": [
    "#### gather_descendants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1faa72c8-e3d0-4c3b-bfe1-356d5c541652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports tests.core.test_compose\n",
    "#@pytest.mark.reference_fails\n",
    "def test_make_column_transformer_descendants (column_transformer_data):\n",
    "    \n",
    "    df, tr1 = column_transformer_data\n",
    "    \n",
    "    tr3 = Component(FunctionTransformer (lambda x: x+100), name='tr3')\n",
    "    \n",
    "    column_transformer = make_column_transformer (\n",
    "        (tr1, ['cont1', 'cont4']),\n",
    "        ('drop', ['cont2', 'cat_1']),\n",
    "        remainder=tr3\n",
    "    )\n",
    "    \n",
    "    # check gather_descendants\n",
    "    column_transformer.gather_descendants()\n",
    "    assert sorted(column_transformer.full_obj.keys())==['column_selector', 'concat', 'tr1', 'tr1_cc', 'tr3', 'tr3_rem']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cd68e49e-5411-4cb6-a5d0-400f1dd607fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test_make_column_transformer_descendants\n"
     ]
    }
   ],
   "source": [
    "tst.run (test_make_column_transformer_descendants, column_transformer_data, tag='dummy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00994218-f5a5-44af-858d-6e2d07a011fa",
   "metadata": {},
   "source": [
    "#### Example using `fit_transform`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "176ae8ff-ec31-48f7-b4be-8723da40d5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports tests.core.test_compose\n",
    "#@pytest.mark.reference_fails\n",
    "def test_make_column_transformer_fit_transform (column_transformer_data):\n",
    "    \n",
    "    df, tr1 = column_transformer_data\n",
    "    \n",
    "    class SumTimes100 (Component):\n",
    "        def _fit (self, X, y=None):\n",
    "            self.sum = X.sum(axis=0)\n",
    "        def _apply (self, X):\n",
    "\n",
    "            dfr = pd.DataFrame ({'c1_times100': self.sum.values[0]*100 + X.iloc[:,0].values,\n",
    "                                 'c2_times100': self.sum.values[1]*100 + X.iloc[:,1].values,\n",
    "                                 'c2_times1000': self.sum.values[1]*1000 + X.iloc[:,1].values})\n",
    "            return dfr\n",
    "\n",
    "    tr1 = SumTimes100 ()\n",
    "    tr2 = PandasComponent(FunctionTransformer (lambda x: x*2), name='tr2')\n",
    "\n",
    "    column_transformer = make_column_transformer (\n",
    "        (tr1, ['cont2', 'cont4']),\n",
    "        (tr2, ['cont2', 'cat_1'])\n",
    "    )\n",
    "    dfr = column_transformer.fit_transform(df)\n",
    "\n",
    "    # display & test\n",
    "    display(dfr)\n",
    "    assert (dfr.columns == ['c1_times100','c2_times100', 'c2_times1000','cont2', 'cat_1']).all()\n",
    "    assert (dfr['c1_times100'] == sum(df.cont2)*100+df.cont2).all()\n",
    "    assert (dfr['c2_times100'] == sum(df.cont4)*100+df.cont4).all()\n",
    "    assert (dfr['c2_times1000'] == sum(df.cont4)*1000+df.cont4).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8a5799e1-ce4a-4ea9-a328-51ccac19ccd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test_make_column_transformer_fit_transform\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c1_times100</th>\n",
       "      <th>c2_times100</th>\n",
       "      <th>c2_times1000</th>\n",
       "      <th>cont2</th>\n",
       "      <th>cat_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3505</td>\n",
       "      <td>13525</td>\n",
       "      <td>135025</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3506</td>\n",
       "      <td>13526</td>\n",
       "      <td>135026</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3507</td>\n",
       "      <td>13527</td>\n",
       "      <td>135027</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3508</td>\n",
       "      <td>13528</td>\n",
       "      <td>135028</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3509</td>\n",
       "      <td>13529</td>\n",
       "      <td>135029</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   c1_times100  c2_times100  c2_times1000  cont2  cat_1\n",
       "0         3505        13525        135025     10      2\n",
       "1         3506        13526        135026     12      4\n",
       "2         3507        13527        135027     14      6\n",
       "3         3508        13528        135028     16      4\n",
       "4         3509        13529        135029     18      2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tst.run (test_make_column_transformer_fit_transform, column_transformer_data, tag='dummy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ebb69a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## MultiSplitComponent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "450548a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class MultiSplitComponent (MultiComponent):\n",
    "    def __init__ (self, \n",
    "                  component=None, \n",
    "                  name=None,\n",
    "                  class_name=None,\n",
    "                  fit_to = 'training',\n",
    "                  fit_additional = [],\n",
    "                  apply_to = ['training', 'validation', 'test'],\n",
    "                  raise_error_if_split_doesnot_exist=False,\n",
    "                  raise_warning_if_split_doesnot_exist=True,\n",
    "                  **kwargs):\n",
    "        if class_name is None:\n",
    "            if hasattr(component, 'class_name'):\n",
    "                class_name = f'{component.class_name}MultiSplit'\n",
    "            else:\n",
    "                class_name = f'{component.__class__.__name__}MultiSplit'\n",
    "\n",
    "        if name is None:\n",
    "            if hasattr(component, 'name'):\n",
    "                name = f'{component.name}_multi_split'\n",
    "            else:\n",
    "                name = f'{component.__class__.__name__}_multi_split'\n",
    "\n",
    "        super().__init__ (name=name, class_name=class_name, **kwargs)\n",
    "    \n",
    "    def _fit (self, X, y=None):\n",
    "        if not isinstance(X, dict):\n",
    "            X = {self.fit_to: X}\n",
    "        component = self.components[0]\n",
    "        additional_data = {}\n",
    "        for split in self.fit_additional:\n",
    "            if split not in ['validation', 'test']:\n",
    "                raise ValueError (f'split {split} not valid')\n",
    "            if split in X.keys():\n",
    "                additional_data[f'{split}_data'] = X[split]\n",
    "            else:\n",
    "                self._issue_error_or_warning (split, X)\n",
    "        \n",
    "        component.fit(X[self.fit_to], y=y, split='training', **additional_data)\n",
    "    \n",
    "    def _issue_error_or_warning (self, split, X):\n",
    "        message = f'split {split} not found in X keys ({X.keys()})'\n",
    "        if self.raise_error_if_split_doesnot_exist:\n",
    "            raise RuntimeError (message)\n",
    "        elif self.raise_warning_if_split_doesnot_exist:\n",
    "            warnings.warn (message)\n",
    "    \n",
    "    def _apply (self, X, apply_to = None, output_not_dict=False, split=None, **kwargs):\n",
    "        apply_to = self.apply_to if apply_to is None else apply_to\n",
    "        apply_to = apply_to if isinstance(apply_to, list) else [apply_to]\n",
    "        if not isinstance(X, dict):\n",
    "            key = apply_to[0] if len(apply_to)==1 else split if split is not None else 'test'\n",
    "            X = {key: X}\n",
    "            input_not_dict = True\n",
    "        else:\n",
    "            input_not_dict = False\n",
    "            \n",
    "        component = self.components[0]\n",
    "        result = {}\n",
    "        for split in apply_to:\n",
    "            if split in X.keys():\n",
    "                result[split] = component.apply (X[split], split=split, **kwargs)\n",
    "            else:\n",
    "                self._issue_error_or_warning (split, X)\n",
    "        \n",
    "        if input_not_dict:\n",
    "            result = result[key]\n",
    "        elif output_not_dict and len(result)==1:\n",
    "            result = list(result.items())[0][1]\n",
    "        return result\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468ea301",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Tests / usage examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06ac335-6c4f-4efd-9d0e-003ada88881c",
   "metadata": {},
   "source": [
    "#### apply transform on multiple splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b90b5e2f-153c-45f1-a886-3d73fa7c24a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports tests.core.test_compose\n",
    "class Transform1 (Component):\n",
    "    def __init__ (self, **kwargs):\n",
    "        super().__init__ (**kwargs)\n",
    "        self.estimator= Bunch(sum = 1)\n",
    "\n",
    "    def _fit (self, X, y=None):\n",
    "        self.estimator.sum = X.sum(axis=0)\n",
    "\n",
    "    def _apply (self, x):\n",
    "        return x*1000 + self.estimator.sum\n",
    "    \n",
    "class Transform2 (Component):\n",
    "    def __init__ (self, **kwargs):\n",
    "        super().__init__ (**kwargs)\n",
    "        self.estimator= Bunch(maxim = 1)\n",
    "\n",
    "    def _fit (self, X, y=None, validation_data=None, test_data=None):\n",
    "        self.estimator.maxim = X.max(axis=0)\n",
    "\n",
    "        print (f'validation_data: {validation_data}')\n",
    "        print (f'test_data: {test_data}')\n",
    "\n",
    "        self.data = dict (validation=validation_data,\n",
    "                          test=test_data)\n",
    "\n",
    "    def _apply (self, x):\n",
    "        return x*100 + self.estimator.maxim\n",
    "\n",
    "def multi_split_data ():\n",
    "    data = dict(training = np.array([1,2,3]).reshape(-1,1),\n",
    "            validation = np.array([10,20,30]).reshape(-1,1),\n",
    "            test = np.array([100,200,300]).reshape(-1,1)\n",
    "            )\n",
    "    \n",
    "    multi_transform1 = MultiSplitComponent (component = Transform1())\n",
    "    \n",
    "    tr2 = Transform2()\n",
    "    multi_transform2 = MultiSplitComponent (component=tr2,\n",
    "                                            fit_additional = ['validation', 'test'])\n",
    "    \n",
    "    return data, multi_transform1, multi_transform2, tr2\n",
    "\n",
    "#@pytest.mark.reference_fails\n",
    "def test_multi_split_transform (multi_split_data):\n",
    "    # example 1: apply transform on multiple splits\n",
    "    data, multi_transform1, multi_transform2, tr2 = multi_split_data\n",
    "    \n",
    "    result = multi_transform1.fit_transform (data)\n",
    "\n",
    "    assert type(result) is dict\n",
    "    assert result.keys() == data.keys()\n",
    "    for split in result.keys():\n",
    "        assert (result[split]==sum(data['training'].ravel())+data[split]*1000).all()\n",
    "\n",
    "    # check that automatic name given is based on component\n",
    "    assert multi_transform1.name=='transform1_multi_split'\n",
    "    assert multi_transform1.class_name=='Transform1MultiSplit'\n",
    "\n",
    "    # check that we can assign a different name\n",
    "    multi_transform1 = MultiSplitComponent (component = Transform1(), name='different', class_name='Yes')\n",
    "    assert multi_transform1.name=='different'\n",
    "    assert multi_transform1.class_name=='Yes'\n",
    "    # check that this new name is given only to MultiSplitComponent, \n",
    "    # not to the component that it's wrapping\n",
    "    assert multi_transform1.component.name=='transform1'\n",
    "    assert multi_transform1.component.class_name=='Transform1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "00f8372c-4b02-41e5-b702-f4d3c2d0b9be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test_multi_split_transform\n"
     ]
    }
   ],
   "source": [
    "tst.run (test_multi_split_transform, multi_split_data, tag='dummy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b14fb68-e261-4c7c-b741-5ec653596910",
   "metadata": {},
   "source": [
    "#### fit method gets training, validation and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "476d31ea-5432-470f-83d1-23ba038c1ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports tests.core.test_compose\n",
    "#@pytest.mark.reference_fails\n",
    "def test_multi_split_fit (multi_split_data):\n",
    "    # example 2: fit method gets training, validation and test\n",
    "    data, multi_transform1, multi_transform2, tr2 = multi_split_data\n",
    "    # we apply the transform to only test\n",
    "    \n",
    "\n",
    "    # we apply the transform to only test data\n",
    "    result = multi_transform2.fit_transform (data, apply_to='test')\n",
    "\n",
    "    assert type(result) is dict\n",
    "    assert list(result.keys()) == ['test']\n",
    "    for split in result.keys():\n",
    "        assert (result[split]==max(data['training'].ravel())+data[split]*100).all()\n",
    "\n",
    "    for split in ['validation', 'test']:\n",
    "        assert (tr2.data[split] == data[split]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "75d7be15-9e4e-4b19-b021-63b40c6c0fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test_multi_split_fit\n",
      "validation_data: [[10]\n",
      " [20]\n",
      " [30]]\n",
      "test_data: [[100]\n",
      " [200]\n",
      " [300]]\n"
     ]
    }
   ],
   "source": [
    "tst.run (test_multi_split_fit, multi_split_data, tag='dummy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3b93cd-645f-4e07-b363-6e766ca25398",
   "metadata": {},
   "source": [
    "#### chain transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7abace90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports tests.core.test_compose\n",
    "#@pytest.mark.reference_fails\n",
    "def test_multi_split_chain (multi_split_data):\n",
    "    data, multi_transform1, multi_transform2, tr2 = multi_split_data\n",
    "    \n",
    "    # test that we can chain transformations\n",
    "\n",
    "    result = multi_transform1.fit_transform (data)\n",
    "    result = multi_transform2.fit_transform (result, apply_to='test')\n",
    "\n",
    "    import pytest \n",
    "\n",
    "    #check that we have no error if split does not exist\n",
    "    result = multi_transform1.fit_transform (data, apply_to=['training', 'validation'])\n",
    "    result = multi_transform2.fit_transform (result, apply_to=['test'])\n",
    "    assert len(result)==0\n",
    "\n",
    "    #check that we have an error if we set the flag `raise_error_if_split_doesnot_exist=True`\n",
    "    multi_transform2.raise_error_if_split_doesnot_exist = True\n",
    "    result = multi_transform1.fit_transform (data, apply_to=['training', 'validation'])\n",
    "    with pytest.raises (RuntimeError):\n",
    "        result = multi_transform2.fit_transform (result, apply_to=['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "906832b1-71d7-4956-a20d-43cbb42e3f5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test_multi_split_chain\n",
      "validation_data: [[10006]\n",
      " [20006]\n",
      " [30006]]\n",
      "test_data: [[100006]\n",
      " [200006]\n",
      " [300006]]\n",
      "validation_data: [[10006]\n",
      " [20006]\n",
      " [30006]]\n",
      "test_data: None\n"
     ]
    }
   ],
   "source": [
    "tst.run (test_multi_split_chain, multi_split_data, tag='dummy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37de82ce-de20-43c5-9540-c43642b15ee7",
   "metadata": {},
   "source": [
    "#### loading / saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "704b6354",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# exports tests.core.test_compose\n",
    "#@pytest.mark.reference_fails\n",
    "def test_multi_split_io (multi_split_data):\n",
    "    \n",
    "    data, multi_transform1, multi_transform2, tr2 = multi_split_data\n",
    "    \n",
    "    # check loading / saving\n",
    "    from block_types.utils.utils import remove_previous_results\n",
    "    from block_types.core.utils import PickleIO\n",
    "\n",
    "    path_results = 'results_multi_split'\n",
    "\n",
    "    remove_previous_results (path_results=path_results)\n",
    "\n",
    "    tr = PickleSaverComponent (FunctionTransformer (lambda x: x*2),\n",
    "                    name='times2',\n",
    "                    path_results=path_results)\n",
    "\n",
    "    multi_transform = MultiSplitComponent (component=tr,\n",
    "                                           apply_to = ['validation', 'test'],\n",
    "                                           path_results = path_results,\n",
    "                                           data_io=PickleIO (path_results = path_results))\n",
    "\n",
    "    result = multi_transform (data)\n",
    "\n",
    "    multi_transform2 = MultiSplitComponent (data_io=PickleIO (path_results = path_results), name='times2_multi_split')\n",
    "\n",
    "    result2 = multi_transform2.data_io.load_result ()\n",
    "\n",
    "    for k in result.keys():\n",
    "        assert (result[k] == result2[k]).all()\n",
    "\n",
    "    assert result.keys()==result2.keys()\n",
    "\n",
    "    assert sorted(os.listdir(path_results))==['test', 'validation', 'whole']\n",
    "\n",
    "    assert (tr.data_io.load_result(split='test') == result['test']).all()\n",
    "\n",
    "    assert (tr.data_io.load_result(split='validation') == result['validation']).all()\n",
    "\n",
    "    assert os.listdir(f'{path_results}/validation')==['times2_result.pk']\n",
    "\n",
    "    assert os.listdir(f'{path_results}/test')==['times2_result.pk']\n",
    "\n",
    "    assert os.listdir(f'{path_results}/whole')==['times2_multi_split_result.pk']\n",
    "\n",
    "    remove_previous_results (path_results=path_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7e75a9b8-0335-4bda-a333-d8f96ef56152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test_multi_split_io\n"
     ]
    }
   ],
   "source": [
    "tst.run (test_multi_split_io, multi_split_data, tag='dummy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca94e1bf-39e4-4e20-8548-43a01ecd8742",
   "metadata": {},
   "source": [
    "### With non-dictionary input / output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2e40a7c6-8546-4abe-b07c-066c48dc555d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports tests.core.test_compose\n",
    "#@pytest.mark.reference_fails\n",
    "def test_multi_split_non_dict ():\n",
    "    # check loading / saving\n",
    "    tr = Component (FunctionTransformer (lambda x: x*2))\n",
    "\n",
    "    multi_transform = MultiSplitComponent (tr, apply_to = ['test'])\n",
    "\n",
    "    data = np.array([100,200,300]).reshape(-1,1)\n",
    "    result = multi_transform (data)\n",
    "\n",
    "    assert type(result)==np.ndarray\n",
    "    assert (result==data*2).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "dece23e3-823a-4fa5-bc8a-2c1e43faa52d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test_multi_split_non_dict\n"
     ]
    }
   ],
   "source": [
    "tst.run (test_multi_split_non_dict, tag='dummy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19c3b90-f00c-44ab-81bc-e3b27b50b41e",
   "metadata": {},
   "source": [
    "output applied to single split, converted to non-dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e9daee36-e729-4bb7-9570-65fbc9014d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports tests.core.test_compose\n",
    "#@pytest.mark.reference_fails\n",
    "def test_multi_split_non_dict_bis ():\n",
    "    tr = Component (FunctionTransformer (lambda x: x*2))\n",
    "\n",
    "    multi_transform = MultiSplitComponent (tr, apply_to = ['test'])\n",
    "    \n",
    "    # output applied to single split, converted to non-dictionary\n",
    "    data = dict(training = np.array([1,2,3]).reshape(-1,1),\n",
    "                validation = np.array([10,20,30]).reshape(-1,1),\n",
    "                test = np.array([100,200,300]).reshape(-1,1))\n",
    "    result = multi_transform (data, output_not_dict=True)\n",
    "\n",
    "    assert type(result)==np.ndarray\n",
    "    assert (result==data['test']*2).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fb5d3190-e661-4dc3-be3d-5f5a252874ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test_multi_split_non_dict_bis\n"
     ]
    }
   ],
   "source": [
    "tst.run (test_multi_split_non_dict_bis, tag='dummy')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (block_types)",
   "language": "python",
   "name": "block_types"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
