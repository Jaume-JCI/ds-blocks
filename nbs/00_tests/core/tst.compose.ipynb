{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86b3a6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "# default_exp tests.core.test_compose\n",
    "from nbdev.showdoc import *\n",
    "from dsblocks.utils.nbdev_utils import nbdev_setup, TestRunner\n",
    "\n",
    "nbdev_setup ()\n",
    "tst = TestRunner (targets=['dummy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1a487f",
   "metadata": {},
   "source": [
    "# Test compose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00c30900-4c9d-473d-aa61-630512bc57c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import pytest\n",
    "import os\n",
    "import joblib\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import Bunch\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from dsblocks.core.compose import *\n",
    "from dsblocks.core.components import Component, PandasComponent, PickleSaverComponent\n",
    "from dsblocks.core.utils import PickleIO\n",
    "from dsblocks.utils.utils import remove_previous_results\n",
    "from dsblocks.core.data_conversion import DataConverter, PandasConverter\n",
    "\n",
    "import dsblocks.config.bt_defaults as dflt\n",
    "from dsblocks.utils.utils import check_last_part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "900e1c41-7dfa-43c7-8100-af96990f3ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@pytest.fixture (name='column_transformer_data')\n",
    "def column_transformer_data_fixture():\n",
    "    return column_transformer_data()\n",
    "\n",
    "@pytest.fixture (name='multi_split_data')\n",
    "def multi_split_data_fixture():\n",
    "    return multi_split_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b974f24d-f4fe-46c6-9c03-56360544faa3",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "## Parallel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88866b64-f7fc-4e8d-81e0-3bec1bcdf0c4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### `find_last_fitted_model`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781df927-700d-4625-9726-4ba814e4edbc",
   "metadata": {},
   "source": [
    "#### Using Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46af70d4-8bd5-4b0b-b935-6822565556ec",
   "metadata": {},
   "source": [
    "##### First test / example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adf09452-6073-4d2e-b725-982f3a03b171",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# export\n",
    "from dsblocks.utils.dummies import make_pipe_fit1\n",
    "\n",
    "def test_pipeline_find_last_fitted_model_seq_others ():\n",
    "    path_results = 'test_pipeline_find_last_fitted_model_seq_start'\n",
    "    remove_previous_results (path_results=path_results)\n",
    "    \n",
    "    # pipelines\n",
    "    pipe1 = make_pipe_fit1 ()\n",
    "    X = np.array([1,2,3]).reshape(-1,1)\n",
    "    r1 = pipe1.fit_apply (X)\n",
    "    \n",
    "    # case 1: component A\n",
    "    pipe2 = make_pipe_fit1 (path_results=path_results, verbose=2)\n",
    "    r = pipe2.A.fit_apply (X)\n",
    "    all_fitted = pipe2.find_last_fitted_model ()\n",
    "    assert not all_fitted\n",
    "    pipe2.A.raise_error = True\n",
    "    with pytest.raises (RuntimeError):\n",
    "        r2 = pipe2.fit_apply (None)\n",
    "    remove_previous_results (path_results=path_results)\n",
    "    \n",
    "    # case 2: component B\n",
    "    pipe2 = make_pipe_fit1 (path_results=path_results, verbose=2)\n",
    "    r = pipe2.A.fit_apply (X)\n",
    "    r = pipe2.B.fit_apply (r)\n",
    "    all_fitted = pipe2.find_last_fitted_model ()\n",
    "    assert not all_fitted\n",
    "    pipe2.A.raise_error = True\n",
    "    r2 = pipe2.fit_apply (None)\n",
    "    assert (r1==r2).all()\n",
    "    remove_previous_results (path_results=path_results)\n",
    "    \n",
    "    # case 2: component C\n",
    "    pipe2 = make_pipe_fit1 (path_results=path_results, verbose=2)\n",
    "    r = pipe2.A.fit_apply (X)\n",
    "    r = pipe2.B.fit_apply (r)\n",
    "    r = pipe2.C.fit_apply (r)\n",
    "    all_fitted = pipe2.find_last_fitted_model ()\n",
    "    assert not all_fitted\n",
    "    pipe2.A.raise_error = True\n",
    "    pipe2.B.raise_error = True\n",
    "    pipe2.B.estimator = Bunch ()\n",
    "    pipe2.C.estimator = Bunch ()\n",
    "    r2 = pipe2.fit_apply (None)\n",
    "    assert (r1==r2).all()\n",
    "    remove_previous_results (path_results=path_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "edba910e-c84c-4af4-bfc8-a2b651dfdbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tst.run (test_pipeline_find_last_fitted_model_seq_others, tag='dummy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4026ff-2bd2-4de7-88cb-324fc710fa10",
   "metadata": {},
   "source": [
    "##### Second test / example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2153f2-d03a-44d1-aa7e-a42c5ed59dca",
   "metadata": {},
   "source": [
    "#### Using Parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78340bb8-2073-4bab-b0e7-9966eaabfff5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# export\n",
    "from dsblocks.utils.dummies import make_pipe_fit2\n",
    "\n",
    "def test_pipeline_find_last_fitted_model_parallel_2 ():\n",
    "    path_results = 'test_pipeline_find_last_fitted_model_parallel_2'\n",
    "    remove_previous_results (path_results=path_results)\n",
    "    \n",
    "    # ******************************************************\n",
    "    # pipelines\n",
    "    pipe1 = make_pipe_fit2 ()\n",
    "    X = np.array([1,2,3]).reshape(-1,1)\n",
    "    r1 = pipe1.fit_apply (X)\n",
    "    \n",
    "    # ******************************************************\n",
    "    pipe2 = make_pipe_fit2 (path_results=path_results, verbose=2, root=True)\n",
    "    # second\n",
    "    r = pipe2.A0.fit_apply (X)\n",
    "    r = pipe2.A1.fit_apply (r)\n",
    "    b1 = pipe2.obj.B1.fit_apply (r)\n",
    "    b2 = pipe2.obj.B2.fit_apply (r)\n",
    "    \n",
    "    b3a = pipe2.obj.B3a.fit_apply (r)\n",
    "    b3b = pipe2.obj.B3b.fit_apply (b3a)\n",
    "    b3c = pipe2.obj.B3c.fit_apply (b3b)\n",
    "    b3d = pipe2.obj.B3d.fit_apply (b3c)\n",
    "    \n",
    "    b4a = pipe2.obj.B4a.fit_apply (r)\n",
    "    b4b = pipe2.obj.B4b.fit_apply (b4a)\n",
    "    b4c = pipe2.obj.B4c.fit_apply (b4b)\n",
    "    b4d = pipe2.obj.B4d.fit_apply (b4c)\n",
    "    b4e = pipe2.obj.B4e.fit_apply (b4d)\n",
    "    \n",
    "    b5 = pipe2.obj.B5.fit_apply (r)\n",
    "\n",
    "    all_fitted = pipe2.find_last_fitted_model ()\n",
    "    assert not all_fitted\n",
    "\n",
    "    pipe2.A0.raise_error = True\n",
    "    pipe2.A1.raise_error = True\n",
    "    \n",
    "    pipe2.obj.B3a.raise_error = True\n",
    "    pipe2.obj.B3b.raise_error = True\n",
    "    pipe2.obj.B3c.raise_error = True\n",
    "        \n",
    "    pipe2.obj.B4a.raise_error = True\n",
    "    pipe2.obj.B4b.raise_error = True\n",
    "    pipe2.obj.B4c.raise_error = True\n",
    "    pipe2.obj.B4d.raise_error = True\n",
    "    \n",
    "    pipe2.A1.create_estimator()\n",
    "    pipe2.obj.B2.create_estimator()\n",
    "    pipe2.obj.B3a.create_estimator()\n",
    "    pipe2.obj.B3b.create_estimator()\n",
    "    pipe2.obj.B4b.create_estimator()\n",
    "    pipe2.obj.B4c.create_estimator()\n",
    "    pipe2.obj.B4e.create_estimator()\n",
    "    pipe2.obj.B5.create_estimator()\n",
    "    \n",
    "    pipe2.logger.info (f'\\n{\"-\"*100}\\n')\n",
    "    r2 = pipe2.fit_apply (None)\n",
    "    assert (r1==r2).all()\n",
    "    \n",
    "    remove_previous_results (path_results=path_results)\n",
    "    \n",
    "    # ******************************************************\n",
    "    \n",
    "    pipe2.logger.info (f'\\n{\"*\"*100}\\n{\"*\"*100}\\n')\n",
    "    pipe2 = make_pipe_fit2 (path_results=path_results, verbose=2, root=True)\n",
    "    # second\n",
    "    r = pipe2.A0.fit_apply (X)\n",
    "    r = pipe2.A1.fit_apply (r)\n",
    "    b1 = pipe2.obj.B1.fit_apply (r)\n",
    "    b2 = pipe2.obj.B2.fit_apply (r)\n",
    "    \n",
    "    b3a = pipe2.obj.B3a.fit_apply (r)\n",
    "    b3b = pipe2.obj.B3b.fit_apply (b3a)\n",
    "    b3c = pipe2.obj.B3c.fit_apply (b3b)\n",
    "    b3d = pipe2.obj.B3d.fit_apply (b3c)\n",
    "    \n",
    "    b4 = pipe2.obj.pipeline_1_1.fit_apply (r)\n",
    "    b5 = pipe2.obj.B5.fit_apply (r)\n",
    "\n",
    "    all_fitted = pipe2.find_last_fitted_model ()\n",
    "    assert not all_fitted\n",
    "\n",
    "    pipe2.A0.raise_error = True\n",
    "    pipe2.A1.raise_error = True\n",
    "    \n",
    "    pipe2.obj.B3a.raise_error = True\n",
    "    pipe2.obj.B3b.raise_error = True\n",
    "    pipe2.obj.B3c.raise_error = True\n",
    "        \n",
    "    pipe2.obj.B4a.raise_error = True\n",
    "    pipe2.obj.B4b.raise_error = True\n",
    "    pipe2.obj.B4c.raise_error = True\n",
    "    pipe2.obj.B4d.raise_error = True\n",
    "    \n",
    "    pipe2.A1.create_estimator()\n",
    "    pipe2.obj.B2.create_estimator()\n",
    "    pipe2.obj.B3a.create_estimator()\n",
    "    pipe2.obj.B3b.create_estimator()\n",
    "    pipe2.obj.B4b.create_estimator()\n",
    "    pipe2.obj.B4c.create_estimator()\n",
    "    pipe2.obj.B4e.create_estimator()\n",
    "    pipe2.obj.B5.create_estimator()\n",
    "    \n",
    "    pipe2.logger.info (f'\\n{\"-\"*100}\\n')\n",
    "    r2 = pipe2.fit_apply (None)\n",
    "    assert (r1==r2).all()\n",
    "    \n",
    "    remove_previous_results (path_results=path_results)\n",
    "    \n",
    "    # ******************************************************\n",
    "    \n",
    "    pipe2.logger.info (f'\\n{\"*\"*100}\\n{\"*\"*100}\\n')\n",
    "    pipe2 = make_pipe_fit2 (path_results=path_results, verbose=2, root=True)\n",
    "    # second\n",
    "    r = pipe2.A0.fit_apply (X)\n",
    "    r = pipe2.A1.fit_apply (r)\n",
    "    r = pipe2.obj.parallel.fit_apply (r)\n",
    "\n",
    "    all_fitted = pipe2.find_last_fitted_model ()\n",
    "    assert not all_fitted\n",
    "\n",
    "    pipe2.A0.raise_error = True\n",
    "    pipe2.A1.raise_error = True\n",
    "    \n",
    "    pipe2.obj.B1.raise_error = True\n",
    "    pipe2.obj.B2.raise_error = True\n",
    "    \n",
    "    pipe2.obj.B3a.raise_error = True\n",
    "    pipe2.obj.B3b.raise_error = True\n",
    "    pipe2.obj.B3c.raise_error = True\n",
    "    pipe2.obj.B3d.raise_error = True\n",
    "        \n",
    "    pipe2.obj.B4a.raise_error = True\n",
    "    pipe2.obj.B4b.raise_error = True\n",
    "    pipe2.obj.B4c.raise_error = True\n",
    "    pipe2.obj.B4d.raise_error = True\n",
    "    pipe2.obj.B4e.raise_error = True\n",
    "    \n",
    "    pipe2.obj.B5.raise_error = True\n",
    "    \n",
    "    pipe2.A1.create_estimator()\n",
    "    pipe2.obj.B2.create_estimator()\n",
    "    pipe2.obj.B3a.create_estimator()\n",
    "    pipe2.obj.B3b.create_estimator()\n",
    "    pipe2.obj.B4b.create_estimator()\n",
    "    pipe2.obj.B4c.create_estimator()\n",
    "    pipe2.obj.B4e.create_estimator()\n",
    "    pipe2.obj.B5.create_estimator()\n",
    "    \n",
    "    pipe2.logger.info (f'\\n{\"-\"*100}\\n')\n",
    "    r2 = pipe2.fit_apply (None)\n",
    "    assert (r1==r2).all()\n",
    "    \n",
    "    remove_previous_results (path_results=path_results)\n",
    "    \n",
    "    # ******************************************************\n",
    "    pipe2.logger.info (f'\\n{\"*\"*100}\\n{\"*\"*100}\\n')\n",
    "    pipe2 = make_pipe_fit2 (path_results=path_results, verbose=2, root=True, new_parallel=True)\n",
    "    # second\n",
    "    r = pipe2.A0.fit_apply (X)\n",
    "    r = pipe2.A1.fit_apply (r)\n",
    "    r = pipe2.obj.new_parallel.fit_apply (r)\n",
    "    r = pipe2.C.fit_apply (r)\n",
    "\n",
    "    all_fitted = pipe2.find_last_fitted_model ()\n",
    "    assert not all_fitted\n",
    "\n",
    "    pipe2.A0.raise_error = True\n",
    "    pipe2.A1.raise_error = True\n",
    "    \n",
    "    pipe2.obj.B1.raise_error = True\n",
    "    pipe2.obj.B2.raise_error = True\n",
    "    \n",
    "    pipe2.obj.B3a.raise_error = True\n",
    "    pipe2.obj.B3b.raise_error = True\n",
    "    pipe2.obj.B3c.raise_error = True\n",
    "    pipe2.obj.B3d.raise_error = True\n",
    "        \n",
    "    pipe2.obj.B4a.raise_error = True\n",
    "    pipe2.obj.B4b.raise_error = True\n",
    "    pipe2.obj.B4c.raise_error = True\n",
    "    pipe2.obj.B4d.raise_error = True\n",
    "    pipe2.obj.B4e.raise_error = True\n",
    "    \n",
    "    pipe2.obj.B5.raise_error = True\n",
    "    \n",
    "    pipe2.new_parallel.raise_error = True\n",
    "    \n",
    "    pipe2.A1.create_estimator()\n",
    "    pipe2.obj.B2.create_estimator()\n",
    "    pipe2.obj.B3a.create_estimator()\n",
    "    pipe2.obj.B3b.create_estimator()\n",
    "    pipe2.obj.B4b.create_estimator()\n",
    "    pipe2.obj.B4c.create_estimator()\n",
    "    pipe2.obj.B4e.create_estimator()\n",
    "    pipe2.obj.B5.create_estimator()\n",
    "    \n",
    "    pipe2.logger.info (f'\\n{\"-\"*100}\\n')\n",
    "    r2 = pipe2.fit_apply (None)\n",
    "    assert (r1==r2).all()\n",
    "    \n",
    "    remove_previous_results (path_results=path_results)\n",
    "    \n",
    "    # ******************************************************\n",
    "    pipe2.logger.info (f'\\n{\"*\"*100}\\n{\"*\"*100}\\n')\n",
    "    pipe2 = make_pipe_fit2 (path_results=path_results, verbose=2, root=True, new_parallel=True)\n",
    "    # second\n",
    "    r = pipe2.A0.fit_apply (X)\n",
    "    r = pipe2.A1.fit_apply (r)\n",
    "    r = pipe2.obj.new_parallel.fit_apply (r)\n",
    "    r = pipe2.C.fit_apply (r)\n",
    "    r = pipe2.D.fit_apply (r)\n",
    "\n",
    "    all_fitted = pipe2.find_last_fitted_model ()\n",
    "    assert all_fitted\n",
    "\n",
    "    pipe2.A0.raise_error = True\n",
    "    pipe2.A1.raise_error = True\n",
    "    \n",
    "    pipe2.obj.B1.raise_error = True\n",
    "    pipe2.obj.B2.raise_error = True\n",
    "    \n",
    "    pipe2.obj.B3a.raise_error = True\n",
    "    pipe2.obj.B3b.raise_error = True\n",
    "    pipe2.obj.B3c.raise_error = True\n",
    "    pipe2.obj.B3d.raise_error = True\n",
    "        \n",
    "    pipe2.obj.B4a.raise_error = True\n",
    "    pipe2.obj.B4b.raise_error = True\n",
    "    pipe2.obj.B4c.raise_error = True\n",
    "    pipe2.obj.B4d.raise_error = True\n",
    "    pipe2.obj.B4e.raise_error = True\n",
    "    \n",
    "    pipe2.obj.B5.raise_error = True\n",
    "    \n",
    "    pipe2.new_parallel.raise_error = True\n",
    "    pipe2.C.raise_error = True\n",
    "    \n",
    "    pipe2.A1.create_estimator()\n",
    "    pipe2.obj.B2.create_estimator()\n",
    "    pipe2.obj.B3a.create_estimator()\n",
    "    pipe2.obj.B3b.create_estimator()\n",
    "    pipe2.obj.B4b.create_estimator()\n",
    "    pipe2.obj.B4c.create_estimator()\n",
    "    pipe2.obj.B4e.create_estimator()\n",
    "    pipe2.obj.B5.create_estimator()\n",
    "    \n",
    "    pipe2.D.create_estimator()\n",
    "    \n",
    "    pipe2.logger.info (f'\\n{\"-\"*100}\\n')\n",
    "    r2 = pipe2.fit_apply (None)\n",
    "    assert (r1==r2).all()\n",
    "    \n",
    "    remove_previous_results (path_results=path_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ffa3ca18-5889-4352-b1b8-19ac3a8d76a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tst.run (test_pipeline_find_last_fitted_model_parallel_2, tag='dummy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f7fb66-2cf8-4ffd-9098-9e20aa1e8dcc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cfcf6eb1-c0b0-4209-98ea-cedcee5df705",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from dsblocks.utils.dummies import (DataSource, SumXY, MaxOfPositiveWithSeparateLabels, Sum1direct,\n",
    "                                       Multiply10direct, subtract_xy, MinOfPositiveWithoutSeparateLabels)\n",
    "def test_data_conversion_sequential_parallel_column_transformer ():\n",
    "    class MinDC (PandasConverter):\n",
    "        def convert_before_fitting (self, *X):\n",
    "            df, label = X\n",
    "            df=df.copy()\n",
    "            df['label']=label\n",
    "            return (df,)\n",
    "\n",
    "        def convert_before_transforming (self, *X, **kwargs):\n",
    "            df, label = X\n",
    "            df=df.copy()\n",
    "            df['label']=label\n",
    "            return super().convert_before_transforming (df)\n",
    "\n",
    "    pipe = Sequential (DataSource (convert_after=lambda x: (x[0],x[1],np.array(x[2]))),\n",
    "                       SumXY (data_converter='GenericConverter'),\n",
    "                       Component(apply=lambda X: X*2, data_converter='GenericConverter'),\n",
    "                       MaxOfPositiveWithSeparateLabels (data_converter='GenericConverter'),\n",
    "                       Parallel (Sum1direct (data_converter='GenericConverter'), \n",
    "                                 Multiply10direct (data_converter='GenericConverter'),\n",
    "                                 finalize_result=lambda x: (x[0][0], x[1][0]),\n",
    "                                 data_converter='GenericConverter'),\n",
    "                       Component(apply=subtract_xy, data_converter='GenericConverter'),\n",
    "                       MinOfPositiveWithoutSeparateLabels (data_converter=MinDC),\n",
    "                       make_column_transformer ((Multiply10direct (data_converter='GenericConverter'), ['a','b']), \n",
    "                                                (Sum1direct (data_converter='GenericConverter'), ['c','d'])),\n",
    "                       Sum1direct (data_converter='GenericConverter'))\n",
    "\n",
    "    x = pipe.fit_apply()\n",
    "\n",
    "    print (x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f0d691a5-aefd-4617-996f-4a507ca3a6b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running test_data_conversion_sequential_parallel_column_transformer\n",
      "        a       b      c       d\n",
      "0  -80349 -211029 -32261 -104135\n",
      "1 -116349 -247029 -52061 -123935\n",
      "2 -152349 -283029 -71861 -143735\n",
      "3 -188349 -319029 -91661 -163535\n"
     ]
    }
   ],
   "source": [
    "tst.run (test_data_conversion_sequential_parallel_column_transformer, tag='dummy')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dsblocks)",
   "language": "python",
   "name": "dsblocks"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
